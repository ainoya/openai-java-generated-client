openapi: 3.0.0
info:
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  termsOfService: https://openai.com/policies/terms-of-use
  title: OpenAI API
  version: 2.3.0
servers:
- url: https://api.openai.com/v1
security:
- ApiKeyAuth: []
tags:
- description: Build Assistants that can call models and use tools.
  name: Assistants
- description: Turn audio into text or text into audio.
  name: Audio
- description: "Given a list of messages comprising a conversation, the model will\
    \ return a response."
  name: Chat
- description: "Given a prompt, the model will return one or more predicted completions,\
    \ and can also return the probabilities of alternative tokens at each position."
  name: Completions
- description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
  name: Embeddings
- description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
  name: Fine-tuning
- description: Create large batches of API requests to run asynchronously.
  name: Batch
- description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
  name: Files
- description: Use Uploads to upload large files in multiple parts.
  name: Uploads
- description: "Given a prompt and/or an input image, the model will generate a new\
    \ image."
  name: Images
- description: List and describe the various models available in the API.
  name: Models
- description: "Given text and/or image inputs, classifies if those inputs are potentially\
    \ harmful."
  name: Moderations
- description: List user actions and configuration changes within this organization.
  name: Audit Logs
paths:
  /assistants:
    get:
      operationId: listAssistants
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
          description: OK
      summary: Returns a list of assistants.
      tags:
      - Assistants
      x-oaiMeta:
        name: List assistants
        group: assistants
        beta: true
        returns: "A list of [assistant](/docs/api-reference/assistants/object) objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistants = client.beta.assistants.list(
                  order="desc",
                  limit="20",
              )
              print(my_assistants.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistants = await openai.beta.assistants.list({
                  order: "desc",
                  limit: "20",
                });

                console.log(myAssistants.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "asst_abc123",
                  "object": "assistant",
                  "created_at": 1698982736,
                  "name": "Coding Tutor",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc456",
                  "object": "assistant",
                  "created_at": 1698982718,
                  "name": "My Assistant",
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc789",
                  "object": "assistant",
                  "created_at": 1698982643,
                  "name": null,
                  "description": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                }
              ],
              "first_id": "asst_abc123",
              "last_id": "asst_abc789",
              "has_more": false
            }
      x-accepts:
      - application/json
    post:
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Create an assistant with a model and instructions.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create assistant
        group: assistants
        beta: true
        returns: "An [assistant](/docs/api-reference/assistants/object) object."
        examples:
        - title: Code Interpreter
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  "name": "Math Tutor",
                  "tools": [{"type": "code_interpreter"}],
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name="Math Tutor",
                  tools=[{"type": "code_interpreter"}],
                  model="gpt-4o",
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name: "Math Tutor",
                  tools: [{ type: "code_interpreter" }],
                  model: "gpt-4o",
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1698984975,
              "name": "Math Tutor",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        - title: Files
          request:
            curl: |
              curl https://api.openai.com/v1/assistants \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  "tools": [{"type": "file_search"}],
                  "tool_resources": {"file_search": {"vector_store_ids": ["vs_123"]}},
                  "model": "gpt-4o"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name="HR Helper",
                  tools=[{"type": "file_search"}],
                  tool_resources={"file_search": {"vector_store_ids": ["vs_123"]}},
                  model="gpt-4o"
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name: "HR Helper",
                  tools: [{ type: "file_search" }],
                  tool_resources: {
                    file_search: {
                      vector_store_ids: ["vs_123"]
                    }
                  },
                  model: "gpt-4o"
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009403,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /assistants/{assistant_id}:
    delete:
      operationId: deleteAssistant
      parameters:
      - description: The ID of the assistant to delete.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
          description: OK
      summary: Delete an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete assistant
        group: assistants
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.assistants.delete("asst_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.assistants.del("asst_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant.deleted",
              "deleted": true
            }
      x-accepts:
      - application/json
    get:
      operationId: getAssistant
      parameters:
      - description: The ID of the assistant to retrieve.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Retrieves an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve assistant
        group: assistants
        beta: true
        returns: "The [assistant](/docs/api-reference/assistants/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.retrieve("asst_abc123")
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.retrieve(
                  "asst_abc123"
                );

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
      x-accepts:
      - application/json
    post:
      operationId: modifyAssistant
      parameters:
      - description: The ID of the assistant to modify.
        explode: false
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Modifies an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify assistant
        group: assistants
        beta: true
        returns: "The modified [assistant](/docs/api-reference/assistants/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    "tools": [{"type": "file_search"}],
                    "model": "gpt-4o"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_assistant = client.beta.assistants.update(
                "asst_abc123",
                instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                name="HR Helper",
                tools=[{"type": "file_search"}],
                model="gpt-4o"
              )

              print(my_updated_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myUpdatedAssistant = await openai.beta.assistants.update(
                  "asst_abc123",
                  {
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    model: "gpt-4o"
                  }
                );

                console.log(myUpdatedAssistant);
              }

              main();
          response: |
            {
              "id": "asst_123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4o",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": []
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /audio/speech:
    post:
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        "200":
          content:
            application/octet-stream:
              schema:
                format: binary
                type: string
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              explode: false
              schema:
                type: string
              style: simple
      summary: Generates audio from the input text.
      tags:
      - Audio
      x-oaiMeta:
        name: Create speech
        group: audio
        returns: The audio file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "tts-1",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy"
                }' \
                --output speech.mp3
            python: |
              from pathlib import Path
              import openai

              speech_file_path = Path(__file__).parent / "speech.mp3"
              response = openai.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input="The quick brown fox jumped over the lazy dog."
              )
              response.stream_to_file(speech_file_path)
            node: |
              import fs from "fs";
              import path from "path";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const speechFile = path.resolve("./speech.mp3");

              async function main() {
                const mp3 = await openai.audio.speech.create({
                  model: "tts-1",
                  voice: "alloy",
                  input: "Today is a wonderful day to build something people love!",
                });
                console.log(speechFile);
                const buffer = Buffer.from(await mp3.arrayBuffer());
                await fs.promises.writeFile(speechFile, buffer);
              }
              main();
      x-content-type: application/json
      x-accepts:
      - application/octet-stream
  /audio/transcriptions:
    post:
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/createTranscription_200_response'
          description: OK
      summary: Transcribes audio into the input language.
      tags:
      - Audio
      x-oaiMeta:
        name: Create transcription
        group: audio
        returns: "The [transcription object](/docs/api-reference/audio/json-object)\
          \ or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object)."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
              )
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
            }
        - title: Word timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=word" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["word"]
              )

              print(transcript.words)
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["word"]
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "words": [
                {
                  "word": "The",
                  "start": 0.0,
                  "end": 0.23999999463558197
                },
                ...
                {
                  "word": "volleyball",
                  "start": 7.400000095367432,
                  "end": 7.900000095367432
                }
              ]
            }
        - title: Segment timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=segment" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["segment"]
              )

              print(transcript.words)
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["segment"]
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "segments": [
                {
                  "id": 0,
                  "seek": 0,
                  "start": 0.0,
                  "end": 3.319999933242798,
                  "text": " The beach was a popular spot on a hot summer day.",
                  "tokens": [
                    50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                  ],
                  "temperature": 0.0,
                  "avg_logprob": -0.2860786020755768,
                  "compression_ratio": 1.2363636493682861,
                  "no_speech_prob": 0.00985979475080967
                },
                ...
              ]
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /audio/translations:
    post:
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/createTranslation_200_response'
          description: OK
      summary: Translates audio into English.
      tags:
      - Audio
      x-oaiMeta:
        name: Create translation
        group: audio
        returns: The translated text.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/translations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/german.m4a" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.translations.create(
                model="whisper-1",
                file=audio_file
              )
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                  const translation = await openai.audio.translations.create({
                      file: fs.createReadStream("speech.mp3"),
                      model: "whisper-1",
                  });

                  console.log(translation.text);
              }
              main();
          response: |
            {
              "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /batches:
    get:
      operationId: listBatches
      parameters:
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
          description: Batch listed successfully.
      summary: List your organization's batches.
      tags:
      - Batch
      x-oaiMeta:
        name: List batch
        group: batch
        returns: "A list of paginated [Batch](/docs/api-reference/batch/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.list()
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.batches.list();

                for await (const batch of list) {
                  console.log(batch);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "batch_abc123",
                  "object": "batch",
                  "endpoint": "/v1/chat/completions",
                  "errors": null,
                  "input_file_id": "file-abc123",
                  "completion_window": "24h",
                  "status": "completed",
                  "output_file_id": "file-cvaTdG",
                  "error_file_id": "file-HOWS94",
                  "created_at": 1711471533,
                  "in_progress_at": 1711471538,
                  "expires_at": 1711557933,
                  "finalizing_at": 1711493133,
                  "completed_at": 1711493163,
                  "failed_at": null,
                  "expired_at": null,
                  "cancelling_at": null,
                  "cancelled_at": null,
                  "request_counts": {
                    "total": 100,
                    "completed": 95,
                    "failed": 5
                  },
                  "metadata": {
                    "customer_id": "user_123456789",
                    "batch_description": "Nightly job",
                  }
                },
                { ... },
              ],
              "first_id": "batch_abc123",
              "last_id": "batch_abc456",
              "has_more": true
            }
      x-accepts:
      - application/json
    post:
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/createBatch_request'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch created successfully.
      summary: Creates and executes a batch from an uploaded file of requests
      tags:
      - Batch
      x-oaiMeta:
        name: Create batch
        group: batch
        returns: "The created [Batch](/docs/api-reference/batch/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input_file_id": "file-abc123",
                  "endpoint": "/v1/chat/completions",
                  "completion_window": "24h"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.create(
                input_file_id="file-abc123",
                endpoint="/v1/chat/completions",
                completion_window="24h"
              )
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.create({
                  input_file_id: "file-abc123",
                  endpoint: "/v1/chat/completions",
                  completion_window: "24h"
                });

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "validating",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": null,
              "expires_at": null,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 0,
                "completed": 0,
                "failed": 0
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /batches/{batch_id}:
    get:
      operationId: retrieveBatch
      parameters:
      - description: The ID of the batch to retrieve.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch retrieved successfully.
      summary: Retrieves a batch.
      tags:
      - Batch
      x-oaiMeta:
        name: Retrieve batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.retrieve("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.retrieve("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "completed",
              "output_file_id": "file-cvaTdG",
              "error_file_id": "file-HOWS94",
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": 1711493133,
              "completed_at": 1711493163,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 95,
                "failed": 5
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
      x-accepts:
      - application/json
  /batches/{batch_id}/cancel:
    post:
      operationId: cancelBatch
      parameters:
      - description: The ID of the batch to cancel.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch is cancelling. Returns the cancelling batch's details.
      summary: "Cancels an in-progress batch. The batch will be in status `cancelling`\
        \ for up to 10 minutes, before changing to `cancelled`, where it will have\
        \ partial results (if any) available in the output file."
      tags:
      - Batch
      x-oaiMeta:
        name: Cancel batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.cancel("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.cancel("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "cancelling",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": 1711475133,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 23,
                "failed": 1
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
      x-accepts:
      - application/json
  /chat/completions:
    post:
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
          description: OK
      summary: |
        Creates a model response for the given chat conversation. Learn more in the
        [text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
        and [audio](/docs/guides/audio) guides.
      tags:
      - Chat
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "system", content: "You are a helpful assistant." }],
                  model: "VAR_model_id",
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-4o-mini",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nHello there, how may I assist you today?",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21,
                "completion_tokens_details": {
                  "reasoning_tokens": 0
                }
              }
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What'\''s in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4o",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": {
                                      "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                  }
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4o",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url: {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                          },
                        }
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-4o-mini",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21,
                "completion_tokens_details": {
                  "reasoning_tokens": 0
                }
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_model_id",
                  messages: [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4o",
                "messages": [
                  {
                    "role": "user",
                    "content": "What'\''s the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4o",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99,
                "completion_tokens_details": {
                  "reasoning_tokens": 0
                }
              }
            }
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18,
                "completion_tokens_details": {
                  "reasoning_tokens": 0
                }
              },
              "system_fingerprint": null
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /completions:
    post:
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
          description: OK
      summary: Creates a completion for the provided prompt and parameters.
      tags:
      - Completions
      x-oaiMeta:
        name: Create completion
        group: completions
        returns: |
          Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.
        legacy: true
        examples:
        - title: No streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.completions.create(
                model="VAR_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.completions.create({
                  model: "VAR_model_id",
                  prompt: "Say this is a test.",
                  max_tokens: 7,
                  temperature: 0,
                });

                console.log(completion);
              }
              main();
          response: |
            {
              "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
              "object": "text_completion",
              "created": 1589478378,
              "model": "VAR_model_id",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [
                {
                  "text": "\n\nThis is indeed a test",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": "length"
                }
              ],
              "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0,
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              for chunk in client.completions.create(
                model="VAR_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0,
                stream=True
              ):
                print(chunk.choices[0].text)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.completions.create({
                  model: "VAR_model_id",
                  prompt: "Say this is a test.",
                  stream: true,
                });

                for await (const chunk of stream) {
                  console.log(chunk.choices[0].text)
                }
              }
              main();
          response: |
            {
              "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
              "object": "text_completion",
              "created": 1690759702,
              "choices": [
                {
                  "text": "This",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": null
                }
              ],
              "model": "gpt-3.5-turbo-instruct"
              "system_fingerprint": "fp_44709d6fcb",
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /embeddings:
    post:
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
          description: OK
      summary: Creates an embedding vector representing the input text.
      tags:
      - Embeddings
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: "A list of [embedding](/docs/api-reference/embeddings/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /files:
    get:
      operationId: listFiles
      parameters:
      - description: Only return files with the given purpose.
        explode: true
        in: query
        name: purpose
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
          description: OK
      summary: Returns a list of files that belong to the user's organization.
      tags:
      - Files
      x-oaiMeta:
        name: List files
        group: files
        returns: "A list of [File](/docs/api-reference/files/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.files.list();

                for await (const file of list) {
                  console.log(file);
                }
              }

              main();
          response: |
            {
              "data": [
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 175,
                  "created_at": 1613677385,
                  "filename": "salesOverview.pdf",
                  "purpose": "assistants",
                },
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 140,
                  "created_at": 1613779121,
                  "filename": "puppy.jsonl",
                  "purpose": "fine-tune",
                }
              ],
              "object": "list"
            }
      x-accepts:
      - application/json
    post:
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
          description: OK
      summary: |
        Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

        The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

        The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

        The Batch API only supports `.jsonl` files up to 100 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

        Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
      tags:
      - Files
      x-oaiMeta:
        name: Upload file
        group: files
        returns: "The uploaded [File](/docs/api-reference/files/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F purpose="fine-tune" \
                -F file="@mydata.jsonl"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.create(
                file=open("mydata.jsonl", "rb"),
                purpose="fine-tune"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.create({
                  file: fs.createReadStream("mydata.jsonl"),
                  purpose: "fine-tune",
                });

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /files/{file_id}:
    delete:
      operationId: deleteFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
          description: OK
      summary: Delete a file.
      tags:
      - Files
      x-oaiMeta:
        name: Delete file
        group: files
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.delete("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.del("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "deleted": true
            }
      x-accepts:
      - application/json
    get:
      operationId: retrieveFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
          description: OK
      summary: Returns information about a specific file.
      tags:
      - Files
      x-oaiMeta:
        name: Retrieve file
        group: files
        returns: "The [File](/docs/api-reference/files/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.retrieve("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.retrieve("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
      x-accepts:
      - application/json
  /files/{file_id}/content:
    get:
      operationId: downloadFile
      parameters:
      - description: The ID of the file to use for this request.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                type: string
          description: OK
      summary: Returns the contents of the specified file.
      tags:
      - Files
      x-oaiMeta:
        name: Retrieve file content
        group: files
        returns: The file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123/content \
                -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
            python: |
              from openai import OpenAI
              client = OpenAI()

              content = client.files.content("file-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.content("file-abc123");

                console.log(file);
              }

              main();
      x-accepts:
      - application/json
  /fine_tuning/jobs:
    get:
      operationId: listPaginatedFineTuningJobs
      parameters:
      - description: Identifier for the last job from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of fine-tuning jobs to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
          description: OK
      summary: |
        List your organization's fine-tuning jobs
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning jobs
        group: fine-tuning
        returns: "A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.jobs.list();

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",
                  "created_at": 1689813489,
                  "level": "warn",
                  "message": "Fine tuning process stopping due to job cancellation",
                  "data": null,
                  "type": "message"
                },
                { ... },
                { ... }
              ], "has_more": true
            }
      x-accepts:
      - application/json
    post:
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Create fine-tuning job
        group: fine-tuning
        returns: "A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
            }
        - title: Epochs
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "hyperparameters": {
                    "n_epochs": 2
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-4o-mini",
                hyperparameters={
                  "n_epochs":2
                }
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  model: "gpt-4o-mini",
                  hyperparameters: { n_epochs: 2 }
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {"n_epochs": 2},
            }
        - title: Validation file
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                validation_file="file-def456",
                model="gpt-4o-mini"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  validation_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
            }
        - title: W&B Integration
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-4o-mini",
                  "integrations": [
                    {
                      "type": "wandb",
                      "wandb": {
                        "project": "my-wandb-project",
                        "name": "ft-run-display-name"
                        "tags": [
                          "first-experiment", "v2"
                        ]
                      }
                    }
                  ]
                }'
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "integrations": [
                {
                  "type": "wandb",
                  "wandb": {
                    "project": "my-wandb-project",
                    "entity": None,
                    "run_id": "ftjob-abc123"
                  }
                }
              ]
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: retrieveFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Retrieve fine-tuning job
        group: fine-tuning
        returns: "The [fine-tuning](/docs/api-reference/fine-tuning/object) object\
          \ with the given ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.retrieve("ftjob-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "davinci-002",
              "created_at": 1692661014,
              "finished_at": 1692661190,
              "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
              "organization_id": "org-123",
              "result_files": [
                  "file-abc123"
              ],
              "status": "succeeded",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
              },
              "trained_tokens": 5768,
              "integrations": [],
              "seed": 0,
              "estimated_finish": 0
            }
      x-accepts:
      - application/json
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: cancelFineTuningJob
      parameters:
      - description: |
          The ID of the fine-tuning job to cancel.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: |
        Immediately cancel a fine-tune job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: Cancel fine-tuning
        group: fine-tuning
        returns: "The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.cancel("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-4o-mini-2024-07-18",
              "created_at": 1721764800,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "hyperparameters": {
                "n_epochs":  "auto"
              },
              "status": "cancelled",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
      x-accepts:
      - application/json
  /fine_tuning/jobs/{fine_tuning_job_id}/checkpoints:
    get:
      operationId: listFineTuningJobCheckpoints
      parameters:
      - description: |
          The ID of the fine-tuning job to get checkpoints for.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      - description: Identifier for the last checkpoint ID from the previous pagination
          request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of checkpoints to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 10
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
          description: OK
      summary: |
        List checkpoints for a fine-tuning job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning checkpoints
        group: fine-tuning
        returns: "A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object)\
          \ for a fine-tuning job."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list"
              "data": [
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1721764867,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",
                  "metrics": {
                    "full_valid_loss": 0.134,
                    "full_valid_mean_token_accuracy": 0.874
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 2000,
                },
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1721764800,
                  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
                  "metrics": {
                    "full_valid_loss": 0.167,
                    "full_valid_mean_token_accuracy": 0.781
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 1000,
                },
              ],
              "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": true
            }
      x-accepts:
      - application/json
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: listFineTuningEvents
      parameters:
      - description: |
          The ID of the fine-tuning job to get events for.
        explode: false
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
        style: simple
      - description: Identifier for the last event from the previous pagination request.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: Number of events to retrieve.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
          description: OK
      summary: |
        Get status updates for a fine-tuning job.
      tags:
      - Fine-tuning
      x-oaiMeta:
        name: List fine-tuning events
        group: fine-tuning
        returns: A list of fine-tuning event objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list_events(
                fine_tuning_job_id="ftjob-abc123",
                limit=2
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "Fine tuning job successfully completed",
                  "data": null,
                  "type": "message"
                },
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
                  "created_at": 1721764800,
                  "level": "info",
                  "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",
                  "data": null,
                  "type": "message"
                }
              ],
              "has_more": true
            }
      x-accepts:
      - application/json
  /images/edits:
    post:
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates an edited or extended image given an original image and a prompt.
      tags:
      - Images
      x-oaiMeta:
        name: Create image edit
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/edits \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F mask="@mask.png" \
                -F prompt="A cute baby sea otter wearing a beret" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.edit(
                image=open("otter.png", "rb"),
                mask=open("mask.png", "rb"),
                prompt="A cute baby sea otter wearing a beret",
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.edit({
                  image: fs.createReadStream("otter.png"),
                  mask: fs.createReadStream("mask.png"),
                  prompt: "A cute baby sea otter wearing a beret",
                });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /images/generations:
    post:
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates an image given a prompt.
      tags:
      - Images
      x-oaiMeta:
        name: Create image
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/generations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "dall-e-3",
                  "prompt": "A cute baby sea otter",
                  "n": 1,
                  "size": "1024x1024"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.generate(
                model="dall-e-3",
                prompt="A cute baby sea otter",
                n=1,
                size="1024x1024"
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.generate({ model: "dall-e-3", prompt: "A cute baby sea otter" });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /images/variations:
    post:
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates a variation of a given image.
      tags:
      - Images
      x-oaiMeta:
        name: Create image variation
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/variations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.images.create_variation(
                image=open("image_edit_original.png", "rb"),
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.createVariation({
                  image: fs.createReadStream("otter.png"),
                });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /models:
    get:
      operationId: listModels
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
          description: OK
      summary: "Lists the currently available models, and provides basic information\
        \ about each one such as the owner and availability."
      tags:
      - Models
      x-oaiMeta:
        name: List models
        group: models
        returns: "A list of [model](/docs/api-reference/models/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.models.list();

                for await (const model of list) {
                  console.log(model);
                }
              }
              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "model-id-0",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner"
                },
                {
                  "id": "model-id-1",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner",
                },
                {
                  "id": "model-id-2",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "openai"
                },
              ],
              "object": "list"
            }
      x-accepts:
      - application/json
  /models/{model}:
    delete:
      operationId: deleteModel
      parameters:
      - description: The model to delete
        explode: false
        in: path
        name: model
        required: true
        schema:
          example: ft:gpt-4o-mini:acemeco:suffix:abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
          description: OK
      summary: Delete a fine-tuned model. You must have the Owner role in your organization
        to delete a model.
      tags:
      - Models
      x-oaiMeta:
        name: Delete a fine-tuned model
        group: models
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.delete("ft:gpt-4o-mini:acemeco:suffix:abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.del("ft:gpt-4o-mini:acemeco:suffix:abc123");

                console.log(model);
              }
              main();
          response: |
            {
              "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
              "object": "model",
              "deleted": true
            }
      x-accepts:
      - application/json
    get:
      operationId: retrieveModel
      parameters:
      - description: The ID of the model to use for this request
        explode: false
        in: path
        name: model
        required: true
        schema:
          example: gpt-4o-mini
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
          description: OK
      summary: "Retrieves a model instance, providing basic information about the\
        \ model such as the owner and permissioning."
      tags:
      - Models
      x-oaiMeta:
        name: Retrieve model
        group: models
        returns: "The [model](/docs/api-reference/models/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/VAR_model_id \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.retrieve("VAR_model_id")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.retrieve("VAR_model_id");

                console.log(model);
              }

              main();
          response: |
            {
              "id": "VAR_model_id",
              "object": "model",
              "created": 1686935002,
              "owned_by": "openai"
            }
      x-accepts:
      - application/json
  /moderations:
    post:
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
          description: OK
      summary: |
        Classifies if text and/or image inputs are potentially harmful. Learn
        more in the [moderation guide](/docs/guides/moderation).
      tags:
      - Moderations
      x-oaiMeta:
        name: Create moderation
        group: moderations
        returns: "A [moderation](/docs/api-reference/moderations/object) object."
        examples:
        - title: Single string
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "input": "I want to kill them."
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              moderation = client.moderations.create(input="I want to kill them.")
              print(moderation)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const moderation = await openai.moderations.create({ input: "I want to kill them." });

                console.log(moderation);
              }
              main();
          response: |
            {
              "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
              "model": "text-moderation-007",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "sexual": false,
                    "hate": false,
                    "harassment": true,
                    "self-harm": false,
                    "sexual/minors": false,
                    "hate/threatening": false,
                    "violence/graphic": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "harassment/threatening": true,
                    "violence": true
                  },
                  "category_scores": {
                    "sexual": 0.000011726012417057063,
                    "hate": 0.22706663608551025,
                    "harassment": 0.5215635299682617,
                    "self-harm": 2.227119921371923e-6,
                    "sexual/minors": 7.107352217872176e-8,
                    "hate/threatening": 0.023547329008579254,
                    "violence/graphic": 0.00003391829886822961,
                    "self-harm/intent": 1.646940972932498e-6,
                    "self-harm/instructions": 1.1198755256458526e-9,
                    "harassment/threatening": 0.5694745779037476,
                    "violence": 0.9971134662628174
                  }
                }
              ]
            }
        - title: Image and text
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -X POST \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "omni-moderation-latest",
                  "input": [
                    { "type": "text", "text": "...text to classify goes here..." },
                    {
                      "type": "image_url",
                      "image_url": {
                        "url": "https://example.com/image.png"
                      }
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.moderations.create(
                  model="omni-moderation-latest",
                  input=[
                      {"type": "text", "text": "...text to classify goes here..."},
                      {
                          "type": "image_url",
                          "image_url": {
                              "url": "https://example.com/image.png",
                              # can also use base64 encoded image URLs
                              # "url": "data:image/jpeg;base64,abcdefg..."
                          }
                      },
                  ],
              )

              print(response)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const moderation = await openai.moderations.create({
                  model: "omni-moderation-latest",
                  input: [
                      { type: "text", text: "...text to classify goes here..." },
                      {
                          type: "image_url",
                          image_url: {
                              url: "https://example.com/image.png"
                              // can also use base64 encoded image URLs
                              // url: "data:image/jpeg;base64,abcdefg..."
                          }
                      }
                  ],
              });

              console.log(moderation);
          response: |
            {
              "id": "modr-0d9740456c391e43c445bf0f010940c7",
              "model": "omni-moderation-latest",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "harassment": true,
                    "harassment/threatening": true,
                    "sexual": false,
                    "hate": false,
                    "hate/threatening": false,
                    "illicit": false,
                    "illicit/violent": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "self-harm": false,
                    "sexual/minors": false,
                    "violence": true,
                    "violence/graphic": true
                  },
                  "category_scores": {
                    "harassment": 0.8189693396524255,
                    "harassment/threatening": 0.804985420696006,
                    "sexual": 1.573112165348997e-6,
                    "hate": 0.007562942636942845,
                    "hate/threatening": 0.004208854591835476,
                    "illicit": 0.030535955153511665,
                    "illicit/violent": 0.008925306722380033,
                    "self-harm/intent": 0.00023023930975076432,
                    "self-harm/instructions": 0.0002293869201073356,
                    "self-harm": 0.012598046106750154,
                    "sexual/minors": 2.212566909570261e-8,
                    "violence": 0.9999992735124786,
                    "violence/graphic": 0.843064871157054
                  },
                  "category_applied_input_types": {
                    "harassment": [
                      "text"
                    ],
                    "harassment/threatening": [
                      "text"
                    ],
                    "sexual": [
                      "text",
                      "image"
                    ],
                    "hate": [
                      "text"
                    ],
                    "hate/threatening": [
                      "text"
                    ],
                    "illicit": [
                      "text"
                    ],
                    "illicit/violent": [
                      "text"
                    ],
                    "self-harm/intent": [
                      "text",
                      "image"
                    ],
                    "self-harm/instructions": [
                      "text",
                      "image"
                    ],
                    "self-harm": [
                      "text",
                      "image"
                    ],
                    "sexual/minors": [
                      "text"
                    ],
                    "violence": [
                      "text",
                      "image"
                    ],
                    "violence/graphic": [
                      "text",
                      "image"
                    ]
                  }
                }
              ]
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/audit_logs:
    get:
      operationId: list-audit-logs
      parameters:
      - description: Return only events whose `effective_at` (Unix seconds) is in
          this range.
        explode: true
        in: query
        name: effective_at
        required: false
        schema:
          $ref: '#/components/schemas/list_audit_logs_effective_at_parameter'
        style: form
      - description: Return only events for these projects.
        explode: true
        in: query
        name: "project_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Return only events with a `type` in one of these values. For\
          \ example, `project.created`. For all options, see the documentation for\
          \ the [audit log object](/docs/api-reference/audit-logs/object)."
        explode: true
        in: query
        name: "event_types[]"
        required: false
        schema:
          items:
            $ref: '#/components/schemas/AuditLogEventType'
          type: array
        style: form
      - description: "Return only events performed by these actors. Can be a user\
          \ ID, a service account ID, or an api key tracking ID."
        explode: true
        in: query
        name: "actor_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: Return only events performed by users with these emails.
        explode: true
        in: query
        name: "actor_emails[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: "Return only events performed on these targets. For example,\
          \ a project ID updated."
        explode: true
        in: query
        name: "resource_ids[]"
        required: false
        schema:
          items:
            type: string
          type: array
        style: form
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAuditLogsResponse'
          description: Audit logs listed successfully.
      summary: List user actions and configuration changes within this organization.
      tags:
      - Audit Logs
      x-oaiMeta:
        name: List audit logs
        group: audit-logs
        returns: "A list of paginated [Audit Log](/docs/api-reference/audit-logs/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/audit_logs \
              -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
              -H "Content-Type: application/json" \
          response: |
            {
                "object": "list",
                "data": [
                    {
                        "id": "audit_log-xxx_yyyymmdd",
                        "type": "project.archived",
                        "effective_at": 1722461446,
                        "actor": {
                            "type": "api_key",
                            "api_key": {
                                "type": "user",
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                }
                            }
                        },
                        "project.archived": {
                            "id": "proj_abc"
                        },
                    },
                    {
                        "id": "audit_log-yyy__20240101",
                        "type": "api_key.updated",
                        "effective_at": 1720804190,
                        "actor": {
                            "type": "session",
                            "session": {
                                "user": {
                                    "id": "user-xxx",
                                    "email": "user@example.com"
                                },
                                "ip_address": "127.0.0.1",
                                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                            }
                        },
                        "api_key.updated": {
                            "id": "key_xxxx",
                            "data": {
                                "scopes": ["resource_2.operation_2"]
                            }
                        },
                    }
                ],
                "first_id": "audit_log-xxx__20240101",
                "last_id": "audit_log_yyy__20240101",
                "has_more": true
            }
      x-accepts:
      - application/json
  /organization/invites:
    get:
      operationId: list-invites
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteListResponse'
          description: Invites listed successfully.
      summary: Returns a list of invites in the organization.
      tags:
      - Invites
      x-oaiMeta:
        name: List invites
        group: administration
        returns: "A list of [Invite](/docs/api-reference/invite/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                "object": "list",
                "data": [
                  {
                    "object": "organization.invite",
                    "id": "invite-abc",
                    "email": "user@example.com",
                    "role": "owner",
                    "status": "accepted",
                    "invited_at": 1711471533,
                    "expires_at": 1711471533,
                    "accepted_at": 1711471533
                  }
                ],
                "first_id": "invite-abc",
                "last_id": "invite-abc",
                "has_more": false
              }
      x-accepts:
      - application/json
    post:
      operationId: inviteUser
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InviteRequest'
        description: The invite request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
          description: User invited successfully.
      summary: Create an invite for a user to the organization. The invite must be
        accepted by the user before they have access to the organization.
      tags:
      - Invites
      x-oaiMeta:
        name: Create invite
        group: administration
        returns: "The created [Invite](/docs/api-reference/invite/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/invites \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "email": "user@example.com",
                    "role": "owner"
                }'
          response:
            content: |
              {
                  "object": "organization.invite",
                  "id": "invite-abc",
                  "email": "user@example.com",
                  "role": "owner",
                  "invited_at": 1711471533,
                  "expires_at": 1711471533,
                  "accepted_at": null
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/invites/{invite_id}:
    delete:
      operationId: delete-invite
      parameters:
      - description: The ID of the invite to delete.
        explode: false
        in: path
        name: invite_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InviteDeleteResponse'
          description: Invite deleted successfully.
      summary: "Delete an invite. If the invite has already been accepted, it cannot\
        \ be deleted."
      tags:
      - Invites
      x-oaiMeta:
        name: Delete invite
        group: administration
        returns: Confirmation that the invite has been deleted
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.invite.deleted",
                  "id": "invite-abc",
                  "deleted": true
              }
      x-accepts:
      - application/json
    get:
      operationId: retrieve-invite
      parameters:
      - description: The ID of the invite to retrieve.
        explode: false
        in: path
        name: invite_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Invite'
          description: Invite retrieved successfully.
      summary: Retrieves an invite.
      tags:
      - Invites
      x-oaiMeta:
        name: Retrieve invite
        group: administration
        returns: "The [Invite](/docs/api-reference/invite/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/invites/invite-abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.invite",
                  "id": "invite-abc",
                  "email": "user@example.com",
                  "role": "owner",
                  "status": "accepted",
                  "invited_at": 1711471533,
                  "expires_at": 1711471533,
                  "accepted_at": 1711471533
              }
      x-accepts:
      - application/json
  /organization/projects:
    get:
      operationId: list-projects
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: If `true` returns all projects including those that have been
          `archived`. Archived projects are not included by default.
        explode: true
        in: query
        name: include_archived
        required: false
        schema:
          default: false
          type: boolean
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectListResponse'
          description: Projects listed successfully.
      summary: Returns a list of projects.
      tags:
      - Projects
      x-oaiMeta:
        name: List projects
        group: administration
        returns: "A list of [Project](/docs/api-reference/projects/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "list",
                  "data": [
                      {
                          "id": "proj_abc",
                          "object": "organization.project",
                          "name": "Project example",
                          "created_at": 1711471533,
                          "archived_at": null,
                          "status": "active"
                      }
                  ],
                  "first_id": "proj-abc",
                  "last_id": "proj-xyz",
                  "has_more": false
              }
      x-accepts:
      - application/json
    post:
      operationId: create-project
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectCreateRequest'
        description: The project create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
          description: Project created successfully.
      summary: "Create a new project in the organization. Projects can be created\
        \ and archived, but cannot be deleted."
      tags:
      - Projects
      x-oaiMeta:
        name: Create project
        group: administration
        returns: "The created [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project ABC"
                }'
          response:
            content: |
              {
                  "id": "proj_abc",
                  "object": "organization.project",
                  "name": "Project ABC",
                  "created_at": 1711471533,
                  "archived_at": null,
                  "status": "active"
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/projects/{project_id}:
    get:
      operationId: retrieve-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
          description: Project retrieved successfully.
      summary: Retrieves a project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project
        group: administration
        description: Retrieve a project.
        returns: "The [Project](/docs/api-reference/projects/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "id": "proj_abc",
                  "object": "organization.project",
                  "name": "Project example",
                  "created_at": 1711471533,
                  "archived_at": null,
                  "status": "active"
              }
      x-accepts:
      - application/json
    post:
      operationId: modify-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUpdateRequest'
        description: The project update request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
          description: Project updated successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response when updating the default project.
      summary: Modifies a project in the organization.
      tags:
      - Projects
      x-oaiMeta:
        name: Modify project
        group: administration
        returns: "The updated [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Project DEF"
                }'
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/projects/{project_id}/api_keys:
    get:
      operationId: list-project-api-keys
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyListResponse'
          description: Project API keys listed successfully.
      summary: Returns a list of API keys in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project API keys
        group: administration
        returns: "A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "list",
                  "data": [
                      {
                          "object": "organization.project.api_key",
                          "redacted_value": "sk-abc...def",
                          "name": "My API Key",
                          "created_at": 1711471533,
                          "id": "key_abc",
                          "owner": {
                              "type": "user",
                              "user": {
                                  "object": "organization.project.user",
                                  "id": "user_abc",
                                  "name": "First Last",
                                  "email": "user@example.com",
                                  "role": "owner",
                                  "added_at": 1711471533
                              }
                          }
                      }
                  ],
                  "first_id": "key_abc",
                  "last_id": "key_xyz",
                  "has_more": false
              }
          error_response:
            content: |
              {
                  "code": 400,
                  "message": "Project {name} is archived"
              }
      x-accepts:
      - application/json
  /organization/projects/{project_id}/api_keys/{key_id}:
    delete:
      operationId: delete-project-api-key
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the API key.
        explode: false
        in: path
        name: key_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKeyDeleteResponse'
          description: Project API key deleted successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response for various conditions.
      summary: Deletes an API key from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project API key
        group: administration
        returns: Confirmation of the key's deletion or an error if the key belonged
          to a service account
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.api_key.deleted",
                  "id": "key_abc",
                  "deleted": true
              }
          error_response:
            content: |
              {
                  "code": 400,
                  "message": "API keys cannot be deleted for service accounts, please delete the service account"
              }
      x-accepts:
      - application/json
    get:
      operationId: retrieve-project-api-key
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the API key.
        explode: false
        in: path
        name: key_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectApiKey'
          description: Project API key retrieved successfully.
      summary: Retrieves an API key in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project API key
        group: administration
        returns: "The [ProjectApiKey](/docs/api-reference/project-api-keys/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.api_key",
                  "redacted_value": "sk-abc...def",
                  "name": "My API Key",
                  "created_at": 1711471533,
                  "id": "key_abc",
                  "owner": {
                      "type": "user",
                      "user": {
                          "object": "organization.project.user",
                          "id": "user_abc",
                          "name": "First Last",
                          "email": "user@example.com",
                          "role": "owner",
                          "added_at": 1711471533
                      }
                  }
              }
      x-accepts:
      - application/json
  /organization/projects/{project_id}/archive:
    post:
      operationId: archive-project
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
          description: Project archived successfully.
      summary: Archives a project in the organization. Archived projects cannot be
        used or updated.
      tags:
      - Projects
      x-oaiMeta:
        name: Archive project
        group: administration
        returns: "The archived [Project](/docs/api-reference/projects/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "id": "proj_abc",
                  "object": "organization.project",
                  "name": "Project DEF",
                  "created_at": 1711471533,
                  "archived_at": 1711471533,
                  "status": "archived"
              }
      x-accepts:
      - application/json
  /organization/projects/{project_id}/service_accounts:
    get:
      operationId: list-project-service-accounts
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountListResponse'
          description: Project service accounts listed successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response when project is archived.
      summary: Returns a list of service accounts in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project service accounts
        group: administration
        returns: "A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "list",
                  "data": [
                      {
                          "object": "organization.project.service_account",
                          "id": "svc_acct_abc",
                          "name": "Service Account",
                          "role": "owner",
                          "created_at": 1711471533
                      }
                  ],
                  "first_id": "svc_acct_abc",
                  "last_id": "svc_acct_xyz",
                  "has_more": false
              }
      x-accepts:
      - application/json
    post:
      operationId: create-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectServiceAccountCreateRequest'
        description: The project service account create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountCreateResponse'
          description: Project service account created successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response when project is archived.
      summary: Creates a new service account in the project. This also returns an
        unredacted API key for the service account.
      tags:
      - Projects
      x-oaiMeta:
        name: Create project service account
        group: administration
        returns: "The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "name": "Production App"
                }'
          response:
            content: |
              {
                  "object": "organization.project.service_account",
                  "id": "svc_acct_abc",
                  "name": "Production App",
                  "role": "member",
                  "created_at": 1711471533,
                  "api_key": {
                      "object": "organization.project.service_account.api_key",
                      "value": "sk-abcdefghijklmnop123",
                      "name": "Secret Key",
                      "created_at": 1711471533,
                      "id": "key_abc"
                  }
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/projects/{project_id}/service_accounts/{service_account_id}:
    delete:
      operationId: delete-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the service account.
        explode: false
        in: path
        name: service_account_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccountDeleteResponse'
          description: Project service account deleted successfully.
      summary: Deletes a service account from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project service account
        group: administration
        returns: "Confirmation of service account being deleted, or an error in case\
          \ of an archived project, which has no service accounts"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.service_account.deleted",
                  "id": "svc_acct_abc",
                  "deleted": true
              }
      x-accepts:
      - application/json
    get:
      operationId: retrieve-project-service-account
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the service account.
        explode: false
        in: path
        name: service_account_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectServiceAccount'
          description: Project service account retrieved successfully.
      summary: Retrieves a service account in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project service account
        group: administration
        returns: "The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object)\
          \ object matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.service_account",
                  "id": "svc_acct_abc",
                  "name": "Service Account",
                  "role": "owner",
                  "created_at": 1711471533
              }
      x-accepts:
      - application/json
  /organization/projects/{project_id}/users:
    get:
      operationId: list-project-users
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserListResponse'
          description: Project users listed successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response when project is archived.
      summary: Returns a list of users in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: List project users
        group: administration
        returns: "A list of [ProjectUser](/docs/api-reference/project-users/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "list",
                  "data": [
                      {
                          "object": "organization.project.user",
                          "id": "user_abc",
                          "name": "First Last",
                          "email": "user@example.com",
                          "role": "owner",
                          "added_at": 1711471533
                      }
                  ],
                  "first_id": "user-abc",
                  "last_id": "user-xyz",
                  "has_more": false
              }
          error_response:
            content: |
              {
                  "code": 400,
                  "message": "Project {name} is archived"
              }
      x-accepts:
      - application/json
    post:
      operationId: create-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserCreateRequest'
        description: The project user create request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
          description: User added to project successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response for various conditions.
      summary: Adds a user to the project. Users must already be members of the organization
        to be added to a project.
      tags:
      - Projects
      x-oaiMeta:
        name: Create project user
        group: administration
        returns: "The created [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "user_id": "user_abc",
                    "role": "member"
                }'
          response:
            content: |
              {
                  "object": "organization.project.user",
                  "id": "user_abc",
                  "email": "user@example.com",
                  "role": "owner",
                  "added_at": 1711471533
              }
          error_response:
            content: |
              {
                  "code": 400,
                  "message": "Project {name} is archived"
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/projects/{project_id}/users/{user_id}:
    delete:
      operationId: delete-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUserDeleteResponse'
          description: Project user deleted successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response for various conditions.
      summary: Deletes a user from the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Delete project user
        group: administration
        returns: "Confirmation that project has been deleted or an error in case of\
          \ an archived project, which has no users"
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.user.deleted",
                  "id": "user_abc",
                  "deleted": true
              }
      x-accepts:
      - application/json
    get:
      operationId: retrieve-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
          description: Project user retrieved successfully.
      summary: Retrieves a user in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Retrieve project user
        group: administration
        returns: "The [ProjectUser](/docs/api-reference/project-users/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.project.user",
                  "id": "user_abc",
                  "name": "First Last",
                  "email": "user@example.com",
                  "role": "owner",
                  "added_at": 1711471533
              }
      x-accepts:
      - application/json
    post:
      operationId: modify-project-user
      parameters:
      - description: The ID of the project.
        explode: false
        in: path
        name: project_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUserUpdateRequest'
        description: The project user update request payload.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ProjectUser'
          description: Project user's role updated successfully.
        "400":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
          description: Error response for various conditions.
      summary: Modifies a user's role in the project.
      tags:
      - Projects
      x-oaiMeta:
        name: Modify project user
        group: administration
        returns: "The updated [ProjectUser](/docs/api-reference/project-users/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response:
            content: |
              {
                  "object": "organization.project.user",
                  "id": "user_abc",
                  "name": "First Last",
                  "email": "user@example.com",
                  "role": "owner",
                  "added_at": 1711471533
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /organization/users:
    get:
      operationId: list-users
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserListResponse'
          description: Users listed successfully.
      summary: Lists all of the users in the organization.
      tags:
      - Users
      x-oaiMeta:
        name: List users
        group: administration
        returns: "A list of [User](/docs/api-reference/users/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "list",
                  "data": [
                      {
                          "object": "organization.user",
                          "id": "user_abc",
                          "name": "First Last",
                          "email": "user@example.com",
                          "role": "owner",
                          "added_at": 1711471533
                      }
                  ],
                  "first_id": "user-abc",
                  "last_id": "user-xyz",
                  "has_more": false
              }
      x-accepts:
      - application/json
  /organization/users/{user_id}:
    delete:
      operationId: delete-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UserDeleteResponse'
          description: User deleted successfully.
      summary: Deletes a user from the organization.
      tags:
      - Users
      x-oaiMeta:
        name: Delete user
        group: administration
        returns: Confirmation of the deleted user
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.user.deleted",
                  "id": "user_abc",
                  "deleted": true
              }
      x-accepts:
      - application/json
    get:
      operationId: retrieve-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
          description: User retrieved successfully.
      summary: Retrieves a user by their identifier.
      tags:
      - Users
      x-oaiMeta:
        name: Retrieve user
        group: administration
        returns: "The [User](/docs/api-reference/users/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json"
          response:
            content: |
              {
                  "object": "organization.user",
                  "id": "user_abc",
                  "name": "First Last",
                  "email": "user@example.com",
                  "role": "owner",
                  "added_at": 1711471533
              }
      x-accepts:
      - application/json
    post:
      operationId: modify-user
      parameters:
      - description: The ID of the user.
        explode: false
        in: path
        name: user_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserRoleUpdateRequest'
        description: The new user role to modify. This must be one of `owner` or `member`.
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
          description: User role updated successfully.
      summary: Modifies a user's role in the organization.
      tags:
      - Users
      x-oaiMeta:
        name: Modify user
        group: administration
        returns: "The updated [User](/docs/api-reference/users/object) object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/organization/users/user_abc \
                -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                    "role": "owner"
                }'
          response:
            content: |
              {
                  "object": "organization.user",
                  "id": "user_abc",
                  "name": "First Last",
                  "email": "user@example.com",
                  "role": "owner",
                  "added_at": 1711471533
              }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads:
    post:
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Create a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: "A [thread](/docs/api-reference/threads) object."
        examples:
        - title: Empty
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d ''
            python: |
              from openai import OpenAI
              client = OpenAI()

              empty_thread = client.beta.threads.create()
              print(empty_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const emptyThread = await openai.beta.threads.create();

                console.log(emptyThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699012949,
              "metadata": {},
              "tool_resources": {}
            }
        - title: Messages
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "OpenAI-Beta: assistants=v2" \
              -d '{
                  "messages": [{
                    "role": "user",
                    "content": "Hello, what is AI?"
                  }, {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message_thread = client.beta.threads.create(
                messages=[
                  {
                    "role": "user",
                    "content": "Hello, what is AI?"
                  },
                  {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  },
                ]
              )

              print(message_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messageThread = await openai.beta.threads.create({
                  messages: [
                    {
                      role: "user",
                      content: "Hello, what is AI?"
                    },
                    {
                      role: "user",
                      content: "How does AI work? Explain it in simple terms.",
                    },
                  ],
                });

                console.log(messageThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {}
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/runs:
    post:
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Create a thread and run it in one request.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Explain deep learning to a 5 year old."}
                      ]
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.create_and_run(
                assistant_id="asst_abc123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Explain deep learning to a 5 year old."}
                  ]
                }
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_abc123",
                  thread: {
                    messages: [
                      { role: "user", content: "Explain deep learning to a 5 year old." },
                    ],
                  },
                });

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076792,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": null,
              "expires_at": 1699077392,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "required_action": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You are a helpful assistant.",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "temperature": 1.0,
              "top_p": 1.0,
              "max_completion_tokens": null,
              "max_prompt_tokens": null,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "incomplete_details": null,
              "usage": null,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "Hello"}
                    ]
                  },
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.create_and_run(
                assistant_id="asst_123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Hello"}
                  ]
                },
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_123",
                    thread: {
                      messages: [
                        { role: "user", content: "Hello" },
                      ],
                    },
                    stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}], "metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                  },
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.create_and_run(
                thread={
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                },
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_123",
                  thread: {
                    messages: [
                      { role: "user", content: "What is the weather like in San Francisco?" },
                    ],
                  },
                  tools: tools,
                  stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}

            ...

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}

            event: thread.run.requires_action
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}:
    delete:
      operationId: deleteThread
      parameters:
      - description: The ID of the thread to delete.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
          description: OK
      summary: Delete a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.threads.delete("thread_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.threads.del("thread_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
      x-accepts:
      - application/json
    get:
      operationId: getThread
      parameters:
      - description: The ID of the thread to retrieve.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Retrieves a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: "The [thread](/docs/api-reference/threads/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_thread = client.beta.threads.retrieve("thread_abc123")
              print(my_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myThread = await openai.beta.threads.retrieve(
                  "thread_abc123"
                );

                console.log(myThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
      x-accepts:
      - application/json
    post:
      operationId: modifyThread
      parameters:
      - description: The ID of the thread to modify. Only the `metadata` can be modified.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Modifies a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: "The modified [thread](/docs/api-reference/threads/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_thread = client.beta.threads.update(
                "thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123"
                }
              )
              print(my_updated_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const updatedThread = await openai.beta.threads.update(
                  "thread_abc123",
                  {
                    metadata: { modified: "true", user: "abc123" },
                  }
                );

                console.log(updatedThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}/messages:
    get:
      operationId: listMessages
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) the messages\
          \ belong to."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: |
          Filter messages by the run ID that generated them.
        explode: true
        in: query
        name: run_id
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
          description: OK
      summary: Returns a list of messages for a given thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: "A list of [message](/docs/api-reference/messages) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_messages = client.beta.threads.messages.list("thread_abc123")
              print(thread_messages.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.list(
                  "thread_abc123"
                );

                console.log(threadMessages.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
    post:
      operationId: createMessage
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to create\
          \ a message for."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Create a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: "A [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_message = client.beta.threads.messages.create(
                "thread_abc123",
                role="user",
                content="How does AI work? Explain it in simple terms.",
              )
              print(thread_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.create(
                  "thread_abc123",
                  { role: "user", content: "How does AI work? Explain it in simple terms." }
                );

                console.log(threadMessages);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}/messages/{message_id}:
    delete:
      operationId: deleteMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to delete.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
          description: OK
      summary: Deletes a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_message = client.beta.threads.messages.delete(
                message_id="msg_abc12",
                thread_id="thread_abc123",
              )
              print(deleted_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const deletedMessage = await openai.beta.threads.messages.del(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(deletedMessage);
              }
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
      x-accepts:
      - application/json
    get:
      operationId: getMessage
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this message belongs."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to retrieve.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Retrieve a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: "The [message](/docs/api-reference/messages/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.retrieve(
                message_id="msg_abc123",
                thread_id="thread_abc123",
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.retrieve(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(message);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
      x-accepts:
      - application/json
    post:
      operationId: modifyMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the message to modify.
        explode: false
        in: path
        name: message_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Modifies a message.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: "The modified [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.update(
                message_id="msg_abc12",
                thread_id="thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123",
                },
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.update(
                  "thread_abc123",
                  "msg_abc123",
                  {
                    metadata: {
                      modified: "true",
                      user: "abc123",
                    },
                  }
                }'
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}/runs:
    get:
      operationId: listRuns
      parameters:
      - description: The ID of the thread the run belongs to.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
          description: OK
      summary: Returns a list of runs belonging to a thread.
      tags:
      - Assistants
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: "A list of [run](/docs/api-reference/runs/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.beta.threads.runs.list(
                "thread_abc123"
              )

              print(runs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const runs = await openai.beta.threads.runs.list(
                  "thread_abc123"
                );

                console.log(runs);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4o",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
    post:
      operationId: createRun
      parameters:
      - description: The ID of the thread to run.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search/customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Create a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  { assistant_id: "asst_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699063290,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": 1699063290,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699063291,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.create(
                thread_id="thread_123",
                assistant_id="asst_123",
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_123",
                  { assistant_id: "asst_123", stream: true }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  {
                    assistant_id: "asst_abc123",
                    tools: tools,
                    stream: true
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to retrieve.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Retrieves a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: "The [run](/docs/api-reference/runs/object) object matching the specified\
          \ ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.retrieve(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.retrieve(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
      x-accepts:
      - application/json
    post:
      operationId: modifyRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to modify.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Modifies a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.update(
                thread_id="thread_abc123",
                run_id="run_abc123",
                metadata={"user_id": "user_abc123"},
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.update(
                  "thread_abc123",
                  "run_abc123",
                  {
                    metadata: {
                      user_id: "user_abc123",
                    },
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelRun
      parameters:
      - description: The ID of the thread to which this run belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to cancel.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Cancels a run that is `in_progress`.
      tags:
      - Assistants
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.cancel(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.cancel(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
      x-accepts:
      - application/json
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listRunSteps
      parameters:
      - description: The ID of the thread the run and run steps belong to.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run the run steps belong to.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search/customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
          description: OK
      summary: Returns a list of run steps belonging to a run.
      tags:
      - Assistants
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: "A list of [run step](/docs/api-reference/run-steps/step-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_steps = client.beta.threads.runs.steps.list(
                  thread_id="thread_abc123",
                  run_id="run_abc123"
              )

              print(run_steps)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.list(
                  "thread_abc123",
                  "run_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getRunStep
      parameters:
      - description: The ID of the thread to which the run and run step belongs.
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run to which the run step belongs.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run step to retrieve.
        explode: false
        in: path
        name: step_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

          See the [file search tool documentation](/docs/assistants/tools/file-search/customizing-file-search-settings) for more information.
        explode: true
        in: query
        name: "include[]"
        required: false
        schema:
          items:
            enum:
            - "step_details.tool_calls[*].file_search.results[*].content"
            type: string
          type: array
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
          description: OK
      summary: Retrieves a run step.
      tags:
      - Assistants
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: "The [run step](/docs/api-reference/run-steps/step-object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_step = client.beta.threads.runs.steps.retrieve(
                  thread_id="thread_abc123",
                  run_id="run_abc123",
                  step_id="step_abc123"
              )

              print(run_step)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.retrieve(
                  "thread_abc123",
                  "run_abc123",
                  "step_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
      x-accepts:
      - application/json
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitToolOuputsToRun
      parameters:
      - description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this run belongs."
        explode: false
        in: path
        name: thread_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the run that requires the tool output submission.
        explode: false
        in: path
        name: run_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      tags:
      - Assistants
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ]
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_123",
              "object": "thread.run",
              "created_at": 1699075592,
              "assistant_id": "asst_123",
              "thread_id": "thread_123",
              "status": "queued",
              "started_at": 1699075592,
              "expires_at": 1699076192,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4o",
              "instructions": null,
              "tools": [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location"]
                    }
                  }
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ],
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" current"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" weather"}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" sunny"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}

            event: thread.message.completed
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4o","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
      x-content-type: application/json
      x-accepts:
      - application/json
  /uploads:
    post:
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
          description: OK
      summary: |
        Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

        Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

        For certain `purpose`s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:
        - [Assistants](/docs/assistants/tools/file-search/supported-files)

        For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).
      tags:
      - Uploads
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `pending`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "purpose": "fine-tune",
                  "filename": "training_examples.jsonl",
                  "bytes": 2147483648,
                  "mime_type": "text/jsonl"
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "pending",
              "expires_at": 1719127296
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /uploads/{upload_id}/cancel:
    post:
      operationId: cancelUpload
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
          description: OK
      summary: |
        Cancels the Upload. No Parts may be added after an Upload is cancelled.
      tags:
      - Uploads
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `cancelled`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/cancel
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "cancelled",
              "expires_at": 1719127296
            }
      x-accepts:
      - application/json
  /uploads/{upload_id}/complete:
    post:
      operationId: completeUpload
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
          description: OK
      summary: "Completes the [Upload](/docs/api-reference/uploads/object). \n\nWithin\
        \ the returned Upload object, there is a nested [File](/docs/api-reference/files/object)\
        \ object that is ready to use in the rest of the platform.\n\nYou can specify\
        \ the order of the Parts by passing in an ordered list of the Part IDs.\n\n\
        The number of bytes uploaded upon completion must match the number of bytes\
        \ initially specified when creating the Upload object. No Parts may be added\
        \ after an Upload is completed.\n"
      tags:
      - Uploads
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `completed` with an additional `file` property containing the created\
          \ usable File object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/complete
                -d '{
                  "part_ids": ["part_def456", "part_ghi789"]
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "completed",
              "expires_at": 1719127296,
              "file": {
                "id": "file-xyz321",
                "object": "file",
                "bytes": 2147483648,
                "created_at": 1719186911,
                "filename": "training_examples.jsonl",
                "purpose": "fine-tune",
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /uploads/{upload_id}/parts:
    post:
      operationId: addUploadPart
      parameters:
      - description: |
          The ID of the Upload.
        explode: false
        in: path
        name: upload_id
        required: true
        schema:
          example: upload_abc123
          type: string
        style: simple
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
          description: OK
      summary: "Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object)\
        \ object. A Part represents a chunk of bytes from the file you are trying\
        \ to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until\
        \ you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts\
        \ in parallel. You can decide the intended order of the Parts when you [complete\
        \ the Upload](/docs/api-reference/uploads/complete).\n"
      tags:
      - Uploads
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: "The upload [Part](/docs/api-reference/uploads/part-object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/parts
                -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
          response: |
            {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719185911,
              "upload_id": "upload_abc123"
            }
      x-content-type: multipart/form-data
      x-accepts:
      - application/json
  /vector_stores:
    get:
      operationId: listVectorStores
      parameters:
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
          description: OK
      summary: Returns a list of vector stores.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        beta: true
        returns: "A list of [vector store](/docs/api-reference/vector-stores/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_stores = client.beta.vector_stores.list()
              print(vector_stores)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStores = await openai.beta.vectorStores.list();
                console.log(vectorStores);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
    post:
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Create a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        beta: true
        returns: "A [vector store](/docs/api-reference/vector-stores/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.create(
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.create({
                  name: "Support FAQ"
                });
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}:
    delete:
      operationId: deleteVectorStore
      parameters:
      - description: The ID of the vector store to delete.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
          description: OK
      summary: Delete a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store = client.beta.vector_stores.delete(
                vector_store_id="vs_abc123"
              )
              print(deleted_vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStore = await openai.beta.vectorStores.del(
                  "vs_abc123"
                );
                console.log(deletedVectorStore);
              }

              main();
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
      x-accepts:
      - application/json
    get:
      operationId: getVectorStore
      parameters:
      - description: The ID of the vector store to retrieve.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Retrieves a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        beta: true
        returns: "The [vector store](/docs/api-reference/vector-stores/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.retrieve(
                vector_store_id="vs_abc123"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.retrieve(
                  "vs_abc123"
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
      x-accepts:
      - application/json
    post:
      operationId: modifyVectorStore
      parameters:
      - description: The ID of the vector store to modify.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Modifies a vector store.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        beta: true
        returns: "The modified [vector store](/docs/api-reference/vector-stores/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.update(
                vector_store_id="vs_abc123",
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.update(
                  "vs_abc123",
                  {
                    name: "Support FAQ"
                  }
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/file_batches:
    post:
      operationId: createVectorStoreFileBatch
      parameters:
      - description: |
          The ID of the vector store for which to create a File Batch.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Create a vector store file batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        beta: true
        returns: "A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_ids": ["file-abc123", "file-abc456"]
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.beta.vector_stores.file_batches.create(
                vector_store_id="vs_abc123",
                file_ids=["file-abc123", "file-abc456"]
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.create(
                  "vs_abc123",
                  {
                    file_ids: ["file-abc123", "file-abc456"]
                  }
                );
                console.log(myVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/file_batches/{batch_id}:
    get:
      operationId: getVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file batch being retrieved.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          example: vsfb_abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Retrieves a vector store file batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        beta: true
        returns: "The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.beta.vector_stores.file_batches.retrieve(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.retrieve(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel:
    post:
      operationId: cancelVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file batch to cancel.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        beta: true
        returns: The modified vector store file batch object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file_batch = client.beta.vector_stores.file_batches.cancel(
                  vector_store_id="vs_abc123",
                  file_batch_id="vsfb_abc123"
              )
              print(deleted_vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFileBatch = await openai.vector_stores.fileBatches.cancel(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(deletedVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "cancelling",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/files:
    get:
      operationId: listFilesInVectorStoreBatch
      parameters:
      - description: The ID of the vector store that the files belong to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file batch that the files belong to.
        explode: false
        in: path
        name: batch_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`."
        explode: true
        in: query
        name: filter
        required: false
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
          description: OK
      summary: Returns a list of vector store files in a batch.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        beta: true
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.beta.vector_stores.file_batches.list_files(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.fileBatches.listFiles(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/files:
    get:
      operationId: listVectorStoreFiles
      parameters:
      - description: The ID of the vector store that the files belong to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.
        explode: true
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
        style: form
      - description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.
        explode: true
        in: query
        name: order
        required: false
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
        explode: true
        in: query
        name: after
        required: false
        schema:
          type: string
        style: form
      - description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.
        explode: true
        in: query
        name: before
        required: false
        schema:
          type: string
        style: form
      - description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`."
        explode: true
        in: query
        name: filter
        required: false
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
        style: form
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
          description: OK
      summary: Returns a list of vector store files.
      tags:
      - Vector stores
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        beta: true
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.beta.vector_stores.files.list(
                vector_store_id="vs_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.files.list(
                  "vs_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
      x-accepts:
      - application/json
    post:
      operationId: createVectorStoreFile
      parameters:
      - description: |
          The ID of the vector store for which to create a File.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
          description: OK
      summary: "Create a vector store file by attaching a [File](/docs/api-reference/files)\
        \ to a [vector store](/docs/api-reference/vector-stores/object)."
      tags:
      - Vector stores
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        beta: true
        returns: "A [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.create(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFile = await openai.beta.vectorStores.files.create(
                  "vs_abc123",
                  {
                    file_id: "file-abc123"
                  }
                );
                console.log(myVectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /vector_stores/{vector_store_id}/files/{file_id}:
    delete:
      operationId: deleteVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
        style: simple
      - description: The ID of the file to delete.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
          description: OK
      summary: "Delete a vector store file. This will remove the file from the vector\
        \ store but the file itself will not be deleted. To delete the file, use the\
        \ [delete file](/docs/api-reference/files/delete) endpoint."
      tags:
      - Vector stores
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file = client.beta.vector_stores.files.delete(
                  vector_store_id="vs_abc123",
                  file_id="file-abc123"
              )
              print(deleted_vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFile = await openai.beta.vectorStores.files.del(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(deletedVectorStoreFile);
              }

              main();
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
      x-accepts:
      - application/json
    get:
      operationId: getVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        explode: false
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
        style: simple
      - description: The ID of the file being retrieved.
        explode: false
        in: path
        name: file_id
        required: true
        schema:
          example: file-abc123
          type: string
        style: simple
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
          description: OK
      summary: Retrieves a vector store file.
      tags:
      - Vector stores
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        beta: true
        returns: "The [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.retrieve(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFile = await openai.beta.vectorStores.files.retrieve(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(vectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
      x-accepts:
      - application/json
components:
  schemas:
    AddUploadPartRequest:
      additionalProperties: false
      properties:
        data:
          description: |
            The chunk of bytes for this Part.
          format: binary
          type: string
      required:
      - data
      type: object
    AssistantObject:
      description: Represents an `assistant` that can call the model and use tools.
      example:
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata: "{}"
        created_at: 0
        description: description
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        top_p: 1
        response_format: auto
        name: name
        temperature: 1
        model: model
        id: id
        object: assistant
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `assistant`."
          enum:
          - assistant
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was
            created.
          type: integer
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: '#/components/schemas/AssistantObject_tools_inner'
          maxItems: 128
          type: array
        tool_resources:
          $ref: '#/components/schemas/AssistantObject_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      required:
      - created_at
      - description
      - id
      - instructions
      - metadata
      - model
      - name
      - object
      - tools
      title: Assistant
      type: object
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: |
          {
            "id": "asst_abc123",
            "object": "assistant",
            "created_at": 1698984975,
            "name": "Math Tutor",
            "description": null,
            "model": "gpt-4o",
            "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
            "tools": [
              {
                "type": "code_interpreter"
              }
            ],
            "metadata": {},
            "top_p": 1.0,
            "temperature": 1.0,
            "response_format": "auto"
          }
    AssistantStreamEvent:
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming.
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEvent'
      - $ref: '#/components/schemas/RunStreamEvent'
      - $ref: '#/components/schemas/RunStepStreamEvent'
      - $ref: '#/components/schemas/MessageStreamEvent'
      - $ref: '#/components/schemas/ErrorEvent'
      - $ref: '#/components/schemas/DoneEvent'
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    AssistantToolsCode:
      example:
        type: code_interpreter
      properties:
        type:
          description: "The type of tool being defined: `code_interpreter`"
          enum:
          - code_interpreter
          type: string
      required:
      - type
      title: Code interpreter tool
      type: object
    AssistantToolsFileSearch:
      properties:
        type:
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          type: string
        file_search:
          $ref: '#/components/schemas/AssistantToolsFileSearch_file_search'
      required:
      - type
      title: FileSearch tool
      type: object
    AssistantToolsFileSearchTypeOnly:
      properties:
        type:
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          type: string
      required:
      - type
      title: FileSearch tool
      type: object
    AssistantToolsFunction:
      properties:
        type:
          description: "The type of tool being defined: `function`"
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/FunctionObject'
      required:
      - function
      - type
      title: Function tool
      type: object
    AssistantsApiResponseFormatOption:
      description: |
        Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models/gpt-4o), [GPT-4 Turbo](/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

        Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
      oneOf:
      - description: |
          `auto` is the default value
        enum:
        - auto
        type: string
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
      - $ref: '#/components/schemas/ResponseFormatJsonSchema'
      x-oaiExpandable: true
    AssistantsApiToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tools and instead generates a message.
        `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools before responding to the user.
        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
      oneOf:
      - description: |
          `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: '#/components/schemas/AssistantsNamedToolChoice'
      x-oaiExpandable: true
    AssistantsNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool.
      properties:
        type:
          description: "The type of the tool. If type is `function`, the function\
            \ name must be set"
          enum:
          - function
          - code_interpreter
          - file_search
          type: string
        function:
          $ref: '#/components/schemas/AssistantsNamedToolChoice_function'
      required:
      - type
      type: object
    AudioResponseFormat:
      default: json
      description: |
        The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.
      enum:
      - json
      - text
      - srt
      - verbose_json
      - vtt
      type: string
    AuditLog:
      description: A log of a user action or configuration change within this organization.
      example:
        user.updated:
          changes_requested:
            role: role
          id: id
        organization.updated:
          changes_requested:
            settings:
              threads_ui_visibility: threads_ui_visibility
              usage_dashboard_visibility: usage_dashboard_visibility
            name: name
            description: description
            title: title
          id: id
        project.updated:
          changes_requested:
            title: title
          id: id
        project.archived:
          id: id
        project:
          name: name
          id: id
        service_account.deleted:
          id: id
        type: api_key.created
        logout.failed:
          error_message: error_message
          error_code: error_code
        login.failed:
          error_message: error_message
          error_code: error_code
        user.added:
          data:
            role: role
          id: id
        invite.accepted:
          id: id
        invite.deleted:
          id: id
        actor:
          api_key:
            service_account:
              id: id
            id: id
            type: user
            user:
              id: id
              email: email
          session:
            ip_address: ip_address
            user:
              id: id
              email: email
          type: session
        effective_at: 0
        invite.sent:
          data:
            role: role
            email: email
          id: id
        service_account.updated:
          changes_requested:
            role: role
          id: id
        service_account.created:
          data:
            role: role
          id: id
        api_key.created:
          data:
            scopes:
            - scopes
            - scopes
          id: id
        user.deleted:
          id: id
        id: id
        api_key.deleted:
          id: id
        project.created:
          data:
            name: name
            title: title
          id: id
        api_key.updated:
          changes_requested:
            scopes:
            - scopes
            - scopes
          id: id
      properties:
        id:
          description: The ID of this log.
          type: string
        type:
          $ref: '#/components/schemas/AuditLogEventType'
        effective_at:
          description: The Unix timestamp (in seconds) of the event.
          type: integer
        project:
          $ref: '#/components/schemas/AuditLog_project'
        actor:
          $ref: '#/components/schemas/AuditLogActor'
        api_key.created:
          $ref: '#/components/schemas/AuditLog_api_key_created'
        api_key.updated:
          $ref: '#/components/schemas/AuditLog_api_key_updated'
        api_key.deleted:
          $ref: '#/components/schemas/AuditLog_api_key_deleted'
        invite.sent:
          $ref: '#/components/schemas/AuditLog_invite_sent'
        invite.accepted:
          $ref: '#/components/schemas/AuditLog_invite_accepted'
        invite.deleted:
          $ref: '#/components/schemas/AuditLog_invite_accepted'
        login.failed:
          $ref: '#/components/schemas/AuditLog_login_failed'
        logout.failed:
          $ref: '#/components/schemas/AuditLog_login_failed'
        organization.updated:
          $ref: '#/components/schemas/AuditLog_organization_updated'
        project.created:
          $ref: '#/components/schemas/AuditLog_project_created'
        project.updated:
          $ref: '#/components/schemas/AuditLog_project_updated'
        project.archived:
          $ref: '#/components/schemas/AuditLog_project_archived'
        service_account.created:
          $ref: '#/components/schemas/AuditLog_service_account_created'
        service_account.updated:
          $ref: '#/components/schemas/AuditLog_service_account_updated'
        service_account.deleted:
          $ref: '#/components/schemas/AuditLog_service_account_deleted'
        user.added:
          $ref: '#/components/schemas/AuditLog_user_added'
        user.updated:
          $ref: '#/components/schemas/AuditLog_user_updated'
        user.deleted:
          $ref: '#/components/schemas/AuditLog_user_deleted'
      required:
      - actor
      - effective_at
      - id
      - type
      type: object
      x-oaiMeta:
        name: The audit log object
        example: |
          {
              "id": "req_xxx_20240101",
              "type": "api_key.created",
              "effective_at": 1720804090,
              "actor": {
                  "type": "session",
                  "session": {
                      "user": {
                          "id": "user-xxx",
                          "email": "user@example.com"
                      },
                      "ip_address": "127.0.0.1",
                      "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                  }
              },
              "api_key.created": {
                  "id": "key_xxxx",
                  "data": {
                      "scopes": ["resource.operation"]
                  }
              }
          }
    AuditLogActor:
      description: The actor who performed the audit logged action.
      example:
        api_key:
          service_account:
            id: id
          id: id
          type: user
          user:
            id: id
            email: email
        session:
          ip_address: ip_address
          user:
            id: id
            email: email
        type: session
      properties:
        type:
          description: The type of actor. Is either `session` or `api_key`.
          enum:
          - session
          - api_key
          type: string
        session:
          $ref: '#/components/schemas/AuditLogActorSession'
        api_key:
          $ref: '#/components/schemas/AuditLogActorApiKey'
      type: object
    AuditLogActorApiKey:
      description: The API Key used to perform the audit logged action.
      example:
        service_account:
          id: id
        id: id
        type: user
        user:
          id: id
          email: email
      properties:
        id:
          description: The tracking id of the API key.
          type: string
        type:
          description: The type of API key. Can be either `user` or `service_account`.
          enum:
          - user
          - service_account
          type: string
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
        service_account:
          $ref: '#/components/schemas/AuditLogActorServiceAccount'
      type: object
    AuditLogActorServiceAccount:
      description: The service account that performed the audit logged action.
      example:
        id: id
      properties:
        id:
          description: The service account id.
          type: string
      type: object
    AuditLogActorSession:
      description: The session in which the audit logged action was performed.
      example:
        ip_address: ip_address
        user:
          id: id
          email: email
      properties:
        user:
          $ref: '#/components/schemas/AuditLogActorUser'
        ip_address:
          description: The IP address from which the action was performed.
          type: string
      type: object
    AuditLogActorUser:
      description: The user who performed the audit logged action.
      example:
        id: id
        email: email
      properties:
        id:
          description: The user id.
          type: string
        email:
          description: The user email.
          type: string
      type: object
    AuditLogEventType:
      description: The event type.
      enum:
      - api_key.created
      - api_key.updated
      - api_key.deleted
      - invite.sent
      - invite.accepted
      - invite.deleted
      - login.succeeded
      - login.failed
      - logout.succeeded
      - logout.failed
      - organization.updated
      - project.created
      - project.updated
      - project.archived
      - service_account.created
      - service_account.updated
      - service_account.deleted
      - user.added
      - user.updated
      - user.deleted
      type: string
      x-oaiExpandable: true
    AutoChunkingStrategyRequestParam:
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`.
      example:
        type: auto
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          type: string
      required:
      - type
      title: Auto Chunking Strategy
      type: object
    Batch:
      example:
        cancelled_at: 2
        metadata: "{}"
        request_counts:
          total: 4
          completed: 7
          failed: 1
        input_file_id: input_file_id
        output_file_id: output_file_id
        error_file_id: error_file_id
        created_at: 6
        in_progress_at: 1
        expired_at: 9
        finalizing_at: 5
        completed_at: 2
        endpoint: endpoint
        expires_at: 5
        cancelling_at: 3
        completion_window: completion_window
        id: id
        failed_at: 7
        errors:
          data:
          - code: code
            param: param
            line: 0
            message: message
          - code: code
            param: param
            line: 0
            message: message
          object: object
        object: batch
        status: validating
      properties:
        id:
          type: string
        object:
          description: "The object type, which is always `batch`."
          enum:
          - batch
          type: string
        endpoint:
          description: The OpenAI API endpoint used by the batch.
          type: string
        errors:
          $ref: '#/components/schemas/Batch_errors'
        input_file_id:
          description: The ID of the input file for the batch.
          type: string
        completion_window:
          description: The time frame within which the batch should be processed.
          type: string
        status:
          description: The current status of the batch.
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
          type: string
        output_file_id:
          description: The ID of the file containing the outputs of successfully executed
            requests.
          type: string
        error_file_id:
          description: The ID of the file containing the outputs of requests with
            errors.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the batch was created.
          type: integer
        in_progress_at:
          description: The Unix timestamp (in seconds) for when the batch started
            processing.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the batch will expire.
          type: integer
        finalizing_at:
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing.
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the batch was completed.
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the batch failed.
          type: integer
        expired_at:
          description: The Unix timestamp (in seconds) for when the batch expired.
          type: integer
        cancelling_at:
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling.
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
          type: integer
        request_counts:
          $ref: '#/components/schemas/Batch_request_counts'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - completion_window
      - created_at
      - endpoint
      - id
      - input_file_id
      - object
      - status
      type: object
      x-oaiMeta:
        name: The batch object
        example: |
          {
            "id": "batch_abc123",
            "object": "batch",
            "endpoint": "/v1/completions",
            "errors": null,
            "input_file_id": "file-abc123",
            "completion_window": "24h",
            "status": "completed",
            "output_file_id": "file-cvaTdG",
            "error_file_id": "file-HOWS94",
            "created_at": 1711471533,
            "in_progress_at": 1711471538,
            "expires_at": 1711557933,
            "finalizing_at": 1711493133,
            "completed_at": 1711493163,
            "failed_at": null,
            "expired_at": null,
            "cancelling_at": null,
            "cancelled_at": null,
            "request_counts": {
              "total": 100,
              "completed": 95,
              "failed": 5
            },
            "metadata": {
              "customer_id": "user_123456789",
              "batch_description": "Nightly eval job",
            }
          }
    BatchRequestInput:
      description: The per-line object of the batch input file
      properties:
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch.
          type: string
        method:
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported.
          enum:
          - POST
          type: string
        url:
          description: "The OpenAI API relative URL to be used for the request. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported."
          type: string
      type: object
      x-oaiMeta:
        name: The request input object
        example: |
          {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
    BatchRequestOutput:
      description: The per-line object of the batch output and error files
      properties:
        id:
          type: string
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs.
          type: string
        response:
          $ref: '#/components/schemas/BatchRequestOutput_response'
        error:
          $ref: '#/components/schemas/BatchRequestOutput_error'
      type: object
      x-oaiMeta:
        name: The request output object
        example: |
          {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
    CancelUploadRequest:
      additionalProperties: false
      type: object
    ChatCompletionFunctionCallOption:
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      type: object
    ChatCompletionFunctions:
      deprecated: true
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
      required:
      - name
      type: object
    ChatCompletionMessageToolCall:
      example:
        function:
          name: name
          arguments: arguments
        id: id
        type: function
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCall_function'
      required:
      - function
      - id
      - type
      type: object
    ChatCompletionMessageToolCallChunk:
      properties:
        index:
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk_function'
      required:
      - index
      type: object
    ChatCompletionMessageToolCalls:
      description: "The tool calls generated by the model, such as function calls."
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
      type: array
    ChatCompletionModalities:
      description: |
        Output types that you would like the model to generate for this request.
        Most models are capable of generating text, which is the default:

        `["text"]`

        The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
        request that this model generate both text and audio responses, you can
        use:

        `["text", "audio"]`
      items:
        enum:
        - text
        - audio
        type: string
      nullable: true
      type: array
    ChatCompletionNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function.
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/AssistantsNamedToolChoice_function'
      required:
      - function
      - type
      type: object
    ChatCompletionRequestAssistantMessage:
      properties:
        content:
          $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage_content'
        refusal:
          description: The refusal message by the assistant.
          nullable: true
          type: string
        role:
          description: "The role of the messages author, in this case `assistant`."
          enum:
          - assistant
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        audio:
          $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage_audio'
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCall'
          type: array
        function_call:
          $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage_function_call'
      required:
      - role
      title: Assistant message
      type: object
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
      x-oaiExpandable: true
    ChatCompletionRequestFunctionMessage:
      deprecated: true
      properties:
        role:
          description: "The role of the messages author, in this case `function`."
          enum:
          - function
          type: string
        content:
          description: The contents of the function message.
          nullable: true
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - content
      - name
      - role
      title: Function message
      type: object
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartAudio:
      description: |
        Learn about [audio inputs](/docs/guides/audio).
      properties:
        type:
          description: The type of the content part. Always `input_audio`.
          enum:
          - input_audio
          type: string
        input_audio:
          $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio_input_audio'
      required:
      - input_audio
      - type
      title: Audio content part
      type: object
    ChatCompletionRequestMessageContentPartImage:
      description: |
        Learn about [image inputs](/docs/guides/vision).
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
        image_url:
          $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage_image_url'
      required:
      - image_url
      - type
      title: Image content part
      type: object
    ChatCompletionRequestMessageContentPartRefusal:
      properties:
        type:
          description: The type of the content part.
          enum:
          - refusal
          type: string
        refusal:
          description: The refusal message generated by the model.
          type: string
      required:
      - refusal
      - type
      title: Refusal content part
      type: object
    ChatCompletionRequestMessageContentPartText:
      description: |
        Learn about [text inputs](/docs/guides/text-generation).
      properties:
        type:
          description: The type of the content part.
          enum:
          - text
          type: string
        text:
          description: The text content.
          type: string
      required:
      - text
      - type
      title: Text content part
      type: object
    ChatCompletionRequestSystemMessage:
      example:
        role: system
        name: name
        content: ChatCompletionRequestSystemMessage_content
      properties:
        content:
          $ref: '#/components/schemas/ChatCompletionRequestSystemMessage_content'
        role:
          description: "The role of the messages author, in this case `system`."
          enum:
          - system
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: System message
      type: object
    ChatCompletionRequestSystemMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ChatCompletionRequestToolMessage:
      properties:
        role:
          description: "The role of the messages author, in this case `tool`."
          enum:
          - tool
          type: string
        content:
          $ref: '#/components/schemas/ChatCompletionRequestToolMessage_content'
        tool_call_id:
          description: Tool call that this message is responding to.
          type: string
      required:
      - content
      - role
      - tool_call_id
      title: Tool message
      type: object
    ChatCompletionRequestToolMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ChatCompletionRequestUserMessage:
      properties:
        content:
          $ref: '#/components/schemas/ChatCompletionRequestUserMessage_content'
        role:
          description: "The role of the messages author, in this case `user`."
          enum:
          - user
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: User message
      type: object
    ChatCompletionRequestUserMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
      x-oaiExpandable: true
    ChatCompletionResponseMessage:
      description: A chat completion message generated by the model.
      example:
        role: assistant
        function_call:
          name: name
          arguments: arguments
        refusal: refusal
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        audio:
          expires_at: 6
          transcript: transcript
          data: data
          id: id
        content: content
      properties:
        content:
          description: The contents of the message.
          nullable: true
          type: string
        refusal:
          description: The refusal message generated by the model.
          nullable: true
          type: string
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCall'
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - assistant
          type: string
        function_call:
          $ref: '#/components/schemas/ChatCompletionResponseMessage_function_call'
        audio:
          $ref: '#/components/schemas/ChatCompletionResponseMessage_audio'
      required:
      - content
      - refusal
      - role
      type: object
    ChatCompletionRole:
      description: The role of the author of a message
      enum:
      - system
      - user
      - assistant
      - tool
      - function
      type: string
    ChatCompletionStreamOptions:
      description: |
        Options for streaming response. Only set this when you set `stream: true`.
      example:
        include_usage: true
      nullable: true
      properties:
        include_usage:
          description: |
            If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.
          type: boolean
      type: object
    ChatCompletionStreamResponseDelta:
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          description: The contents of the chunk message.
          nullable: true
          type: string
        function_call:
          $ref: '#/components/schemas/ChatCompletionStreamResponseDelta_function_call'
        tool_calls:
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - system
          - user
          - assistant
          - tool
          type: string
        refusal:
          description: The refusal message generated by the model.
          nullable: true
          type: string
      type: object
    ChatCompletionTokenLogprob:
      example:
        top_logprobs:
        - logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
        - logprob: 5.637376656633329
          bytes:
          - 2
          - 2
          token: token
        logprob: 1.4658129805029452
        bytes:
        - 5
        - 5
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          nullable: true
          type: array
        top_logprobs:
          description: "List of the most likely tokens and their log probability,\
            \ at this token position. In rare cases, there may be fewer than the number\
            \ of requested `top_logprobs` returned."
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob_top_logprobs_inner'
          type: array
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
      type: object
    ChatCompletionTool:
      example:
        function:
          name: name
          description: description
          strict: false
          parameters:
            key: ""
        type: function
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/FunctionObject'
      required:
      - function
      - type
      type: object
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present.
      oneOf:
      - description: |
          `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
      x-oaiExpandable: true
    ChunkingStrategyRequestParam:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy."
      oneOf:
      - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
      - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      type: object
      x-oaiExpandable: true
    CompleteUploadRequest:
      additionalProperties: false
      example:
        part_ids:
        - part_ids
        - part_ids
        md5: md5
      properties:
        part_ids:
          description: |
            The ordered list of Part IDs.
          items:
            type: string
          type: array
        md5:
          description: |
            The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.
          type: string
      required:
      - part_ids
      type: object
    CompletionUsage:
      description: Usage statistics for the completion request.
      example:
        completion_tokens: 9
        prompt_tokens: 3
        completion_tokens_details:
          audio_tokens: 4
          reasoning_tokens: 7
        prompt_tokens_details:
          audio_tokens: 1
          cached_tokens: 1
        total_tokens: 2
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
        completion_tokens_details:
          $ref: '#/components/schemas/CompletionUsage_completion_tokens_details'
        prompt_tokens_details:
          $ref: '#/components/schemas/CompletionUsage_prompt_tokens_details'
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    CreateAssistantRequest:
      additionalProperties: false
      example:
        top_p: 1
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
            vector_stores:
            - chunking_strategy:
                type: auto
              metadata: "{}"
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
        metadata: "{}"
        response_format: auto
        name: name
        temperature: 1
        description: description
        model: gpt-4o
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
      properties:
        model:
          $ref: '#/components/schemas/CreateAssistantRequest_model'
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: '#/components/schemas/AssistantObject_tools_inner'
          maxItems: 128
          type: array
        tool_resources:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      required:
      - model
      type: object
    CreateChatCompletionFunctionResponse:
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input."
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            $ref: '#/components/schemas/CreateChatCompletionFunctionResponse_choices_inner'
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion`."
          enum:
          - chat.completion
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-abc123",
            "object": "chat.completion",
            "created": 1699896916,
            "model": "gpt-4o-mini",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": null,
                  "tool_calls": [
                    {
                      "id": "call_abc123",
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                      }
                    }
                  ]
                },
                "logprobs": null,
                "finish_reason": "tool_calls"
              }
            ],
            "usage": {
              "prompt_tokens": 82,
              "completion_tokens": 17,
              "total_tokens": 99,
              "completion_tokens_details": {
                "reasoning_tokens": 0
              }
            }
          }
    CreateChatCompletionImageResponse:
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input."
      type: object
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-4o-mini",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
              },
              "logprobs": null,
              "finish_reason": "stop"
            }],
            "usage": {
              "prompt_tokens": 9,
              "completion_tokens": 12,
              "total_tokens": 21,
              "completion_tokens_details": {
                "reasoning_tokens": 0
              }
            }
          }
    CreateChatCompletionRequest:
      example:
        top_logprobs: 2
        metadata:
          key: metadata
        logit_bias:
          key: 6
        seed: 2147483647
        presence_penalty: -1.079145645226094
        tools:
        - function:
            name: name
            description: description
            strict: false
            parameters:
              key: ""
          type: function
        - function:
            name: name
            description: description
            strict: false
            parameters:
              key: ""
          type: function
        logprobs: false
        top_p: 1
        max_completion_tokens: 5
        frequency_penalty: -1.6796687238155954
        modalities:
        - text
        - text
        response_format:
          type: text
        stream: false
        temperature: 1
        tool_choice: none
        model: o1-preview
        service_tier: auto
        audio:
          voice: alloy
          format: wav
        max_tokens: 5
        store: false
        "n": 1
        stop: CreateChatCompletionRequest_stop
        parallel_tool_calls: true
        messages:
        - role: system
          name: name
          content: ChatCompletionRequestSystemMessage_content
        - role: system
          name: name
          content: ChatCompletionRequestSystemMessage_content
        stream_options:
          include_usage: true
        user: user-1234
      properties:
        messages:
          description: |
            A list of messages comprising the conversation so far. Depending on the
            [model](/docs/models) you use, different message types (modalities) are
            supported, like [text](/docs/guides/text-generation),
            [images](/docs/guides/vision), and [audio](/docs/guides/audio).
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          minItems: 1
          type: array
        model:
          enum:
          - o1-preview
          - o1-preview-2024-09-12
          - o1-mini
          - o1-mini-2024-09-12
          - gpt-4o
          - gpt-4o-2024-08-06
          - gpt-4o-2024-05-13
          - gpt-4o-2024-08-06
          - gpt-4o-realtime-preview
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-audio-preview
          - gpt-4o-audio-preview-2024-10-01
          - chatgpt-4o-latest
          - gpt-4o-mini
          - gpt-4o-mini-2024-07-18
          - gpt-4-turbo
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-turbo-preview
          - gpt-4-1106-preview
          - gpt-4-vision-preview
          - gpt-4
          - gpt-4-0314
          - gpt-4-0613
          - gpt-4-32k
          - gpt-4-32k-0314
          - gpt-4-32k-0613
          - gpt-3.5-turbo
          - gpt-3.5-turbo-16k
          - gpt-3.5-turbo-0301
          - gpt-3.5-turbo-0613
          - gpt-3.5-turbo-1106
          - gpt-3.5-turbo-0125
          - gpt-3.5-turbo-16k-0613
          type: string
        store:
          default: false
          description: |
            Whether or not to store the output of this chat completion request
            for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.
          nullable: true
          type: boolean
        metadata:
          additionalProperties:
            type: string
          description: |
            Developer-defined tags and values used for filtering completions
            in the [dashboard](https://platform.openai.com/chat-completions).
          nullable: true
          type: object
        frequency_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        logit_bias:
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        logprobs:
          default: false
          description: "Whether to return log probabilities of the output tokens or\
            \ not. If true, returns the log probabilities of each output token returned\
            \ in the `content` of `message`."
          nullable: true
          type: boolean
        top_logprobs:
          description: "An integer between 0 and 20 specifying the number of most\
            \ likely tokens to return at each token position, each with an associated\
            \ log probability. `logprobs` must be set to `true` if this parameter\
            \ is used."
          maximum: 20
          minimum: 0
          nullable: true
          type: integer
        max_tokens:
          deprecated: true
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

            This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).
          nullable: true
          type: integer
        "n":
          default: 1
          description: How many chat completion choices to generate for each input
            message. Note that you will be charged based on the number of generated
            tokens across all of the choices. Keep `n` as `1` to minimize costs.
          example: 1
          maximum: 128
          minimum: 1
          nullable: true
          type: integer
        modalities:
          description: |
            Output types that you would like the model to generate for this request.
            Most models are capable of generating text, which is the default:

            `["text"]`

            The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
            request that this model generate both text and audio responses, you can
            use:

            `["text", "audio"]`
          items:
            enum:
            - text
            - audio
            type: string
          nullable: true
          type: array
        audio:
          $ref: '#/components/schemas/CreateChatCompletionRequest_audio'
        presence_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        response_format:
          $ref: '#/components/schemas/CreateChatCompletionRequest_response_format'
        seed:
          description: |
            This feature is in Beta.
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          nullable: true
          type: integer
          x-oaiMeta:
            beta: true
        service_tier:
          default: auto
          description: "Specifies the latency tier to use for processing the request.\
            \ This parameter is relevant for customers subscribed to the scale tier\
            \ service:\n  - If set to 'auto', and the Project is Scale tier enabled,\
            \ the system will utilize scale tier credits until they are exhausted.\
            \ \n  - If set to 'auto', and the Project is not Scale tier enabled, the\
            \ request will be processed using the default service tier with a lower\
            \ uptime SLA and no latency guarentee.\n  - If set to 'default', the request\
            \ will be processed using the default service tier with a lower uptime\
            \ SLA and no latency guarentee.\n  - When not set, the default behavior\
            \ is 'auto'.\n\n  When this parameter is set, the response body will include\
            \ the `service_tier` utilized.\n"
          enum:
          - auto
          - default
          nullable: true
          type: string
        stop:
          $ref: '#/components/schemas/CreateChatCompletionRequest_stop'
        stream:
          default: false
          description: |
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          nullable: true
          type: boolean
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        tools:
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          nullable: true
          type: array
        tool_choice:
          $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
        parallel_tool_calls:
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
            \ during tool use."
          nullable: true
          type: boolean
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - messages
      - model
      type: object
    CreateChatCompletionResponse:
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input."
      example:
        created: 7
        usage:
          completion_tokens: 9
          prompt_tokens: 3
          completion_tokens_details:
            audio_tokens: 4
            reasoning_tokens: 7
          prompt_tokens_details:
            audio_tokens: 1
            cached_tokens: 1
          total_tokens: 2
        model: model
        service_tier: scale
        id: id
        choices:
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            refusal: refusal
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            audio:
              expires_at: 6
              transcript: transcript
              data: data
              id: id
            content: content
          logprobs:
            refusal:
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            content:
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            refusal: refusal
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            audio:
              expires_at: 6
              transcript: transcript
              data: data
              id: id
            content: content
          logprobs:
            refusal:
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            content:
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
            - top_logprobs:
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              - logprob: 5.637376656633329
                bytes:
                - 2
                - 2
                token: token
              logprob: 1.4658129805029452
              bytes:
              - 5
              - 5
              token: token
        system_fingerprint: system_fingerprint
        object: chat.completion
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            $ref: '#/components/schemas/CreateChatCompletionResponse_choices_inner'
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        service_tier:
          description: The service tier used for processing the request. This field
            is only included if the `service_tier` parameter is specified in the request.
          enum:
          - scale
          - default
          example: scale
          nullable: true
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion`."
          enum:
          - chat.completion
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-123456",
            "object": "chat.completion",
            "created": 1728933352,
            "model": "gpt-4o-2024-08-06",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "Hi there! How can I assist you today?",
                  "refusal": null
                },
                "logprobs": null,
                "finish_reason": "stop"
              }
            ],
            "usage": {
              "prompt_tokens": 19,
              "completion_tokens": 10,
              "total_tokens": 29,
              "prompt_tokens_details": {
                "cached_tokens": 0
              },
              "completion_tokens_details": {
                "reasoning_tokens": 0
              }
            },
            "system_fingerprint": "fp_6b68a8204b"
          }
    CreateChatCompletionStreamResponse:
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input."
      properties:
        id:
          description: A unique identifier for the chat completion. Each chunk has
            the same ID.
          type: string
        choices:
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`.
          items:
            $ref: '#/components/schemas/CreateChatCompletionStreamResponse_choices_inner'
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp.
          type: integer
        model:
          description: The model to generate the completion.
          type: string
        service_tier:
          description: The service tier used for processing the request. This field
            is only included if the `service_tier` parameter is specified in the request.
          enum:
          - scale
          - default
          example: scale
          nullable: true
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion.chunk`."
          enum:
          - chat.completion.chunk
          type: string
        usage:
          $ref: '#/components/schemas/CreateChatCompletionStreamResponse_usage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
    CreateCompletionRequest:
      example:
        logit_bias:
          key: 1
        seed: -2147483648
        max_tokens: 16
        presence_penalty: 0.25495066265333133
        echo: false
        suffix: test.
        "n": 1
        logprobs: 2
        top_p: 1
        frequency_penalty: 0.4109824732281613
        best_of: 1
        stop: |2+

        stream: false
        temperature: 1
        model: CreateCompletionRequest_model
        stream_options:
          include_usage: true
        prompt: This is a test.
        user: user-1234
      properties:
        model:
          $ref: '#/components/schemas/CreateCompletionRequest_model'
        prompt:
          $ref: '#/components/schemas/CreateCompletionRequest_prompt'
        best_of:
          default: 1
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          maximum: 20
          minimum: 0
          nullable: true
          type: integer
        echo:
          default: false
          description: |
            Echo back the prompt in addition to the completion
          nullable: true
          type: boolean
        frequency_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        logit_bias:
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        logprobs:
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
          maximum: 5
          minimum: 0
          nullable: true
          type: integer
        max_tokens:
          default: 16
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          example: 16
          minimum: 0
          nullable: true
          type: integer
        "n":
          default: 1
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          example: 1
          maximum: 128
          minimum: 1
          nullable: true
          type: integer
        presence_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        seed:
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          nullable: true
          type: integer
        stop:
          $ref: '#/components/schemas/CreateCompletionRequest_stop'
        stream:
          default: false
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          nullable: true
          type: boolean
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        suffix:
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`.
          example: test.
          nullable: true
          type: string
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - model
      - prompt
      type: object
    CreateCompletionResponse:
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      example:
        created: 5
        usage:
          completion_tokens: 9
          prompt_tokens: 3
          completion_tokens_details:
            audio_tokens: 4
            reasoning_tokens: 7
          prompt_tokens_details:
            audio_tokens: 1
            cached_tokens: 1
          total_tokens: 2
        model: model
        id: id
        choices:
        - finish_reason: stop
          index: 0
          text: text
          logprobs:
            top_logprobs:
            - key: 5.962133916683182
            - key: 5.962133916683182
            token_logprobs:
            - 1.4658129805029452
            - 1.4658129805029452
            tokens:
            - tokens
            - tokens
            text_offset:
            - 6
            - 6
        - finish_reason: stop
          index: 0
          text: text
          logprobs:
            top_logprobs:
            - key: 5.962133916683182
            - key: 5.962133916683182
            token_logprobs:
            - 1.4658129805029452
            - 1.4658129805029452
            tokens:
            - tokens
            - tokens
            text_offset:
            - 6
            - 6
        system_fingerprint: system_fingerprint
        object: text_completion
      properties:
        id:
          description: A unique identifier for the completion.
          type: string
        choices:
          description: The list of completion choices the model generated for the
            input prompt.
          items:
            $ref: '#/components/schemas/CreateCompletionResponse_choices_inner'
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the completion was
            created.
          type: integer
        model:
          description: The model used for completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always \"text_completion\""
          enum:
          - text_completion
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
    CreateEmbeddingRequest:
      additionalProperties: false
      example:
        input: The quick brown fox jumped over the lazy dog
        encoding_format: float
        model: text-embedding-3-small
        user: user-1234
        dimensions: 1
      properties:
        input:
          $ref: '#/components/schemas/CreateEmbeddingRequest_input'
        model:
          $ref: '#/components/schemas/CreateEmbeddingRequest_model'
        encoding_format:
          default: float
          description: "The format to return the embeddings in. Can be either `float`\
            \ or [`base64`](https://pypi.org/project/pybase64/)."
          enum:
          - float
          - base64
          example: float
          type: string
        dimensions:
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
          minimum: 1
          type: integer
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - input
      - model
      type: object
    CreateEmbeddingResponse:
      example:
        data:
        - index: 0
          embedding:
          - 6.027456183070403
          - 6.027456183070403
          object: embedding
        - index: 0
          embedding:
          - 6.027456183070403
          - 6.027456183070403
          object: embedding
        usage:
          prompt_tokens: 1
          total_tokens: 5
        model: model
        object: list
      properties:
        data:
          description: The list of embeddings generated by the model.
          items:
            $ref: '#/components/schemas/Embedding'
          type: array
        model:
          description: The name of the model used to generate the embedding.
          type: string
        object:
          description: "The object type, which is always \"list\"."
          enum:
          - list
          type: string
        usage:
          $ref: '#/components/schemas/CreateEmbeddingResponse_usage'
      required:
      - data
      - model
      - object
      - usage
      type: object
    CreateFileRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The File object (not file name) to be uploaded.
          format: binary
          type: string
        purpose:
          description: |
            The intended purpose of the uploaded file.

            Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          type: string
      required:
      - file
      - purpose
      type: object
    CreateFineTuningJobRequest:
      example:
        training_file: file-abc123
        seed: 42
        validation_file: file-abc123
        hyperparameters:
          batch_size: auto
          n_epochs: auto
          learning_rate_multiplier: auto
        model: gpt-4o-mini
        suffix: suffix
        integrations:
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
      properties:
        model:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_model'
        training_file:
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
          example: file-abc123
          type: string
        hyperparameters:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_hyperparameters'
        suffix:
          description: |
            A string of up to 64 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.
          maxLength: 64
          minLength: 1
          nullable: true
          type: string
        validation_file:
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
          example: file-abc123
          nullable: true
          type: string
        integrations:
          description: A list of integrations to enable for your fine-tuning job.
          items:
            $ref: '#/components/schemas/CreateFineTuningJobRequest_integrations_inner'
          nullable: true
          type: array
        seed:
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you.
          example: 42
          maximum: 2147483647
          minimum: 0
          nullable: true
          type: integer
      required:
      - model
      - training_file
      type: object
    CreateImageEditRequest:
      properties:
        image:
          description: "The image to edit. Must be a valid PNG file, less than 4MB,\
            \ and square. If mask is not provided, image must have transparency, which\
            \ will be used as the mask."
          format: binary
          type: string
        prompt:
          description: A text description of the desired image(s). The maximum length
            is 1000 characters.
          example: A cute baby sea otter wearing a beret
          type: string
        mask:
          description: "An additional image whose fully transparent areas (e.g. where\
            \ alpha is zero) indicate where `image` should be edited. Must be a valid\
            \ PNG file, less than 4MB, and have the same dimensions as `image`."
          format: binary
          type: string
        model:
          $ref: '#/components/schemas/CreateImageEditRequest_model'
        "n":
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
          example: 1
          maximum: 10
          minimum: 1
          nullable: true
          type: integer
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          nullable: true
          type: string
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          nullable: true
          type: string
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - image
      - prompt
      type: object
    CreateImageRequest:
      example:
        response_format: url
        size: 1024x1024
        model: dall-e-2
        style: vivid
        prompt: A cute baby sea otter
        user: user-1234
        "n": 1
        quality: standard
      properties:
        prompt:
          description: A text description of the desired image(s). The maximum length
            is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
          example: A cute baby sea otter
          type: string
        model:
          enum:
          - dall-e-2
          - dall-e-3
          nullable: true
          type: string
        "n":
          default: 1
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported."
          example: 1
          maximum: 10
          minimum: 1
          nullable: true
          type: integer
        quality:
          default: standard
          description: The quality of the image that will be generated. `hd` creates
            images with finer details and greater consistency across the image. This
            param is only supported for `dall-e-3`.
          enum:
          - standard
          - hd
          example: standard
          type: string
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          nullable: true
          type: string
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`,\
            \ `1792x1024`, or `1024x1792` for `dall-e-3` models."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1792x1024
          - 1024x1792
          example: 1024x1024
          nullable: true
          type: string
        style:
          default: vivid
          description: "The style of the generated images. Must be one of `vivid`\
            \ or `natural`. Vivid causes the model to lean towards generating hyper-real\
            \ and dramatic images. Natural causes the model to produce more natural,\
            \ less hyper-real looking images. This param is only supported for `dall-e-3`."
          enum:
          - vivid
          - natural
          example: vivid
          nullable: true
          type: string
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - prompt
      type: object
    CreateImageVariationRequest:
      properties:
        image:
          description: "The image to use as the basis for the variation(s). Must be\
            \ a valid PNG file, less than 4MB, and square."
          format: binary
          type: string
        model:
          enum:
          - dall-e-2
          nullable: true
          type: string
        "n":
          default: 1
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported."
          example: 1
          maximum: 10
          minimum: 1
          nullable: true
          type: integer
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          nullable: true
          type: string
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          nullable: true
          type: string
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - image
      type: object
    CreateMessageRequest:
      additionalProperties: false
      example:
        metadata: "{}"
        role: user
        attachments:
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        content: CreateMessageRequest_content
      properties:
        role:
          description: |
            The role of the entity that is creating the message. Allowed values include:
            - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
            - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
          enum:
          - user
          - assistant
          type: string
        content:
          $ref: '#/components/schemas/CreateMessageRequest_content'
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ should be added to."
          items:
            $ref: '#/components/schemas/CreateMessageRequest_attachments_inner'
          nullable: true
          required:
          - file_id
          - tools
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - content
      - role
      type: object
    CreateModerationRequest:
      example:
        input: I want to kill them.
        model: omni-moderation-latest
      properties:
        input:
          $ref: '#/components/schemas/CreateModerationRequest_input'
        model:
          enum:
          - omni-moderation-latest
          - omni-moderation-2024-09-26
          - text-moderation-latest
          - text-moderation-stable
          type: string
      required:
      - input
      type: object
    CreateModerationResponse:
      description: Represents if a given text input is potentially harmful.
      example:
        model: model
        id: id
        results:
        - category_scores:
            illicit/violent: 2.3021358869347655
            self-harm/instructions: 3.616076749251911
            harassment: 1.4658129805029452
            violence/graphic: 1.2315135367772556
            illicit: 5.637376656633329
            self-harm/intent: 9.301444243932576
            hate/threatening: 6.027456183070403
            sexual/minors: 4.145608029883936
            harassment/threatening: 5.962133916683182
            hate: 0.8008281904610115
            self-harm: 7.061401241503109
            sexual: 2.027123023002322
            violence: 7.386281948385884
          flagged: true
          category_applied_input_types:
            illicit/violent:
            - text
            - text
            self-harm/instructions:
            - text
            - text
            harassment:
            - text
            - text
            violence/graphic:
            - text
            - text
            illicit:
            - text
            - text
            self-harm/intent:
            - text
            - text
            hate/threatening:
            - text
            - text
            sexual/minors:
            - text
            - text
            harassment/threatening:
            - text
            - text
            hate:
            - text
            - text
            self-harm:
            - text
            - text
            sexual:
            - text
            - text
            violence:
            - text
            - text
          categories:
            illicit/violent: true
            self-harm/instructions: true
            harassment: true
            violence/graphic: true
            illicit: true
            self-harm/intent: true
            hate/threatening: true
            sexual/minors: true
            harassment/threatening: true
            hate: true
            self-harm: true
            sexual: true
            violence: true
        - category_scores:
            illicit/violent: 2.3021358869347655
            self-harm/instructions: 3.616076749251911
            harassment: 1.4658129805029452
            violence/graphic: 1.2315135367772556
            illicit: 5.637376656633329
            self-harm/intent: 9.301444243932576
            hate/threatening: 6.027456183070403
            sexual/minors: 4.145608029883936
            harassment/threatening: 5.962133916683182
            hate: 0.8008281904610115
            self-harm: 7.061401241503109
            sexual: 2.027123023002322
            violence: 7.386281948385884
          flagged: true
          category_applied_input_types:
            illicit/violent:
            - text
            - text
            self-harm/instructions:
            - text
            - text
            harassment:
            - text
            - text
            violence/graphic:
            - text
            - text
            illicit:
            - text
            - text
            self-harm/intent:
            - text
            - text
            hate/threatening:
            - text
            - text
            sexual/minors:
            - text
            - text
            harassment/threatening:
            - text
            - text
            hate:
            - text
            - text
            self-harm:
            - text
            - text
            sexual:
            - text
            - text
            violence:
            - text
            - text
          categories:
            illicit/violent: true
            self-harm/instructions: true
            harassment: true
            violence/graphic: true
            illicit: true
            self-harm/intent: true
            hate/threatening: true
            sexual/minors: true
            harassment/threatening: true
            hate: true
            self-harm: true
            sexual: true
            violence: true
      properties:
        id:
          description: The unique identifier for the moderation request.
          type: string
        model:
          description: The model used to generate the moderation results.
          type: string
        results:
          description: A list of moderation objects.
          items:
            $ref: '#/components/schemas/CreateModerationResponse_results_inner'
          type: array
      required:
      - id
      - model
      - results
      type: object
      x-oaiMeta:
        name: The moderation object
        example: |
          {
            "id": "modr-0d9740456c391e43c445bf0f010940c7",
            "model": "omni-moderation-latest",
            "results": [
              {
                "flagged": true,
                "categories": {
                  "harassment": true,
                  "harassment/threatening": true,
                  "sexual": false,
                  "hate": false,
                  "hate/threatening": false,
                  "illicit": false,
                  "illicit/violent": false,
                  "self-harm/intent": false,
                  "self-harm/instructions": false,
                  "self-harm": false,
                  "sexual/minors": false,
                  "violence": true,
                  "violence/graphic": true
                },
                "category_scores": {
                  "harassment": 0.8189693396524255,
                  "harassment/threatening": 0.804985420696006,
                  "sexual": 1.573112165348997e-6,
                  "hate": 0.007562942636942845,
                  "hate/threatening": 0.004208854591835476,
                  "illicit": 0.030535955153511665,
                  "illicit/violent": 0.008925306722380033,
                  "self-harm/intent": 0.00023023930975076432,
                  "self-harm/instructions": 0.0002293869201073356,
                  "self-harm": 0.012598046106750154,
                  "sexual/minors": 2.212566909570261e-8,
                  "violence": 0.9999992735124786,
                  "violence/graphic": 0.843064871157054
                },
                "category_applied_input_types": {
                  "harassment": [
                    "text"
                  ],
                  "harassment/threatening": [
                    "text"
                  ],
                  "sexual": [
                    "text",
                    "image"
                  ],
                  "hate": [
                    "text"
                  ],
                  "hate/threatening": [
                    "text"
                  ],
                  "illicit": [
                    "text"
                  ],
                  "illicit/violent": [
                    "text"
                  ],
                  "self-harm/intent": [
                    "text",
                    "image"
                  ],
                  "self-harm/instructions": [
                    "text",
                    "image"
                  ],
                  "self-harm": [
                    "text",
                    "image"
                  ],
                  "sexual/minors": [
                    "text"
                  ],
                  "violence": [
                    "text",
                    "image"
                  ],
                  "violence/graphic": [
                    "text",
                    "image"
                  ]
                }
              }
            ]
          }
    CreateRunRequest:
      additionalProperties: false
      example:
        instructions: instructions
        additional_instructions: additional_instructions
        metadata: "{}"
        assistant_id: assistant_id
        additional_messages:
        - metadata: "{}"
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        - metadata: "{}"
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        truncation_strategy:
          last_messages: 1
          type: auto
        top_p: 1
        max_completion_tokens: 256
        response_format: auto
        parallel_tool_calls: true
        stream: true
        temperature: 1
        tool_choice: none
        model: gpt-4o
        max_prompt_tokens: 256
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        model:
          enum:
          - gpt-4o
          - gpt-4o-2024-08-06
          - gpt-4o-2024-05-13
          - gpt-4o-2024-08-06
          - gpt-4o-mini
          - gpt-4o-mini-2024-07-18
          - gpt-4-turbo
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-turbo-preview
          - gpt-4-1106-preview
          - gpt-4-vision-preview
          - gpt-4
          - gpt-4-0314
          - gpt-4-0613
          - gpt-4-32k
          - gpt-4-32k-0314
          - gpt-4-32k-0613
          - gpt-3.5-turbo
          - gpt-3.5-turbo-16k
          - gpt-3.5-turbo-0613
          - gpt-3.5-turbo-1106
          - gpt-3.5-turbo-0125
          - gpt-3.5-turbo-16k-0613
          nullable: true
          type: string
        instructions:
          description: "Overrides the [instructions](/docs/api-reference/assistants/createAssistant)\
            \ of the assistant. This is useful for modifying the behavior on a per-run\
            \ basis."
          nullable: true
          type: string
        additional_instructions:
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions.
          nullable: true
          type: string
        additional_messages:
          description: Adds additional messages to the thread before creating the
            run.
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          nullable: true
          type: array
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: '#/components/schemas/AssistantObject_tools_inner'
          maxItems: 20
          nullable: true
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
            \ during tool use."
          nullable: true
          type: boolean
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      required:
      - assistant_id
      type: object
    CreateSpeechRequest:
      additionalProperties: false
      example:
        voice: alloy
        input: input
        response_format: mp3
        model: tts-1
        speed: 0.5503105714228793
      properties:
        model:
          enum:
          - tts-1
          - tts-1-hd
          type: string
        input:
          description: The text to generate audio for. The maximum length is 4096
            characters.
          maxLength: 4096
          type: string
        voice:
          description: "The voice to use when generating the audio. Supported voices\
            \ are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews\
            \ of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options)."
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          type: string
        response_format:
          default: mp3
          description: "The format to audio in. Supported formats are `mp3`, `opus`,\
            \ `aac`, `flac`, `wav`, and `pcm`."
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          type: string
        speed:
          default: 1
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default.
          maximum: 4
          minimum: 0.25
          type: number
      required:
      - input
      - model
      - voice
      type: object
    CreateThreadAndRunRequest:
      additionalProperties: false
      example:
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata: "{}"
        assistant_id: assistant_id
        thread:
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
              vector_stores:
              - chunking_strategy:
                  type: auto
                metadata: "{}"
                file_ids:
                - file_ids
                - file_ids
                - file_ids
                - file_ids
                - file_ids
          metadata: "{}"
          messages:
          - metadata: "{}"
            role: user
            attachments:
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            content: CreateMessageRequest_content
          - metadata: "{}"
            role: user
            attachments:
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            - file_id: file_id
              tools:
              - type: code_interpreter
              - type: code_interpreter
            content: CreateMessageRequest_content
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        truncation_strategy:
          last_messages: 1
          type: auto
        top_p: 1
        max_completion_tokens: 256
        response_format: auto
        parallel_tool_calls: true
        stream: true
        temperature: 1
        tool_choice: none
        model: gpt-4o
        max_prompt_tokens: 256
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        model:
          enum:
          - gpt-4o
          - gpt-4o-2024-08-06
          - gpt-4o-2024-05-13
          - gpt-4o-2024-08-06
          - gpt-4o-mini
          - gpt-4o-mini-2024-07-18
          - gpt-4-turbo
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-turbo-preview
          - gpt-4-1106-preview
          - gpt-4-vision-preview
          - gpt-4
          - gpt-4-0314
          - gpt-4-0613
          - gpt-4-32k
          - gpt-4-32k-0314
          - gpt-4-32k-0613
          - gpt-3.5-turbo
          - gpt-3.5-turbo-16k
          - gpt-3.5-turbo-0613
          - gpt-3.5-turbo-1106
          - gpt-3.5-turbo-0125
          - gpt-3.5-turbo-16k-0613
          nullable: true
          type: string
        instructions:
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: string
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: '#/components/schemas/CreateThreadAndRunRequest_tools_inner'
          maxItems: 20
          nullable: true
          type: array
        tool_resources:
          $ref: '#/components/schemas/CreateThreadAndRunRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
            \ during tool use."
          nullable: true
          type: boolean
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      required:
      - assistant_id
      type: object
    CreateThreadRequest:
      additionalProperties: false
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
            vector_stores:
            - chunking_strategy:
                type: auto
              metadata: "{}"
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
        metadata: "{}"
        messages:
        - metadata: "{}"
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
        - metadata: "{}"
          role: user
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          content: CreateMessageRequest_content
      properties:
        messages:
          description: "A list of [messages](/docs/api-reference/messages) to start\
            \ the thread with."
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          type: array
        tool_resources:
          $ref: '#/components/schemas/CreateThreadRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    CreateTranscriptionRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          $ref: '#/components/schemas/CreateTranscriptionRequest_model'
        language:
          description: |
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
          type: string
        response_format:
          $ref: '#/components/schemas/AudioResponseFormat'
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
        timestamp_granularities:
          default:
          - segment
          description: |
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
          items:
            enum:
            - word
            - segment
            type: string
          type: array
      required:
      - file
      - model
      type: object
    CreateTranscriptionResponseJson:
      description: "Represents a transcription response returned by model, based on\
        \ the provided input."
      example:
        text: text
      properties:
        text:
          description: The transcribed text.
          type: string
      required:
      - text
      type: object
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: |
          {
            "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
          }
    CreateTranscriptionResponseVerboseJson:
      description: "Represents a verbose json transcription response returned by model,\
        \ based on the provided input."
      properties:
        language:
          description: The language of the input audio.
          type: string
        duration:
          description: The duration of the input audio.
          type: string
        text:
          description: The transcribed text.
          type: string
        words:
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: '#/components/schemas/TranscriptionWord'
          type: array
        segments:
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          type: array
      required:
      - duration
      - language
      - text
      type: object
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: |
          {
            "task": "transcribe",
            "language": "english",
            "duration": 8.470000267028809,
            "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
            "segments": [
              {
                "id": 0,
                "seek": 0,
                "start": 0.0,
                "end": 3.319999933242798,
                "text": " The beach was a popular spot on a hot summer day.",
                "tokens": [
                  50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                ],
                "temperature": 0.0,
                "avg_logprob": -0.2860786020755768,
                "compression_ratio": 1.2363636493682861,
                "no_speech_prob": 0.00985979475080967
              },
              ...
            ]
          }
    CreateTranslationRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          enum:
          - whisper-1
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
          type: string
        response_format:
          $ref: '#/components/schemas/AudioResponseFormat'
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
      required:
      - file
      - model
      type: object
    CreateTranslationResponseJson:
      example:
        text: text
      properties:
        text:
          type: string
      required:
      - text
      type: object
    CreateTranslationResponseVerboseJson:
      properties:
        language:
          description: The language of the output translation (always `english`).
          type: string
        duration:
          description: The duration of the input audio.
          type: string
        text:
          description: The translated text.
          type: string
        segments:
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          type: array
      required:
      - duration
      - language
      - text
      type: object
    CreateUploadRequest:
      additionalProperties: false
      example:
        filename: filename
        purpose: assistants
        mime_type: mime_type
        bytes: 0
      properties:
        filename:
          description: |
            The name of the file to upload.
          type: string
        purpose:
          description: |
            The intended purpose of the uploaded file.

            See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          type: string
        bytes:
          description: |
            The number of bytes in the file you are uploading.
          type: integer
        mime_type:
          description: |
            The MIME type of the file.

            This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.
          type: string
      required:
      - bytes
      - filename
      - mime_type
      - purpose
      type: object
    CreateVectorStoreFileBatchRequest:
      additionalProperties: false
      example:
        chunking_strategy:
          type: auto
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          minItems: 1
          type: array
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
      required:
      - file_ids
      type: object
    CreateVectorStoreFileRequest:
      additionalProperties: false
      example:
        chunking_strategy:
          type: auto
        file_id: file_id
      properties:
        file_id:
          description: "A [File](/docs/api-reference/files) ID that the vector store\
            \ should use. Useful for tools like `file_search` that can access files."
          type: string
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
      required:
      - file_id
      type: object
    CreateVectorStoreRequest:
      additionalProperties: false
      example:
        chunking_strategy:
          type: auto
        metadata: "{}"
        expires_after:
          anchor: last_active_at
          days: 339
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        name: name
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          type: array
        name:
          description: The name of the vector store.
          type: string
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        chunking_strategy:
          $ref: '#/components/schemas/CreateVectorStoreRequest_chunking_strategy'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    DefaultProjectErrorResponse:
      properties:
        code:
          type: integer
        message:
          type: string
      required:
      - code
      - message
      type: object
    DeleteAssistantResponse:
      example:
        deleted: true
        id: id
        object: assistant.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - assistant.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DeleteFileResponse:
      example:
        deleted: true
        id: id
        object: file
      properties:
        id:
          type: string
        object:
          enum:
          - file
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    DeleteMessageResponse:
      example:
        deleted: true
        id: id
        object: thread.message.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.message.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DeleteModelResponse:
      example:
        deleted: true
        id: id
        object: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DeleteThreadResponse:
      example:
        deleted: true
        id: id
        object: thread.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DeleteVectorStoreFileResponse:
      example:
        deleted: true
        id: id
        object: vector_store.file.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.file.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DeleteVectorStoreResponse:
      example:
        deleted: true
        id: id
        object: vector_store.deleted
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    DoneEvent:
      description: Occurs when a stream ends.
      properties:
        event:
          enum:
          - done
          type: string
        data:
          enum:
          - "[DONE]"
          type: string
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is `[DONE]`"
    Embedding:
      description: |
        Represents an embedding vector returned by embedding endpoint.
      example:
        index: 0
        embedding:
        - 6.027456183070403
        - 6.027456183070403
        object: embedding
      properties:
        index:
          description: The index of the embedding in the list of embeddings.
          type: integer
        embedding:
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).
          items:
            type: number
          type: array
        object:
          description: "The object type, which is always \"embedding\"."
          enum:
          - embedding
          type: string
      required:
      - embedding
      - index
      - object
      type: object
      x-oaiMeta:
        name: The embedding object
        example: |
          {
            "object": "embedding",
            "embedding": [
              0.0023064255,
              -0.009327292,
              .... (1536 floats total for ada-002)
              -0.0028842222,
            ],
            "index": 0
          }
    Error:
      example:
        code: code
        param: param
        message: message
        type: type
      properties:
        code:
          nullable: true
          type: string
        message:
          nullable: false
          type: string
        param:
          nullable: true
          type: string
        type:
          nullable: false
          type: string
      required:
      - code
      - message
      - param
      - type
      type: object
    ErrorEvent:
      description: "Occurs when an [error](/docs/guides/error-codes/api-errors) occurs.\
        \ This can happen due to an internal server error or a timeout."
      properties:
        event:
          enum:
          - error
          type: string
        data:
          $ref: '#/components/schemas/Error'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is an [error](/docs/guides/error-codes/api-errors)"
    ErrorResponse:
      example:
        error:
          code: code
          param: param
          message: message
          type: type
      properties:
        error:
          $ref: '#/components/schemas/Error'
      required:
      - error
      type: object
    FileSearchRankingOptions:
      description: |
        The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.

        See the [file search tool documentation](/docs/assistants/tools/file-search/customizing-file-search-settings) for more information.
      properties:
        ranker:
          description: The ranker to use for the file search. If not specified will
            use the `auto` ranker.
          enum:
          - auto
          - default_2024_08_21
          type: string
        score_threshold:
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
      required:
      - score_threshold
      title: File search tool call ranking options
      type: object
    FineTuneChatCompletionRequestAssistantMessage:
      allOf:
      - deprecated: false
        properties:
          weight:
            description: Controls whether the assistant message is trained against
              (0 or 1)
            enum:
            - 0
            - 1
            type: integer
        title: Assistant message
        type: object
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      required:
      - role
    FineTuningIntegration:
      example:
        wandb:
          name: name
          project: my-wandb-project
          entity: entity
          tags:
          - custom-tag
          - custom-tag
        type: wandb
      properties:
        type:
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
          type: string
        wandb:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb'
      required:
      - type
      - wandb
      title: Fine-Tuning Job Integration
      type: object
    FineTuningJob:
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
      example:
        training_file: training_file
        result_files:
        - file-abc123
        - file-abc123
        finished_at: 6
        seed: 5
        fine_tuned_model: fine_tuned_model
        validation_file: validation_file
        created_at: 0
        error:
          code: code
          param: param
          message: message
        estimated_finish: 5
        organization_id: organization_id
        hyperparameters:
          n_epochs: auto
        model: model
        id: id
        trained_tokens: 1
        integrations:
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        - wandb:
            name: name
            project: my-wandb-project
            entity: entity
            tags:
            - custom-tag
            - custom-tag
          type: wandb
        object: fine_tuning.job
        status: validating_files
      properties:
        id:
          description: "The object identifier, which can be referenced in the API\
            \ endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created.
          type: integer
        error:
          $ref: '#/components/schemas/FineTuningJob_error'
        fine_tuned_model:
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running.
          nullable: true
          type: string
        finished_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running.
          nullable: true
          type: integer
        hyperparameters:
          $ref: '#/components/schemas/FineTuningJob_hyperparameters'
        model:
          description: The base model that is being fine-tuned.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job\"."
          enum:
          - fine_tuning.job
          type: string
        organization_id:
          description: The organization that owns the fine-tuning job.
          type: string
        result_files:
          description: "The compiled results file ID(s) for the fine-tuning job. You\
            \ can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          items:
            example: file-abc123
            type: string
          type: array
        status:
          description: "The current status of the fine-tuning job, which can be either\
            \ `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`."
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
          type: string
        trained_tokens:
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running.
          nullable: true
          type: integer
        training_file:
          description: "The file ID used for training. You can retrieve the training\
            \ data with the [Files API](/docs/api-reference/files/retrieve-contents)."
          type: string
        validation_file:
          description: "The file ID used for validation. You can retrieve the validation\
            \ results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          nullable: true
          type: string
        integrations:
          description: A list of integrations to enable for this fine-tuning job.
          items:
            $ref: '#/components/schemas/FineTuningJob_integrations_inner'
          maxItems: 5
          nullable: true
          type: array
        seed:
          description: The seed used for the fine-tuning job.
          type: integer
        estimated_finish:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running.
          nullable: true
          type: integer
      required:
      - created_at
      - error
      - fine_tuned_model
      - finished_at
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - seed
      - status
      - trained_tokens
      - training_file
      - validation_file
      title: FineTuningJob
      type: object
      x-oaiMeta:
        name: The fine-tuning job object
        example: |
          {
            "object": "fine_tuning.job",
            "id": "ftjob-abc123",
            "model": "davinci-002",
            "created_at": 1692661014,
            "finished_at": 1692661190,
            "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
            "organization_id": "org-123",
            "result_files": [
                "file-abc123"
            ],
            "status": "succeeded",
            "validation_file": null,
            "training_file": "file-abc123",
            "hyperparameters": {
                "n_epochs": 4,
                "batch_size": 1,
                "learning_rate_multiplier": 1.0
            },
            "trained_tokens": 5768,
            "integrations": [],
            "seed": 0,
            "estimated_finish": 0
          }
    FineTuningJobCheckpoint:
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
      example:
        step_number: 6
        created_at: 0
        fine_tuning_job_id: fine_tuning_job_id
        id: id
        metrics:
          full_valid_mean_token_accuracy: 3.616076749251911
          valid_loss: 2.3021358869347655
          full_valid_loss: 9.301444243932576
          train_mean_token_accuracy: 5.637376656633329
          valid_mean_token_accuracy: 7.061401241503109
          train_loss: 5.962133916683182
          step: 1.4658129805029452
        fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
        object: fine_tuning.job.checkpoint
      properties:
        id:
          description: "The checkpoint identifier, which can be referenced in the\
            \ API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created.
          type: integer
        fine_tuned_model_checkpoint:
          description: The name of the fine-tuned checkpoint model that is created.
          type: string
        step_number:
          description: The step number that the checkpoint was created at.
          type: integer
        metrics:
          $ref: '#/components/schemas/FineTuningJobCheckpoint_metrics'
        fine_tuning_job_id:
          description: The name of the fine-tuning job that this checkpoint was created
            from.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job.checkpoint\"\
            ."
          enum:
          - fine_tuning.job.checkpoint
          type: string
      required:
      - created_at
      - fine_tuned_model_checkpoint
      - fine_tuning_job_id
      - id
      - metrics
      - object
      - step_number
      title: FineTuningJobCheckpoint
      type: object
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: |
          {
            "object": "fine_tuning.job.checkpoint",
            "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
            "created_at": 1712211699,
            "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
            "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
            "metrics": {
              "step": 88,
              "train_loss": 0.478,
              "train_mean_token_accuracy": 0.924,
              "valid_loss": 10.112,
              "valid_mean_token_accuracy": 0.145,
              "full_valid_loss": 0.567,
              "full_valid_mean_token_accuracy": 0.944
            },
            "step_number": 88
          }
    FineTuningJobEvent:
      description: Fine-tuning job event object
      example:
        level: info
        created_at: 0
        id: id
        message: message
        object: fine_tuning.job.event
      properties:
        id:
          type: string
        created_at:
          type: integer
        level:
          enum:
          - info
          - warn
          - error
          type: string
        message:
          type: string
        object:
          enum:
          - fine_tuning.job.event
          type: string
      required:
      - created_at
      - id
      - level
      - message
      - object
      type: object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: |
          {
            "object": "fine_tuning.job.event",
            "id": "ftevent-abc123"
            "created_at": 1677610602,
            "level": "info",
            "message": "Created fine-tuning job"
          }
    FinetuneChatRequestInput:
      description: The per-line training example of a fine-tuning input file for chat
        models
      properties:
        messages:
          items:
            $ref: '#/components/schemas/FinetuneChatRequestInput_messages_inner'
          minItems: 1
          type: array
        tools:
          description: A list of tools the model may generate JSON inputs for.
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          type: array
        parallel_tool_calls:
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
            \ during tool use."
          nullable: true
          type: boolean
        functions:
          deprecated: true
          description: A list of functions the model may generate JSON inputs for.
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          maxItems: 128
          minItems: 1
          type: array
      type: object
      x-oaiMeta:
        name: Training format for chat models
        example: |
          {
            "messages": [
              { "role": "user", "content": "What is the weather in San Francisco?" },
              {
                "role": "assistant",
                "tool_calls": [
                  {
                    "id": "call_id",
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
                    }
                  }
                ]
              }
            ],
            "parallel_tool_calls": false,
            "tools": [
              {
                "type": "function",
                "function": {
                  "name": "get_current_weather",
                  "description": "Get the current weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and country, eg. San Francisco, USA"
                      },
                      "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
                    },
                    "required": ["location", "format"]
                  }
                }
              }
            ]
          }
    FinetuneCompletionRequestInput:
      description: The per-line training example of a fine-tuning input file for completions
        models
      properties:
        prompt:
          description: The input prompt for this training example.
          type: string
        completion:
          description: The desired completion for this training example.
          type: string
      type: object
      x-oaiMeta:
        name: Training format for completions models
        example: |
          {
            "prompt": "What is the answer to 2+2",
            "completion": "4"
          }
    FunctionObject:
      example:
        name: name
        description: description
        strict: false
        parameters:
          key: ""
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
        strict:
          default: false
          description: "Whether to enable strict schema adherence when generating\
            \ the function call. If set to true, the model will follow the exact schema\
            \ defined in the `parameters` field. Only a subset of JSON Schema is supported\
            \ when `strict` is `true`. Learn more about Structured Outputs in the\
            \ [function calling guide](docs/guides/function-calling)."
          nullable: true
          type: boolean
      required:
      - name
      type: object
    FunctionParameters:
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list."
      type: object
    Image:
      description: Represents the url or the content of an image generated by the
        OpenAI API.
      example:
        revised_prompt: revised_prompt
        b64_json: b64_json
        url: url
      properties:
        b64_json:
          description: "The base64-encoded JSON of the generated image, if `response_format`\
            \ is `b64_json`."
          type: string
        url:
          description: "The URL of the generated image, if `response_format` is `url`\
            \ (default)."
          type: string
        revised_prompt:
          description: "The prompt that was used to generate the image, if there was\
            \ any revision to the prompt."
          type: string
      type: object
      x-oaiMeta:
        name: The image object
        example: |
          {
            "url": "...",
            "revised_prompt": "..."
          }
    ImagesResponse:
      example:
        data:
        - revised_prompt: revised_prompt
          b64_json: b64_json
          url: url
        - revised_prompt: revised_prompt
          b64_json: b64_json
          url: url
        created: 0
      properties:
        created:
          type: integer
        data:
          items:
            $ref: '#/components/schemas/Image'
          type: array
      required:
      - created
      - data
    Invite:
      description: Represents an individual `invite` to the organization.
      example:
        role: owner
        expires_at: 6
        invited_at: 0
        id: id
        accepted_at: 1
        email: email
        object: organization.invite
        status: accepted
      properties:
        object:
          description: "The object type, which is always `organization.invite`"
          enum:
          - organization.invite
          type: string
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        email:
          description: The email address of the individual to whom the invite was
            sent
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
        status:
          description: "`accepted`,`expired`, or `pending`"
          enum:
          - accepted
          - expired
          - pending
          type: string
        invited_at:
          description: The Unix timestamp (in seconds) of when the invite was sent.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) of when the invite expires.
          type: integer
        accepted_at:
          description: The Unix timestamp (in seconds) of when the invite was accepted.
          type: integer
      required:
      - email
      - expires_at
      - id
      - invited_at
      - object
      - role
      - status
      type: object
      x-oaiMeta:
        name: The invite object
        example: |
          {
            "object": "organization.invite",
            "id": "invite-abc",
            "email": "user@example.com",
            "role": "owner",
            "status": "accepted",
            "invited_at": 1711471533,
            "expires_at": 1711471533,
            "accepted_at": 1711471533
          }
    InviteDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.invite.deleted
      properties:
        object:
          description: "The object type, which is always `organization.invite.deleted`"
          enum:
          - organization.invite.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    InviteListResponse:
      example:
        first_id: first_id
        data:
        - role: owner
          expires_at: 6
          invited_at: 0
          id: id
          accepted_at: 1
          email: email
          object: organization.invite
          status: accepted
        - role: owner
          expires_at: 6
          invited_at: 0
          id: id
          accepted_at: 1
          email: email
          object: organization.invite
          status: accepted
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          description: "The object type, which is always `list`"
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/Invite'
          type: array
        first_id:
          description: The first `invite_id` in the retrieved `list`
          type: string
        last_id:
          description: The last `invite_id` in the retrieved `list`
          type: string
        has_more:
          description: The `has_more` property is used for pagination to indicate
            there are additional results.
          type: boolean
      required:
      - data
      - object
      type: object
    InviteRequest:
      example:
        role: reader
        email: email
      properties:
        email:
          description: Send an email to this address
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - reader
          - owner
          type: string
      required:
      - email
      - role
      type: object
    ListAssistantsResponse:
      example:
        first_id: asst_abc123
        data:
        - instructions: instructions
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
          metadata: "{}"
          created_at: 0
          description: description
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 1
          response_format: auto
          name: name
          temperature: 1
          model: model
          id: id
          object: assistant
        - instructions: instructions
          tool_resources:
            code_interpreter:
              file_ids:
              - file_ids
              - file_ids
              - file_ids
              - file_ids
              - file_ids
            file_search:
              vector_store_ids:
              - vector_store_ids
          metadata: "{}"
          created_at: 0
          description: description
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 1
          response_format: auto
          name: name
          temperature: 1
          model: model
          id: id
          object: assistant
        last_id: asst_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/AssistantObject'
          type: array
        first_id:
          example: asst_abc123
          type: string
        last_id:
          example: asst_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698982736,
                "name": "Coding Tutor",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc456",
                "object": "assistant",
                "created_at": 1698982718,
                "name": "My Assistant",
                "description": null,
                "model": "gpt-4o",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc789",
                "object": "assistant",
                "created_at": 1698982643,
                "name": null,
                "description": null,
                "model": "gpt-4o",
                "instructions": null,
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            ],
            "first_id": "asst_abc123",
            "last_id": "asst_abc789",
            "has_more": false
          }
    ListAuditLogsResponse:
      example:
        first_id: audit_log-defb456h8dks
        data:
        - user.updated:
            changes_requested:
              role: role
            id: id
          organization.updated:
            changes_requested:
              settings:
                threads_ui_visibility: threads_ui_visibility
                usage_dashboard_visibility: usage_dashboard_visibility
              name: name
              description: description
              title: title
            id: id
          project.updated:
            changes_requested:
              title: title
            id: id
          project.archived:
            id: id
          project:
            name: name
            id: id
          service_account.deleted:
            id: id
          type: api_key.created
          logout.failed:
            error_message: error_message
            error_code: error_code
          login.failed:
            error_message: error_message
            error_code: error_code
          user.added:
            data:
              role: role
            id: id
          invite.accepted:
            id: id
          invite.deleted:
            id: id
          actor:
            api_key:
              service_account:
                id: id
              id: id
              type: user
              user:
                id: id
                email: email
            session:
              ip_address: ip_address
              user:
                id: id
                email: email
            type: session
          effective_at: 0
          invite.sent:
            data:
              role: role
              email: email
            id: id
          service_account.updated:
            changes_requested:
              role: role
            id: id
          service_account.created:
            data:
              role: role
            id: id
          api_key.created:
            data:
              scopes:
              - scopes
              - scopes
            id: id
          user.deleted:
            id: id
          id: id
          api_key.deleted:
            id: id
          project.created:
            data:
              name: name
              title: title
            id: id
          api_key.updated:
            changes_requested:
              scopes:
              - scopes
              - scopes
            id: id
        - user.updated:
            changes_requested:
              role: role
            id: id
          organization.updated:
            changes_requested:
              settings:
                threads_ui_visibility: threads_ui_visibility
                usage_dashboard_visibility: usage_dashboard_visibility
              name: name
              description: description
              title: title
            id: id
          project.updated:
            changes_requested:
              title: title
            id: id
          project.archived:
            id: id
          project:
            name: name
            id: id
          service_account.deleted:
            id: id
          type: api_key.created
          logout.failed:
            error_message: error_message
            error_code: error_code
          login.failed:
            error_message: error_message
            error_code: error_code
          user.added:
            data:
              role: role
            id: id
          invite.accepted:
            id: id
          invite.deleted:
            id: id
          actor:
            api_key:
              service_account:
                id: id
              id: id
              type: user
              user:
                id: id
                email: email
            session:
              ip_address: ip_address
              user:
                id: id
                email: email
            type: session
          effective_at: 0
          invite.sent:
            data:
              role: role
              email: email
            id: id
          service_account.updated:
            changes_requested:
              role: role
            id: id
          service_account.created:
            data:
              role: role
            id: id
          api_key.created:
            data:
              scopes:
              - scopes
              - scopes
            id: id
          user.deleted:
            id: id
          id: id
          api_key.deleted:
            id: id
          project.created:
            data:
              name: name
              title: title
            id: id
          api_key.updated:
            changes_requested:
              scopes:
              - scopes
              - scopes
            id: id
        last_id: audit_log-hnbkd8s93s
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/AuditLog'
          type: array
        first_id:
          example: audit_log-defb456h8dks
          type: string
        last_id:
          example: audit_log-hnbkd8s93s
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ListBatchesResponse:
      example:
        first_id: batch_abc123
        data:
        - cancelled_at: 2
          metadata: "{}"
          request_counts:
            total: 4
            completed: 7
            failed: 1
          input_file_id: input_file_id
          output_file_id: output_file_id
          error_file_id: error_file_id
          created_at: 6
          in_progress_at: 1
          expired_at: 9
          finalizing_at: 5
          completed_at: 2
          endpoint: endpoint
          expires_at: 5
          cancelling_at: 3
          completion_window: completion_window
          id: id
          failed_at: 7
          errors:
            data:
            - code: code
              param: param
              line: 0
              message: message
            - code: code
              param: param
              line: 0
              message: message
            object: object
          object: batch
          status: validating
        - cancelled_at: 2
          metadata: "{}"
          request_counts:
            total: 4
            completed: 7
            failed: 1
          input_file_id: input_file_id
          output_file_id: output_file_id
          error_file_id: error_file_id
          created_at: 6
          in_progress_at: 1
          expired_at: 9
          finalizing_at: 5
          completed_at: 2
          endpoint: endpoint
          expires_at: 5
          cancelling_at: 3
          completion_window: completion_window
          id: id
          failed_at: 7
          errors:
            data:
            - code: code
              param: param
              line: 0
              message: message
            - code: code
              param: param
              line: 0
              message: message
            object: object
          object: batch
          status: validating
        last_id: batch_abc456
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: '#/components/schemas/Batch'
          type: array
        first_id:
          example: batch_abc123
          type: string
        last_id:
          example: batch_abc456
          type: string
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
      required:
      - data
      - has_more
      - object
      type: object
    ListFilesResponse:
      example:
        data:
        - filename: filename
          purpose: assistants
          bytes: 0
          created_at: 6
          id: id
          status_details: status_details
          object: file
          status: uploaded
        - filename: filename
          purpose: assistants
          bytes: 0
          created_at: 6
          id: id
          status_details: status_details
          object: file
          status: uploaded
        object: list
      properties:
        data:
          items:
            $ref: '#/components/schemas/OpenAIFile'
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - data
      - object
      type: object
    ListFineTuningJobCheckpointsResponse:
      example:
        first_id: first_id
        data:
        - step_number: 6
          created_at: 0
          fine_tuning_job_id: fine_tuning_job_id
          id: id
          metrics:
            full_valid_mean_token_accuracy: 3.616076749251911
            valid_loss: 2.3021358869347655
            full_valid_loss: 9.301444243932576
            train_mean_token_accuracy: 5.637376656633329
            valid_mean_token_accuracy: 7.061401241503109
            train_loss: 5.962133916683182
            step: 1.4658129805029452
          fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
          object: fine_tuning.job.checkpoint
        - step_number: 6
          created_at: 0
          fine_tuning_job_id: fine_tuning_job_id
          id: id
          metrics:
            full_valid_mean_token_accuracy: 3.616076749251911
            valid_loss: 2.3021358869347655
            full_valid_loss: 9.301444243932576
            train_mean_token_accuracy: 5.637376656633329
            valid_mean_token_accuracy: 7.061401241503109
            train_loss: 5.962133916683182
            step: 1.4658129805029452
          fine_tuned_model_checkpoint: fine_tuned_model_checkpoint
          object: fine_tuning.job.checkpoint
        last_id: last_id
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
          type: array
        object:
          enum:
          - list
          type: string
        first_id:
          nullable: true
          type: string
        last_id:
          nullable: true
          type: string
        has_more:
          type: boolean
      required:
      - data
      - has_more
      - object
      type: object
    ListFineTuningJobEventsResponse:
      example:
        data:
        - level: info
          created_at: 0
          id: id
          message: message
          object: fine_tuning.job.event
        - level: info
          created_at: 0
          id: id
          message: message
          object: fine_tuning.job.event
        object: list
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - data
      - object
      type: object
    ListMessagesResponse:
      example:
        first_id: msg_abc123
        data:
        - metadata: "{}"
          role: user
          assistant_id: assistant_id
          run_id: run_id
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          created_at: 0
          content:
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          completed_at: 6
          thread_id: thread_id
          id: id
          incomplete_at: 1
          incomplete_details:
            reason: content_filter
          object: thread.message
          status: in_progress
        - metadata: "{}"
          role: user
          assistant_id: assistant_id
          run_id: run_id
          attachments:
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          - file_id: file_id
            tools:
            - type: code_interpreter
            - type: code_interpreter
          created_at: 0
          content:
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          - image_file:
              file_id: file_id
              detail: auto
            type: image_file
          completed_at: 6
          thread_id: thread_id
          id: id
          incomplete_at: 1
          incomplete_details:
            reason: content_filter
          object: thread.message
          status: in_progress
        last_id: msg_abc123
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/MessageObject'
          type: array
        first_id:
          example: msg_abc123
          type: string
        last_id:
          example: msg_abc123
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListModelsResponse:
      example:
        data:
        - created: 0
          owned_by: owned_by
          id: id
          object: model
        - created: 0
          owned_by: owned_by
          id: id
          object: model
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/Model'
          type: array
      required:
      - data
      - object
      type: object
    ListPaginatedFineTuningJobsResponse:
      example:
        data:
        - training_file: training_file
          result_files:
          - file-abc123
          - file-abc123
          finished_at: 6
          seed: 5
          fine_tuned_model: fine_tuned_model
          validation_file: validation_file
          created_at: 0
          error:
            code: code
            param: param
            message: message
          estimated_finish: 5
          organization_id: organization_id
          hyperparameters:
            n_epochs: auto
          model: model
          id: id
          trained_tokens: 1
          integrations:
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          object: fine_tuning.job
          status: validating_files
        - training_file: training_file
          result_files:
          - file-abc123
          - file-abc123
          finished_at: 6
          seed: 5
          fine_tuned_model: fine_tuned_model
          validation_file: validation_file
          created_at: 0
          error:
            code: code
            param: param
            message: message
          estimated_finish: 5
          organization_id: organization_id
          hyperparameters:
            n_epochs: auto
          model: model
          id: id
          trained_tokens: 1
          integrations:
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          - wandb:
              name: name
              project: my-wandb-project
              entity: entity
              tags:
              - custom-tag
              - custom-tag
            type: wandb
          object: fine_tuning.job
          status: validating_files
        has_more: true
        object: list
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJob'
          type: array
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
      required:
      - data
      - has_more
      - object
      type: object
    ListRunStepsResponse:
      example:
        first_id: step_abc123
        data:
        - cancelled_at: 1
          metadata: "{}"
          assistant_id: assistant_id
          run_id: run_id
          usage:
            completion_tokens: 2
            prompt_tokens: 7
            total_tokens: 9
          created_at: 0
          expired_at: 6
          type: message_creation
          step_details:
            message_creation:
              message_id: message_id
            type: message_creation
          completed_at: 5
          thread_id: thread_id
          id: id
          last_error:
            code: server_error
            message: message
          failed_at: 5
          object: thread.run.step
          status: in_progress
        - cancelled_at: 1
          metadata: "{}"
          assistant_id: assistant_id
          run_id: run_id
          usage:
            completion_tokens: 2
            prompt_tokens: 7
            total_tokens: 9
          created_at: 0
          expired_at: 6
          type: message_creation
          step_details:
            message_creation:
              message_id: message_id
            type: message_creation
          completed_at: 5
          thread_id: thread_id
          id: id
          last_error:
            code: server_error
            message: message
          failed_at: 5
          object: thread.run.step
          status: in_progress
        last_id: step_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/RunStepObject'
          type: array
        first_id:
          example: step_abc123
          type: string
        last_id:
          example: step_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListRunsResponse:
      example:
        first_id: run_abc123
        data:
        - cancelled_at: 5
          instructions: instructions
          metadata: "{}"
          assistant_id: assistant_id
          required_action:
            submit_tool_outputs:
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
            type: submit_tool_outputs
          usage:
            completion_tokens: 7
            prompt_tokens: 9
            total_tokens: 3
          created_at: 0
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 4.145608029883936
          max_completion_tokens: 256
          thread_id: thread_id
          expires_at: 6
          response_format: auto
          temperature: 2.027123023002322
          tool_choice: none
          model: model
          id: id
          last_error:
            code: server_error
            message: message
          incomplete_details:
            reason: max_completion_tokens
          truncation_strategy:
            last_messages: 1
            type: auto
          completed_at: 2
          parallel_tool_calls: true
          started_at: 1
          failed_at: 5
          max_prompt_tokens: 256
          object: thread.run
          status: queued
        - cancelled_at: 5
          instructions: instructions
          metadata: "{}"
          assistant_id: assistant_id
          required_action:
            submit_tool_outputs:
              tool_calls:
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
              - function:
                  name: name
                  arguments: arguments
                id: id
                type: function
            type: submit_tool_outputs
          usage:
            completion_tokens: 7
            prompt_tokens: 9
            total_tokens: 3
          created_at: 0
          tools:
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          - type: code_interpreter
          top_p: 4.145608029883936
          max_completion_tokens: 256
          thread_id: thread_id
          expires_at: 6
          response_format: auto
          temperature: 2.027123023002322
          tool_choice: none
          model: model
          id: id
          last_error:
            code: server_error
            message: message
          incomplete_details:
            reason: max_completion_tokens
          truncation_strategy:
            last_messages: 1
            type: auto
          completed_at: 2
          parallel_tool_calls: true
          started_at: 1
          failed_at: 5
          max_prompt_tokens: 256
          object: thread.run
          status: queued
        last_id: run_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/RunObject'
          type: array
        first_id:
          example: run_abc123
          type: string
        last_id:
          example: run_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ListThreadsResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/ThreadObject'
          type: array
        first_id:
          example: asst_abc123
          type: string
        last_id:
          example: asst_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListVectorStoreFilesResponse:
      example:
        first_id: file-abc123
        data:
        - chunking_strategy:
            static:
              max_chunk_size_tokens: 685
              chunk_overlap_tokens: 5
            type: static
          usage_bytes: 0
          created_at: 6
          id: id
          last_error:
            code: server_error
            message: message
          object: vector_store.file
          vector_store_id: vector_store_id
          status: in_progress
        - chunking_strategy:
            static:
              max_chunk_size_tokens: 685
              chunk_overlap_tokens: 5
            type: static
          usage_bytes: 0
          created_at: 6
          id: id
          last_error:
            code: server_error
            message: message
          object: vector_store.file
          vector_store_id: vector_store_id
          status: in_progress
        last_id: file-abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
          type: array
        first_id:
          example: file-abc123
          type: string
        last_id:
          example: file-abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    ListVectorStoresResponse:
      example:
        first_id: vs_abc123
        data:
        - file_counts:
            in_progress: 1
            total: 7
            cancelled: 2
            completed: 5
            failed: 5
          metadata: "{}"
          expires_at: 3
          expires_after:
            anchor: last_active_at
            days: 339
          last_active_at: 2
          usage_bytes: 6
          name: name
          created_at: 0
          id: id
          object: vector_store
          status: expired
        - file_counts:
            in_progress: 1
            total: 7
            cancelled: 2
            completed: 5
            failed: 5
          metadata: "{}"
          expires_at: 3
          expires_after:
            anchor: last_active_at
            days: 339
          last_active_at: 2
          usage_bytes: 6
          name: name
          created_at: 0
          id: id
          object: vector_store
          status: expired
        last_id: vs_abc456
        has_more: false
        object: list
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: '#/components/schemas/VectorStoreObject'
          type: array
        first_id:
          example: vs_abc123
          type: string
        last_id:
          example: vs_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    MessageContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      example:
        image_file:
          file_id: file_id
          detail: auto
        type: image_file
      properties:
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
        image_file:
          $ref: '#/components/schemas/MessageContentImageFileObject_image_file'
      required:
      - image_file
      - type
      title: Image file
      type: object
    MessageContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
        image_url:
          $ref: '#/components/schemas/MessageContentImageUrlObject_image_url'
      required:
      - image_url
      - type
      title: Image URL
      type: object
    MessageContentRefusalObject:
      description: The refusal content generated by the assistant.
      properties:
        type:
          description: Always `refusal`.
          enum:
          - refusal
          type: string
        refusal:
          nullable: false
          type: string
      required:
      - refusal
      - type
      title: Refusal
      type: object
    MessageContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject_file_citation'
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_citation
      - start_index
      - text
      - type
      title: File citation
      type: object
    MessageContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject_file_path'
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_path
      - start_index
      - text
      - type
      title: File path
      type: object
    MessageContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          $ref: '#/components/schemas/MessageContentTextObject_text'
      required:
      - text
      - type
      title: Text
      type: object
    MessageDeltaContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
        image_file:
          $ref: '#/components/schemas/MessageDeltaContentImageFileObject_image_file'
      required:
      - index
      - type
      title: Image file
      type: object
    MessageDeltaContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
        image_url:
          $ref: '#/components/schemas/MessageDeltaContentImageUrlObject_image_url'
      required:
      - index
      - type
      title: Image URL
      type: object
    MessageDeltaContentRefusalObject:
      description: The refusal content that is part of a message.
      properties:
        index:
          description: The index of the refusal part in the message.
          type: integer
        type:
          description: Always `refusal`.
          enum:
          - refusal
          type: string
        refusal:
          type: string
      required:
      - index
      - type
      title: Refusal
      type: object
    MessageDeltaContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject_file_citation'
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File citation
      type: object
    MessageDeltaContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject_file_path'
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File path
      type: object
    MessageDeltaContentTextObject:
      description: The text content that is part of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          $ref: '#/components/schemas/MessageDeltaContentTextObject_text'
      required:
      - index
      - type
      title: Text
      type: object
    MessageDeltaObject:
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming.
      properties:
        id:
          description: "The identifier of the message, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message.delta`."
          enum:
          - thread.message.delta
          type: string
        delta:
          $ref: '#/components/schemas/MessageDeltaObject_delta'
      required:
      - delta
      - id
      - object
      title: Message delta object
      type: object
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: |
          {
            "id": "msg_123",
            "object": "thread.message.delta",
            "delta": {
              "content": [
                {
                  "index": 0,
                  "type": "text",
                  "text": { "value": "Hello", "annotations": [] }
                }
              ]
            }
          }
    MessageObject:
      description: "Represents a message within a [thread](/docs/api-reference/threads)."
      example:
        metadata: "{}"
        role: user
        assistant_id: assistant_id
        run_id: run_id
        attachments:
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        - file_id: file_id
          tools:
          - type: code_interpreter
          - type: code_interpreter
        created_at: 0
        content:
        - image_file:
            file_id: file_id
            detail: auto
          type: image_file
        - image_file:
            file_id: file_id
            detail: auto
          type: image_file
        completed_at: 6
        thread_id: thread_id
        id: id
        incomplete_at: 1
        incomplete_details:
          reason: content_filter
        object: thread.message
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message`."
          enum:
          - thread.message
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        thread_id:
          description: "The [thread](/docs/api-reference/threads) ID that this message\
            \ belongs to."
          type: string
        status:
          description: "The status of the message, which can be either `in_progress`,\
            \ `incomplete`, or `completed`."
          enum:
          - in_progress
          - incomplete
          - completed
          type: string
        incomplete_details:
          $ref: '#/components/schemas/MessageObject_incomplete_details'
        completed_at:
          description: The Unix timestamp (in seconds) for when the message was completed.
          nullable: true
          type: integer
        incomplete_at:
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete.
          nullable: true
          type: integer
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: '#/components/schemas/MessageObject_content_inner'
          type: array
        assistant_id:
          description: "If applicable, the ID of the [assistant](/docs/api-reference/assistants)\
            \ that authored this message."
          nullable: true
          type: string
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) associated with\
            \ the creation of this message. Value is `null` when messages are created\
            \ manually using the create message or create thread endpoints."
          nullable: true
          type: string
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ were added to."
          items:
            $ref: '#/components/schemas/CreateMessageRequest_attachments_inner'
          nullable: true
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - assistant_id
      - attachments
      - content
      - created_at
      - id
      - metadata
      - object
      - role
      - run_id
      - status
      - thread_id
      title: The message object
      type: object
      x-oaiMeta:
        name: The message object
        beta: true
        example: |
          {
            "id": "msg_abc123",
            "object": "thread.message",
            "created_at": 1698983503,
            "thread_id": "thread_abc123",
            "role": "assistant",
            "content": [
              {
                "type": "text",
                "text": {
                  "value": "Hi! How can I help you today?",
                  "annotations": []
                }
              }
            ],
            "assistant_id": "asst_abc123",
            "run_id": "run_abc123",
            "attachments": [],
            "metadata": {}
          }
    MessageRequestContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          description: Text content to be sent to the model
          type: string
      required:
      - text
      - type
      title: Text
      type: object
    MessageStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/MessageStreamEvent_oneOf'
      - $ref: '#/components/schemas/MessageStreamEvent_oneOf_1'
      - $ref: '#/components/schemas/MessageStreamEvent_oneOf_2'
      - $ref: '#/components/schemas/MessageStreamEvent_oneOf_3'
      - $ref: '#/components/schemas/MessageStreamEvent_oneOf_4'
    Model:
      description: Describes an OpenAI model offering that can be used with the API.
      example:
        created: 0
        owned_by: owned_by
        id: id
        object: model
      properties:
        id:
          description: "The model identifier, which can be referenced in the API endpoints."
          type: string
        created:
          description: The Unix timestamp (in seconds) when the model was created.
          type: integer
        object:
          description: "The object type, which is always \"model\"."
          enum:
          - model
          type: string
        owned_by:
          description: The organization that owns the model.
          type: string
      required:
      - created
      - id
      - object
      - owned_by
      title: Model
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    ModifyAssistantRequest:
      additionalProperties: false
      example:
        top_p: 1
        instructions: instructions
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata: "{}"
        response_format: auto
        name: name
        temperature: 1
        description: description
        model: model
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
      properties:
        model:
          type: string
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: '#/components/schemas/AssistantObject_tools_inner'
          maxItems: 128
          type: array
        tool_resources:
          $ref: '#/components/schemas/ModifyAssistantRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      type: object
    ModifyMessageRequest:
      additionalProperties: false
      example:
        metadata: "{}"
      properties:
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    ModifyRunRequest:
      additionalProperties: false
      example:
        metadata: "{}"
      properties:
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    ModifyThreadRequest:
      additionalProperties: false
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata: "{}"
      properties:
        tool_resources:
          $ref: '#/components/schemas/ModifyThreadRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    OpenAIFile:
      description: The `File` object represents a document that has been uploaded
        to OpenAI.
      example:
        filename: filename
        purpose: assistants
        bytes: 0
        created_at: 6
        id: id
        status_details: status_details
        object: file
        status: uploaded
      properties:
        id:
          description: "The file identifier, which can be referenced in the API endpoints."
          type: string
        bytes:
          description: "The size of the file, in bytes."
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the file was created.
          type: integer
        filename:
          description: The name of the file.
          type: string
        object:
          description: "The object type, which is always `file`."
          enum:
          - file
          type: string
        purpose:
          description: "The intended purpose of the file. Supported values are `assistants`,\
            \ `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\
            \ and `vision`."
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
          type: string
        status:
          deprecated: true
          description: "Deprecated. The current status of the file, which can be either\
            \ `uploaded`, `processed`, or `error`."
          enum:
          - uploaded
          - processed
          - error
          type: string
        status_details:
          deprecated: true
          description: "Deprecated. For details on why a fine-tuning training file\
            \ failed validation, see the `error` field on `fine_tuning.job`."
          type: string
      required:
      - bytes
      - created_at
      - filename
      - id
      - object
      - purpose
      - status
      title: OpenAIFile
      x-oaiMeta:
        name: The file object
        example: |
          {
            "id": "file-abc123",
            "object": "file",
            "bytes": 120000,
            "created_at": 1677610602,
            "filename": "salesOverview.pdf",
            "purpose": "assistants",
          }
    OtherChunkingStrategyResponseParam:
      additionalProperties: false
      description: "This is returned when the chunking strategy is unknown. Typically,\
        \ this is because the file was indexed before the `chunking_strategy` concept\
        \ was introduced in the API."
      properties:
        type:
          description: Always `other`.
          enum:
          - other
          type: string
      required:
      - type
      title: Other Chunking Strategy
      type: object
    ParallelToolCalls:
      description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
        \ during tool use."
      nullable: true
      type: boolean
    Project:
      description: Represents an individual project.
      example:
        archived_at: 6
        name: name
        created_at: 0
        id: id
        object: organization.project
        status: active
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        object:
          description: "The object type, which is always `organization.project`"
          enum:
          - organization.project
          type: string
        name:
          description: The name of the project. This appears in reporting.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the project was created.
          type: integer
        archived_at:
          description: The Unix timestamp (in seconds) of when the project was archived
            or `null`.
          nullable: true
          type: integer
        status:
          description: '`active` or `archived`'
          enum:
          - active
          - archived
          type: string
      required:
      - created_at
      - id
      - name
      - object
      - status
      type: object
      x-oaiMeta:
        name: The project object
        example: |
          {
              "id": "proj_abc",
              "object": "organization.project",
              "name": "Project example",
              "created_at": 1711471533,
              "archived_at": null,
              "status": "active"
          }
    ProjectApiKey:
      description: Represents an individual API key in a project.
      example:
        owner:
          service_account:
            role: owner
            name: name
            created_at: 1
            id: id
            object: organization.project.service_account
          type: user
          user:
            added_at: 6
            role: owner
            name: name
            id: id
            email: email
            object: organization.project.user
        name: name
        created_at: 0
        redacted_value: redacted_value
        id: id
        object: organization.project.api_key
      properties:
        object:
          description: "The object type, which is always `organization.project.api_key`"
          enum:
          - organization.project.api_key
          type: string
        redacted_value:
          description: The redacted value of the API key
          type: string
        name:
          description: The name of the API key
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the API key was created
          type: integer
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        owner:
          $ref: '#/components/schemas/ProjectApiKey_owner'
      required:
      - created_at
      - id
      - name
      - object
      - owner
      - redacted_value
      type: object
      x-oaiMeta:
        name: The project API key object
        example: |
          {
              "object": "organization.project.api_key",
              "redacted_value": "sk-abc...def",
              "name": "My API Key",
              "created_at": 1711471533,
              "id": "key_abc",
              "owner": {
                  "type": "user",
                  "user": {
                      "object": "organization.project.user",
                      "id": "user_abc",
                      "name": "First Last",
                      "email": "user@example.com",
                      "role": "owner",
                      "created_at": 1711471533
                  }
              }
          }
    ProjectApiKeyDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.api_key.deleted
      properties:
        object:
          enum:
          - organization.project.api_key.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    ProjectApiKeyListResponse:
      example:
        first_id: first_id
        data:
        - owner:
            service_account:
              role: owner
              name: name
              created_at: 1
              id: id
              object: organization.project.service_account
            type: user
            user:
              added_at: 6
              role: owner
              name: name
              id: id
              email: email
              object: organization.project.user
          name: name
          created_at: 0
          redacted_value: redacted_value
          id: id
          object: organization.project.api_key
        - owner:
            service_account:
              role: owner
              name: name
              created_at: 1
              id: id
              object: organization.project.service_account
            type: user
            user:
              added_at: 6
              role: owner
              name: name
              id: id
              email: email
              object: organization.project.user
          name: name
          created_at: 0
          redacted_value: redacted_value
          id: id
          object: organization.project.api_key
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/ProjectApiKey'
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ProjectCreateRequest:
      example:
        name: name
      properties:
        name:
          description: "The friendly name of the project, this name appears in reports."
          type: string
      required:
      - name
      type: object
    ProjectListResponse:
      example:
        first_id: first_id
        data:
        - archived_at: 6
          name: name
          created_at: 0
          id: id
          object: organization.project
          status: active
        - archived_at: 6
          name: name
          created_at: 0
          id: id
          object: organization.project
          status: active
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/Project'
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ProjectServiceAccount:
      description: Represents an individual service account in a project.
      example:
        role: owner
        name: name
        created_at: 1
        id: id
        object: organization.project.service_account
      properties:
        object:
          description: "The object type, which is always `organization.project.service_account`"
          enum:
          - organization.project.service_account
          type: string
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the service account
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
        created_at:
          description: The Unix timestamp (in seconds) of when the service account
            was created
          type: integer
      required:
      - created_at
      - id
      - name
      - object
      - role
      type: object
      x-oaiMeta:
        name: The project service account object
        example: |
          {
              "object": "organization.project.service_account",
              "id": "svc_acct_abc",
              "name": "Service Account",
              "role": "owner",
              "created_at": 1711471533
          }
    ProjectServiceAccountApiKey:
      example:
        name: name
        created_at: 6
        id: id
        value: value
        object: organization.project.service_account.api_key
      properties:
        object:
          description: "The object type, which is always `organization.project.service_account.api_key`"
          enum:
          - organization.project.service_account.api_key
          type: string
        value:
          type: string
        name:
          type: string
        created_at:
          type: integer
        id:
          type: string
      required:
      - created_at
      - id
      - name
      - object
      - value
      type: object
    ProjectServiceAccountCreateRequest:
      example:
        name: name
      properties:
        name:
          description: The name of the service account being created.
          type: string
      required:
      - name
      type: object
    ProjectServiceAccountCreateResponse:
      example:
        role: member
        api_key:
          name: name
          created_at: 6
          id: id
          value: value
          object: organization.project.service_account.api_key
        name: name
        created_at: 0
        id: id
        object: organization.project.service_account
      properties:
        object:
          enum:
          - organization.project.service_account
          type: string
        id:
          type: string
        name:
          type: string
        role:
          description: Service accounts can only have one role of type `member`
          enum:
          - member
          type: string
        created_at:
          type: integer
        api_key:
          $ref: '#/components/schemas/ProjectServiceAccountApiKey'
      required:
      - api_key
      - created_at
      - id
      - name
      - object
      - role
      type: object
    ProjectServiceAccountDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.service_account.deleted
      properties:
        object:
          enum:
          - organization.project.service_account.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    ProjectServiceAccountListResponse:
      example:
        first_id: first_id
        data:
        - role: owner
          name: name
          created_at: 1
          id: id
          object: organization.project.service_account
        - role: owner
          name: name
          created_at: 1
          id: id
          object: organization.project.service_account
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/ProjectServiceAccount'
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ProjectUpdateRequest:
      example:
        name: name
      properties:
        name:
          description: "The updated name of the project, this name appears in reports."
          type: string
      required:
      - name
      type: object
    ProjectUser:
      description: Represents an individual user in a project.
      example:
        added_at: 6
        role: owner
        name: name
        id: id
        email: email
        object: organization.project.user
      properties:
        object:
          description: "The object type, which is always `organization.project.user`"
          enum:
          - organization.project.user
          type: string
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the user
          type: string
        email:
          description: The email address of the user
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
        added_at:
          description: The Unix timestamp (in seconds) of when the project was added.
          type: integer
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      type: object
      x-oaiMeta:
        name: The project user object
        example: |
          {
              "object": "organization.project.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    ProjectUserCreateRequest:
      example:
        role: owner
        user_id: user_id
      properties:
        user_id:
          description: The ID of the user.
          type: string
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
      required:
      - role
      - user_id
      type: object
    ProjectUserDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.project.user.deleted
      properties:
        object:
          enum:
          - organization.project.user.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    ProjectUserListResponse:
      example:
        first_id: first_id
        data:
        - added_at: 6
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
        - added_at: 6
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
        last_id: last_id
        has_more: true
        object: object
      properties:
        object:
          type: string
        data:
          items:
            $ref: '#/components/schemas/ProjectUser'
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ProjectUserUpdateRequest:
      example:
        role: owner
      properties:
        role:
          description: '`owner` or `member`'
          enum:
          - owner
          - member
          type: string
      required:
      - role
      type: object
    RealtimeClientEventConversationItemCreate:
      description: Send this event when adding an item to the conversation.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.create\"."
          type: string
        previous_item_id:
          description: The ID of the preceding item after which the new item will
            be inserted.
          type: string
        item:
          $ref: '#/components/schemas/RealtimeClientEventConversationItemCreate_item'
      required:
      - item
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.create
        group: realtime
        example: |
          {
              "event_id": "event_345",
              "type": "conversation.item.create",
              "previous_item_id": null,
              "item": {
                  "id": "msg_001",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_text",
                          "text": "Hello, how are you?"
                      }
                  ]
              }
          }
    RealtimeClientEventConversationItemDelete:
      description: Send this event when you want to remove any item from the conversation
        history.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.delete\"."
          type: string
        item_id:
          description: The ID of the item to delete.
          type: string
      required:
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.delete
        group: realtime
        example: |
          {
              "event_id": "event_901",
              "type": "conversation.item.delete",
              "item_id": "msg_003"
          }
    RealtimeClientEventConversationItemTruncate:
      description: Send this event when you want to truncate a previous assistant
        message’s audio.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.truncate\"."
          type: string
        item_id:
          description: The ID of the assistant message item to truncate.
          type: string
        content_index:
          description: The index of the content part to truncate.
          type: integer
        audio_end_ms:
          description: "Inclusive duration up to which audio is truncated, in milliseconds."
          type: integer
      required:
      - audio_end_ms
      - content_index
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.truncate
        group: realtime
        example: |
          {
              "event_id": "event_678",
              "type": "conversation.item.truncate",
              "item_id": "msg_002",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    RealtimeClientEventInputAudioBufferAppend:
      description: Send this event to append audio bytes to the input audio buffer.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.append\"."
          type: string
        audio:
          description: Base64-encoded audio bytes.
          type: string
      required:
      - audio
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.append
        group: realtime
        example: |
          {
              "event_id": "event_456",
              "type": "input_audio_buffer.append",
              "audio": "Base64EncodedAudioData"
          }
    RealtimeClientEventInputAudioBufferClear:
      description: Send this event to clear the audio bytes in the buffer.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.clear\"."
          type: string
      required:
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.clear
        group: realtime
        example: |
          {
              "event_id": "event_012",
              "type": "input_audio_buffer.clear"
          }
    RealtimeClientEventInputAudioBufferCommit:
      description: Send this event to commit audio bytes to a user message.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.commit\"."
          type: string
      required:
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.commit
        group: realtime
        example: |
          {
              "event_id": "event_789",
              "type": "input_audio_buffer.commit"
          }
    RealtimeClientEventResponseCancel:
      description: Send this event to cancel an in-progress response.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"response.cancel\"."
          type: string
      required:
      - type
      type: object
      x-oaiMeta:
        name: response.cancel
        group: realtime
        example: |
          {
              "event_id": "event_567",
              "type": "response.cancel"
          }
    RealtimeClientEventResponseCreate:
      description: Send this event to trigger a response generation.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"response.create\"."
          type: string
        response:
          $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response'
      required:
      - response
      - type
      type: object
      x-oaiMeta:
        name: response.create
        group: realtime
        example: |
          {
              "event_id": "event_234",
              "type": "response.create",
              "response": {
                  "modalities": ["text", "audio"],
                  "instructions": "Please assist the user.",
                  "voice": "alloy",
                  "output_audio_format": "pcm16",
                  "tools": [
                      {
                          "type": "function",
                          "name": "calculate_sum",
                          "description": "Calculates the sum of two numbers.",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "a": { "type": "number" },
                                  "b": { "type": "number" }
                              },
                              "required": ["a", "b"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.7,
                  "max_output_tokens": 150
              }
          }
    RealtimeClientEventSessionUpdate:
      description: Send this event to update the session’s default configuration.
      properties:
        event_id:
          description: Optional client-generated ID used to identify this event.
          type: string
        type:
          description: "The event type, must be \"session.update\"."
          type: string
        session:
          $ref: '#/components/schemas/RealtimeClientEventSessionUpdate_session'
      required:
      - session
      - type
      type: object
      x-oaiMeta:
        name: session.update
        group: realtime
        example: |
          {
              "event_id": "event_123",
              "type": "session.update",
              "session": {
                  "modalities": ["text", "audio"],
                  "instructions": "Your knowledge cutoff is 2023-10. You are a helpful assistant.",
                  "voice": "alloy",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "model": "whisper-1"
                  },
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 200
                  },
                  "tools": [
                      {
                          "type": "function",
                          "name": "get_weather",
                          "description": "Get the current weather for a location.",
                          "parameters": {
                              "type": "object",
                              "properties": {
                                  "location": { "type": "string" }
                              },
                              "required": ["location"]
                          }
                      }
                  ],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_output_tokens": null
              }
          }
    RealtimeServerEventConversationCreated:
      description: Returned when a conversation is created. Emitted right after session
        creation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.created\"."
          type: string
        conversation:
          $ref: '#/components/schemas/RealtimeServerEventConversationCreated_conversation'
      required:
      - conversation
      - event_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.created
        group: realtime
        example: |
          {
              "event_id": "event_9101",
              "type": "conversation.created",
              "conversation": {
                  "id": "conv_001",
                  "object": "realtime.conversation"
              }
          }
    RealtimeServerEventConversationItemCreated:
      description: Returned when a conversation item is created.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.created\"."
          type: string
        previous_item_id:
          description: The ID of the preceding item.
          type: string
        item:
          $ref: '#/components/schemas/RealtimeServerEventConversationItemCreated_item'
      required:
      - event_id
      - item
      - previous_item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.created
        group: realtime
        example: |
          {
              "event_id": "event_1920",
              "type": "conversation.item.created",
              "previous_item_id": "msg_002",
              "item": {
                  "id": "msg_003",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "user",
                  "content": [
                      {
                          "type": "input_audio",
                          "transcript": null
                      }
                  ]
              }
          }
    RealtimeServerEventConversationItemDeleted:
      description: Returned when an item in the conversation is deleted.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.deleted\"."
          type: string
        item_id:
          description: The ID of the item that was deleted.
          type: string
      required:
      - event_id
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.deleted
        group: realtime
        example: |
          {
              "event_id": "event_2728",
              "type": "conversation.item.deleted",
              "item_id": "msg_005"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionCompleted:
      description: Returned when input audio transcription is enabled and a transcription
        succeeds.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.input_audio_transcription.completed\"\
            ."
          type: string
        item_id:
          description: The ID of the user message item.
          type: string
        content_index:
          description: The index of the content part containing the audio.
          type: integer
        transcript:
          description: The transcribed text.
          type: string
      required:
      - content_index
      - event_id
      - item_id
      - transcript
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.completed
        group: realtime
        example: |
          {
              "event_id": "event_2122",
              "type": "conversation.item.input_audio_transcription.completed",
              "item_id": "msg_003",
              "content_index": 0,
              "transcript": "Hello, how are you?"
          }
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed:
      description: "Returned when input audio transcription is configured, and a transcription\
        \ request for a user message failed."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.input_audio_transcription.failed\"\
            ."
          type: string
        item_id:
          description: The ID of the user message item.
          type: string
        content_index:
          description: The index of the content part containing the audio.
          type: integer
        error:
          $ref: '#/components/schemas/RealtimeServerEventConversationItemInputAudioTranscriptionFailed_error'
      required:
      - content_index
      - error
      - event_id
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.input_audio_transcription.failed
        group: realtime
        example: |
          {
              "event_id": "event_2324",
              "type": "conversation.item.input_audio_transcription.failed",
              "item_id": "msg_003",
              "content_index": 0,
              "error": {
                  "type": "transcription_error",
                  "code": "audio_unintelligible",
                  "message": "The audio could not be transcribed.",
                  "param": null
              }
          }
    RealtimeServerEventConversationItemTruncated:
      description: Returned when an earlier assistant audio message item is truncated
        by the client.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"conversation.item.truncated\"."
          type: string
        item_id:
          description: The ID of the assistant message item that was truncated.
          type: string
        content_index:
          description: The index of the content part that was truncated.
          type: integer
        audio_end_ms:
          description: "The duration up to which the audio was truncated, in milliseconds."
          type: integer
      required:
      - audio_end_ms
      - content_index
      - event_id
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: conversation.item.truncated
        group: realtime
        example: |
          {
              "event_id": "event_2526",
              "type": "conversation.item.truncated",
              "item_id": "msg_004",
              "content_index": 0,
              "audio_end_ms": 1500
          }
    RealtimeServerEventError:
      description: Returned when an error occurs.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"error\"."
          type: string
        error:
          $ref: '#/components/schemas/RealtimeServerEventError_error'
      required:
      - error
      - event_id
      - type
      type: object
      x-oaiMeta:
        name: error
        group: realtime
        example: |
          {
              "event_id": "event_890",
              "type": "error",
              "error": {
                  "type": "invalid_request_error",
                  "code": "invalid_event",
                  "message": "The 'type' field is missing.",
                  "param": null,
                  "event_id": "event_567"
              }
          }
    RealtimeServerEventInputAudioBufferCleared:
      description: Returned when the input audio buffer is cleared by the client.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.cleared\"."
          type: string
      required:
      - event_id
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.cleared
        group: realtime
        example: |
          {
              "event_id": "event_1314",
              "type": "input_audio_buffer.cleared"
          }
    RealtimeServerEventInputAudioBufferCommitted:
      description: "Returned when an input audio buffer is committed, either by the\
        \ client or automatically in server VAD mode."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.committed\"."
          type: string
        previous_item_id:
          description: The ID of the preceding item after which the new item will
            be inserted.
          type: string
        item_id:
          description: The ID of the user message item that will be created.
          type: string
      required:
      - event_id
      - item_id
      - previous_item_id
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.committed
        group: realtime
        example: |
          {
              "event_id": "event_1121",
              "type": "input_audio_buffer.committed",
              "previous_item_id": "msg_001",
              "item_id": "msg_002"
          }
    RealtimeServerEventInputAudioBufferSpeechStarted:
      description: Returned in server turn detection mode when speech is detected.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.speech_started\"\
            ."
          type: string
        audio_start_ms:
          description: Milliseconds since the session started when speech was detected.
          type: integer
        item_id:
          description: The ID of the user message item that will be created when speech
            stops.
          type: string
      required:
      - audio_start_ms
      - event_id
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.speech_started
        group: realtime
        example: |
          {
              "event_id": "event_1516",
              "type": "input_audio_buffer.speech_started",
              "audio_start_ms": 1000,
              "item_id": "msg_003"
          }
    RealtimeServerEventInputAudioBufferSpeechStopped:
      description: Returned in server turn detection mode when speech stops.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"input_audio_buffer.speech_stopped\"\
            ."
          type: string
        audio_end_ms:
          description: Milliseconds since the session started when speech stopped.
          type: integer
        item_id:
          description: The ID of the user message item that will be created.
          type: string
      required:
      - audio_end_ms
      - event_id
      - item_id
      - type
      type: object
      x-oaiMeta:
        name: input_audio_buffer.speech_stopped
        group: realtime
        example: |
          {
              "event_id": "event_1718",
              "type": "input_audio_buffer.speech_stopped",
              "audio_end_ms": 2000,
              "item_id": "msg_003"
          }
    RealtimeServerEventRateLimitsUpdated:
      description: Emitted after every "response.done" event to indicate the updated
        rate limits.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"rate_limits.updated\"."
          type: string
        rate_limits:
          description: List of rate limit information.
          items:
            $ref: '#/components/schemas/RealtimeServerEventRateLimitsUpdated_rate_limits_inner'
          type: array
      required:
      - event_id
      - rate_limits
      - type
      type: object
      x-oaiMeta:
        name: rate_limits.updated
        group: realtime
        example: |
          {
              "event_id": "event_5758",
              "type": "rate_limits.updated",
              "rate_limits": [
                  {
                      "name": "requests",
                      "limit": 1000,
                      "remaining": 999,
                      "reset_seconds": 60
                  },
                  {
                      "name": "tokens",
                      "limit": 50000,
                      "remaining": 49950,
                      "reset_seconds": 60
                  }
              ]
          }
    RealtimeServerEventResponseAudioDelta:
      description: Returned when the model-generated audio is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.audio.delta\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: Base64-encoded audio data delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.audio.delta
        group: realtime
        example: |
          {
              "event_id": "event_4950",
              "type": "response.audio.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Base64EncodedAudioDelta"
          }
    RealtimeServerEventResponseAudioDone:
      description: "Returned when the model-generated audio is done. Also emitted\
        \ when a Response is interrupted, incomplete, or cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.audio.done\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.audio.done
        group: realtime
        example: |
          {
              "event_id": "event_5152",
              "type": "response.audio.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0
          }
    RealtimeServerEventResponseAudioTranscriptDelta:
      description: Returned when the model-generated transcription of audio output
        is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.audio_transcript.delta\"\
            ."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: The transcript delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.audio_transcript.delta
        group: realtime
        example: |
          {
              "event_id": "event_4546",
              "type": "response.audio_transcript.delta",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "delta": "Hello, how can I a"
          }
    RealtimeServerEventResponseAudioTranscriptDone:
      description: "Returned when the model-generated transcription of audio output\
        \ is done streaming. Also emitted when a Response is interrupted, incomplete,\
        \ or cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.audio_transcript.done\"\
            ."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        transcript:
          description: The final transcript of the audio.
          type: string
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - transcript
      - type
      type: object
      x-oaiMeta:
        name: response.audio_transcript.done
        group: realtime
        example: |
          {
              "event_id": "event_4748",
              "type": "response.audio_transcript.done",
              "response_id": "resp_001",
              "item_id": "msg_008",
              "output_index": 0,
              "content_index": 0,
              "transcript": "Hello, how can I assist you today?"
          }
    RealtimeServerEventResponseContentPartAdded:
      description: Returned when a new content part is added to an assistant message
        item during response generation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.content_part.added\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item to which the content part was added.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        part:
          $ref: '#/components/schemas/RealtimeServerEventResponseContentPartAdded_part'
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.content_part.added
        group: realtime
        example: |
          {
              "event_id": "event_3738",
              "type": "response.content_part.added",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": ""
              }
          }
    RealtimeServerEventResponseContentPartDone:
      description: "Returned when a content part is done streaming in an assistant\
        \ message item. Also emitted when a Response is interrupted, incomplete, or\
        \ cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.content_part.done\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        part:
          $ref: '#/components/schemas/RealtimeServerEventResponseContentPartDone_part'
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - part
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.content_part.done
        group: realtime
        example: |
          {
              "event_id": "event_3940",
              "type": "response.content_part.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "part": {
                  "type": "text",
                  "text": "Sure, I can help with that."
              }
          }
    RealtimeServerEventResponseCreated:
      description: "Returned when a new Response is created. The first event of response\
        \ creation, where the response is in an initial state of \"in_progress\"."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.created\"."
          type: string
        response:
          $ref: '#/components/schemas/RealtimeServerEventResponseCreated_response'
      required:
      - event_id
      - response
      - type
      type: object
      x-oaiMeta:
        name: response.created
        group: realtime
        example: |
          {
              "event_id": "event_2930",
              "type": "response.created",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "in_progress",
                  "status_details": null,
                  "output": [],
                  "usage": null
              }
          }
    RealtimeServerEventResponseDone:
      description: "Returned when a Response is done streaming. Always emitted, no\
        \ matter the final state."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.done\"."
          type: string
        response:
          $ref: '#/components/schemas/RealtimeServerEventResponseDone_response'
      required:
      - event_id
      - response
      - type
      type: object
      x-oaiMeta:
        name: response.done
        group: realtime
        example: |
          {
              "event_id": "event_3132",
              "type": "response.done",
              "response": {
                  "id": "resp_001",
                  "object": "realtime.response",
                  "status": "completed",
                  "status_details": null,
                  "output": [
                      {
                          "id": "msg_006",
                          "object": "realtime.item",
                          "type": "message",
                          "status": "completed",
                          "role": "assistant",
                          "content": [
                              {
                                  "type": "text",
                                  "text": "Sure, how can I assist you today?"
                              }
                          ]
                      }
                  ],
                  "usage": {
                      "total_tokens": 50,
                      "input_tokens": 20,
                      "output_tokens": 30
                  }
              }
          }
    RealtimeServerEventResponseFunctionCallArgumentsDelta:
      description: Returned when the model-generated function call arguments are updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.function_call_arguments.delta\"\
            ."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the function call item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        call_id:
          description: The ID of the function call.
          type: string
        delta:
          description: The arguments delta as a JSON string.
          type: string
      required:
      - call_id
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.function_call_arguments.delta
        group: realtime
        example: |
          {
              "event_id": "event_5354",
              "type": "response.function_call_arguments.delta",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "delta": "{\"location\": \"San\""
          }
    RealtimeServerEventResponseFunctionCallArgumentsDone:
      description: "Returned when the model-generated function call arguments are\
        \ done streaming. Also emitted when a Response is interrupted, incomplete,\
        \ or cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.function_call_arguments.done\"\
            ."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the function call item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        call_id:
          description: The ID of the function call.
          type: string
        arguments:
          description: The final arguments as a JSON string.
          type: string
      required:
      - arguments
      - call_id
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.function_call_arguments.done
        group: realtime
        example: |
          {
              "event_id": "event_5556",
              "type": "response.function_call_arguments.done",
              "response_id": "resp_002",
              "item_id": "fc_001",
              "output_index": 0,
              "call_id": "call_001",
              "arguments": "{\"location\": \"San Francisco\"}"
          }
    RealtimeServerEventResponseOutputItemAdded:
      description: Returned when a new Item is created during response generation.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.output_item.added\"."
          type: string
        response_id:
          description: The ID of the response to which the item belongs.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        item:
          $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemAdded_item'
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.output_item.added
        group: realtime
        example: |
          {
              "event_id": "event_3334",
              "type": "response.output_item.added",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "in_progress",
                  "role": "assistant",
                  "content": []
              }
          }
    RealtimeServerEventResponseOutputItemDone:
      description: "Returned when an Item is done streaming. Also emitted when a Response\
        \ is interrupted, incomplete, or cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.output_item.done\"."
          type: string
        response_id:
          description: The ID of the response to which the item belongs.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        item:
          $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemDone_item'
      required:
      - event_id
      - item
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.output_item.done
        group: realtime
        example: |
          {
              "event_id": "event_3536",
              "type": "response.output_item.done",
              "response_id": "resp_001",
              "output_index": 0,
              "item": {
                  "id": "msg_007",
                  "object": "realtime.item",
                  "type": "message",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                      {
                          "type": "text",
                          "text": "Sure, I can help with that."
                      }
                  ]
              }
          }
    RealtimeServerEventResponseTextDelta:
      description: Returned when the text value of a "text" content part is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.text.delta\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        delta:
          description: The text delta.
          type: string
      required:
      - content_index
      - delta
      - event_id
      - item_id
      - output_index
      - response_id
      - type
      type: object
      x-oaiMeta:
        name: response.text.delta
        group: realtime
        example: |
          {
              "event_id": "event_4142",
              "type": "response.text.delta",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "delta": "Sure, I can h"
          }
    RealtimeServerEventResponseTextDone:
      description: "Returned when the text value of a \"text\" content part is done\
        \ streaming. Also emitted when a Response is interrupted, incomplete, or cancelled."
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"response.text.done\"."
          type: string
        response_id:
          description: The ID of the response.
          type: string
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item in the response.
          type: integer
        content_index:
          description: The index of the content part in the item's content array.
          type: integer
        text:
          description: The final text content.
          type: string
      required:
      - content_index
      - event_id
      - item_id
      - output_index
      - response_id
      - text
      - type
      type: object
      x-oaiMeta:
        name: response.text.done
        group: realtime
        example: |
          {
              "event_id": "event_4344",
              "type": "response.text.done",
              "response_id": "resp_001",
              "item_id": "msg_007",
              "output_index": 0,
              "content_index": 0,
              "text": "Sure, I can help with that."
          }
    RealtimeServerEventSessionCreated:
      description: Returned when a session is created. Emitted automatically when
        a new connection is established.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"session.created\"."
          type: string
        session:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session'
      required:
      - event_id
      - session
      - type
      type: object
      x-oaiMeta:
        name: session.created
        group: realtime
        example: |
          {
              "event_id": "event_1234",
              "type": "session.created",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview-2024-10-01",
                  "modalities": ["text", "audio"],
                  "instructions": "",
                  "voice": "alloy",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": null,
                  "turn_detection": {
                      "type": "server_vad",
                      "threshold": 0.5,
                      "prefix_padding_ms": 300,
                      "silence_duration_ms": 200
                  },
                  "tools": [],
                  "tool_choice": "auto",
                  "temperature": 0.8,
                  "max_output_tokens": null
              }
          }
    RealtimeServerEventSessionUpdated:
      description: Returned when a session is updated.
      properties:
        event_id:
          description: The unique ID of the server event.
          type: string
        type:
          description: "The event type, must be \"session.updated\"."
          type: string
        session:
          $ref: '#/components/schemas/RealtimeServerEventSessionUpdated_session'
      required:
      - event_id
      - session
      - type
      type: object
      x-oaiMeta:
        name: session.updated
        group: realtime
        example: |
          {
              "event_id": "event_5678",
              "type": "session.updated",
              "session": {
                  "id": "sess_001",
                  "object": "realtime.session",
                  "model": "gpt-4o-realtime-preview-2024-10-01",
                  "modalities": ["text"],
                  "instructions": "New instructions",
                  "voice": "alloy",
                  "input_audio_format": "pcm16",
                  "output_audio_format": "pcm16",
                  "input_audio_transcription": {
                      "enabled": true,
                      "model": "whisper-1"
                  },
                  "turn_detection": {
                      "type": "none"
                  },
                  "tools": [],
                  "tool_choice": "none",
                  "temperature": 0.7,
                  "max_output_tokens": 200
              }
          }
    ResponseFormatJsonObject:
      properties:
        type:
          description: "The type of response format being defined: `json_object`"
          enum:
          - json_object
          type: string
      required:
      - type
      type: object
    ResponseFormatJsonSchema:
      properties:
        type:
          description: "The type of response format being defined: `json_schema`"
          enum:
          - json_schema
          type: string
        json_schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchema_json_schema'
      required:
      - json_schema
      - type
      type: object
    ResponseFormatJsonSchemaSchema:
      additionalProperties: true
      description: "The schema for the response format, described as a JSON Schema\
        \ object."
      type: object
    ResponseFormatText:
      example:
        type: text
      properties:
        type:
          description: "The type of response format being defined: `text`"
          enum:
          - text
          type: string
      required:
      - type
      type: object
    RunCompletionUsage:
      description: "Usage statistics related to the run. This value will be `null`\
        \ if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)."
      example:
        completion_tokens: 7
        prompt_tokens: 9
        total_tokens: 3
      nullable: true
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    RunObject:
      description: "Represents an execution run on a [thread](/docs/api-reference/threads)."
      example:
        cancelled_at: 5
        instructions: instructions
        metadata: "{}"
        assistant_id: assistant_id
        required_action:
          submit_tool_outputs:
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
          type: submit_tool_outputs
        usage:
          completion_tokens: 7
          prompt_tokens: 9
          total_tokens: 3
        created_at: 0
        tools:
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        - type: code_interpreter
        top_p: 4.145608029883936
        max_completion_tokens: 256
        thread_id: thread_id
        expires_at: 6
        response_format: auto
        temperature: 2.027123023002322
        tool_choice: none
        model: model
        id: id
        last_error:
          code: server_error
          message: message
        incomplete_details:
          reason: max_completion_tokens
        truncation_strategy:
          last_messages: 1
          type: auto
        completed_at: 2
        parallel_tool_calls: true
        started_at: 1
        failed_at: 5
        max_prompt_tokens: 256
        object: thread.run
        status: queued
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run`."
          enum:
          - thread.run
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ executed on as a part of this run."
          type: string
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ used for execution of this run."
          type: string
        status:
          description: "The status of the run, which can be either `queued`, `in_progress`,\
            \ `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\
            \ `incomplete`, or `expired`."
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
          type: string
        required_action:
          $ref: '#/components/schemas/RunObject_required_action'
        last_error:
          $ref: '#/components/schemas/RunObject_last_error'
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          nullable: true
          type: integer
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          nullable: true
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          nullable: true
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          nullable: true
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          nullable: true
          type: integer
        incomplete_details:
          $ref: '#/components/schemas/RunObject_incomplete_details'
        model:
          description: "The model that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        instructions:
          description: "The instructions that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        tools:
          default: []
          description: "The list of tools that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          items:
            $ref: '#/components/schemas/AssistantObject_tools_inner'
          maxItems: 20
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
        temperature:
          description: "The sampling temperature used for this run. If not set, defaults\
            \ to 1."
          nullable: true
          type: number
        top_p:
          description: "The nucleus sampling value used for this run. If not set,\
            \ defaults to 1."
          nullable: true
          type: number
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        parallel_tool_calls:
          description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
            \ during tool use."
          nullable: true
          type: boolean
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
      required:
      - assistant_id
      - created_at
      - id
      - instructions
      - last_error
      - max_completion_tokens
      - max_prompt_tokens
      - metadata
      - model
      - object
      - parallel_tool_calls
      - required_action
      - response_format
      - status
      - thread_id
      - tool_choice
      - tools
      - truncation_strategy
      - usage
      title: A run on a thread
      type: object
      x-oaiMeta:
        name: The run object
        beta: true
        example: |
          {
            "id": "run_abc123",
            "object": "thread.run",
            "created_at": 1698107661,
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "status": "completed",
            "started_at": 1699073476,
            "expires_at": null,
            "cancelled_at": null,
            "failed_at": null,
            "completed_at": 1699073498,
            "last_error": null,
            "model": "gpt-4o",
            "instructions": null,
            "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
            "metadata": {},
            "incomplete_details": null,
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            },
            "temperature": 1.0,
            "top_p": 1.0,
            "max_prompt_tokens": 1000,
            "max_completion_tokens": 1000,
            "truncation_strategy": {
              "type": "auto",
              "last_messages": null
            },
            "response_format": "auto",
            "tool_choice": "auto",
            "parallel_tool_calls": true
          }
    RunStepCompletionUsage:
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`.
      example:
        completion_tokens: 2
        prompt_tokens: 7
        total_tokens: 9
      nullable: true
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run
            step.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run step.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    RunStepDeltaObject:
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming.
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step.delta`."
          enum:
          - thread.run.step.delta
          type: string
        delta:
          $ref: '#/components/schemas/RunStepDeltaObject_delta'
      required:
      - delta
      - id
      - object
      title: Run step delta object
      type: object
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: |
          {
            "id": "step_123",
            "object": "thread.run.step.delta",
            "delta": {
              "step_details": {
                "type": "tool_calls",
                "tool_calls": [
                  {
                    "index": 0,
                    "id": "call_123",
                    "type": "code_interpreter",
                    "code_interpreter": { "input": "", "outputs": [] }
                  }
                ]
              }
            }
          }
    RunStepDeltaStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
        message_creation:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject_message_creation'
      required:
      - type
      title: Message creation
      type: object
    RunStepDeltaStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
        code_interpreter:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter'
      required:
      - index
      - type
      title: Code interpreter tool call
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `image`.
          enum:
          - image
          type: string
        image:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image'
      required:
      - index
      - type
      title: Code interpreter image output
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - index
      - type
      title: Code interpreter log output
      type: object
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
        file_search:
          description: "For now, this is always going to be an empty object."
          type: object
          x-oaiTypeLabel: map
      required:
      - file_search
      - index
      - type
      title: File search tool call
      type: object
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject_function'
      required:
      - index
      - type
      title: Function tool call
      type: object
    RunStepDeltaStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner'
          type: array
      required:
      - type
      title: Tool calls
      type: object
    RunStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      example:
        message_creation:
          message_id: message_id
        type: message_creation
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
        message_creation:
          $ref: '#/components/schemas/RunStepDetailsMessageCreationObject_message_creation'
      required:
      - message_creation
      - type
      title: Message creation
      type: object
    RunStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
        code_interpreter:
          $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter'
      required:
      - code_interpreter
      - id
      - type
      title: Code Interpreter tool call
      type: object
    RunStepDetailsToolCallsCodeOutputImageObject:
      properties:
        type:
          description: Always `image`.
          enum:
          - image
          type: string
        image:
          $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject_image'
      required:
      - image
      - type
      title: Code Interpreter image output
      type: object
    RunStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - logs
      - type
      title: Code Interpreter log output
      type: object
    RunStepDetailsToolCallsFileSearchObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
        file_search:
          $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject_file_search'
      required:
      - file_search
      - id
      - type
      title: File search tool call
      type: object
    RunStepDetailsToolCallsFileSearchRankingOptionsObject:
      description: The ranking options for the file search.
      properties:
        ranker:
          description: The ranker used for the file search.
          enum:
          - default_2024_08_21
          type: string
        score_threshold:
          description: The score threshold for the file search. All values must be
            a floating point number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
      required:
      - ranker
      - score_threshold
      title: File search tool call ranking options
      type: object
    RunStepDetailsToolCallsFileSearchResultObject:
      description: A result instance of the file search.
      properties:
        file_id:
          description: The ID of the file that result was found in.
          type: string
        file_name:
          description: The name of the file that result was found in.
          type: string
        score:
          description: The score of the result. All values must be a floating point
            number between 0 and 1.
          maximum: 1
          minimum: 0
          type: number
        content:
          description: The content of the result that was found. The content is only
            included if requested via the include query parameter.
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject_content_inner'
          type: array
      required:
      - file_id
      - file_name
      - score
      title: File search tool call result
      type: object
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFunctionObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject_function'
      required:
      - function
      - id
      - type
      title: Function tool call
      type: object
    RunStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsObject_tool_calls_inner'
          type: array
      required:
      - tool_calls
      - type
      title: Tool calls
      type: object
    RunStepObject:
      description: |
        Represents a step in execution of a run.
      example:
        cancelled_at: 1
        metadata: "{}"
        assistant_id: assistant_id
        run_id: run_id
        usage:
          completion_tokens: 2
          prompt_tokens: 7
          total_tokens: 9
        created_at: 0
        expired_at: 6
        type: message_creation
        step_details:
          message_creation:
            message_id: message_id
          type: message_creation
        completed_at: 5
        thread_id: thread_id
        id: id
        last_error:
          code: server_error
          message: message
        failed_at: 5
        object: thread.run.step
        status: in_progress
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step`."
          enum:
          - thread.run.step
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ associated with the run step."
          type: string
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ run."
          type: string
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) that this run\
            \ step is a part of."
          type: string
        type:
          description: "The type of run step, which can be either `message_creation`\
            \ or `tool_calls`."
          enum:
          - message_creation
          - tool_calls
          type: string
        status:
          description: "The status of the run step, which can be either `in_progress`,\
            \ `cancelled`, `failed`, `completed`, or `expired`."
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
          type: string
        step_details:
          $ref: '#/components/schemas/RunStepObject_step_details'
        last_error:
          $ref: '#/components/schemas/RunStepObject_last_error'
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired.
          nullable: true
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          nullable: true
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          nullable: true
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          nullable: true
          type: integer
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
      required:
      - assistant_id
      - cancelled_at
      - created_at
      - expired_at
      - failed_at
      - id
      - last_error
      - metadata
      - object
      - run_id
      - status
      - step_details
      - thread_id
      - type
      - usage
      title: Run steps
      type: object
      x-oaiMeta:
        name: The run step object
        beta: true
        example: |
          {
            "id": "step_abc123",
            "object": "thread.run.step",
            "created_at": 1699063291,
            "run_id": "run_abc123",
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "type": "message_creation",
            "status": "completed",
            "cancelled_at": null,
            "completed_at": 1699063291,
            "expired_at": null,
            "failed_at": null,
            "last_error": null,
            "step_details": {
              "type": "message_creation",
              "message_creation": {
                "message_id": "msg_abc123"
              }
            },
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            }
          }
    RunStepStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_1'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_2'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_3'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_4'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_5'
      - $ref: '#/components/schemas/RunStepStreamEvent_oneOf_6'
    RunStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStreamEvent_oneOf'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_1'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_2'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_3'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_4'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_5'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_6'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_7'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_8'
      - $ref: '#/components/schemas/RunStreamEvent_oneOf_9'
    RunToolCallObject:
      description: Tool call objects
      example:
        function:
          name: name
          arguments: arguments
        id: id
        type: function
      properties:
        id:
          description: "The ID of the tool call. This ID must be referenced when you\
            \ submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)\
            \ endpoint."
          type: string
        type:
          description: "The type of tool call the output is required for. For now,\
            \ this is always `function`."
          enum:
          - function
          type: string
        function:
          $ref: '#/components/schemas/RunToolCallObject_function'
      required:
      - function
      - id
      - type
      type: object
    StaticChunkingStrategy:
      additionalProperties: false
      example:
        max_chunk_size_tokens: 685
        chunk_overlap_tokens: 5
      properties:
        max_chunk_size_tokens:
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`.
          maximum: 4096
          minimum: 100
          type: integer
        chunk_overlap_tokens:
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
          type: integer
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
      type: object
    StaticChunkingStrategyRequestParam:
      additionalProperties: false
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          type: string
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
      required:
      - static
      - type
      title: Static Chunking Strategy
      type: object
    StaticChunkingStrategyResponseParam:
      additionalProperties: false
      example:
        static:
          max_chunk_size_tokens: 685
          chunk_overlap_tokens: 5
        type: static
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          type: string
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
      required:
      - static
      - type
      title: Static Chunking Strategy
      type: object
    SubmitToolOutputsRunRequest:
      additionalProperties: false
      example:
        stream: true
        tool_outputs:
        - output: output
          tool_call_id: tool_call_id
        - output: output
          tool_call_id: tool_call_id
      properties:
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          items:
            $ref: '#/components/schemas/SubmitToolOutputsRunRequest_tool_outputs_inner'
          type: array
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
      required:
      - tool_outputs
      type: object
    ThreadObject:
      description: "Represents a thread that contains [messages](/docs/api-reference/messages)."
      example:
        tool_resources:
          code_interpreter:
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
          file_search:
            vector_store_ids:
            - vector_store_ids
        metadata: "{}"
        created_at: 0
        id: id
        object: thread
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread`."
          enum:
          - thread
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        tool_resources:
          $ref: '#/components/schemas/ModifyThreadRequest_tool_resources'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - created_at
      - id
      - metadata
      - object
      - tool_resources
      title: Thread
      type: object
      x-oaiMeta:
        name: The thread object
        beta: true
        example: |
          {
            "id": "thread_abc123",
            "object": "thread",
            "created_at": 1698107661,
            "metadata": {}
          }
    ThreadStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEvent_oneOf'
    TranscriptionSegment:
      properties:
        id:
          description: Unique identifier of the segment.
          type: integer
        seek:
          description: Seek offset of the segment.
          type: integer
        start:
          description: Start time of the segment in seconds.
          format: float
          type: number
        end:
          description: End time of the segment in seconds.
          format: float
          type: number
        text:
          description: Text content of the segment.
          type: string
        tokens:
          description: Array of token IDs for the text content.
          items:
            type: integer
          type: array
        temperature:
          description: Temperature parameter used for generating the segment.
          format: float
          type: number
        avg_logprob:
          description: "Average logprob of the segment. If the value is lower than\
            \ -1, consider the logprobs failed."
          format: float
          type: number
        compression_ratio:
          description: "Compression ratio of the segment. If the value is greater\
            \ than 2.4, consider the compression failed."
          format: float
          type: number
        no_speech_prob:
          description: "Probability of no speech in the segment. If the value is higher\
            \ than 1.0 and the `avg_logprob` is below -1, consider this segment silent."
          format: float
          type: number
      required:
      - avg_logprob
      - compression_ratio
      - end
      - id
      - no_speech_prob
      - seek
      - start
      - temperature
      - text
      - tokens
      type: object
    TranscriptionWord:
      properties:
        word:
          description: The text content of the word.
          type: string
        start:
          description: Start time of the word in seconds.
          format: float
          type: number
        end:
          description: End time of the word in seconds.
          format: float
          type: number
      required:
      - end
      - start
      - word
      type: object
    TruncationObject:
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run.
      example:
        last_messages: 1
        type: auto
      properties:
        type:
          description: "The truncation strategy to use for the thread. The default\
            \ is `auto`. If set to `last_messages`, the thread will be truncated to\
            \ the n most recent messages in the thread. When set to `auto`, messages\
            \ in the middle of the thread will be dropped to fit the context length\
            \ of the model, `max_prompt_tokens`."
          enum:
          - auto
          - last_messages
          type: string
        last_messages:
          description: The number of most recent messages from the thread when constructing
            the context for the run.
          minimum: 1
          nullable: true
          type: integer
      required:
      - type
      title: Thread Truncation Controls
      type: object
    UpdateVectorStoreRequest:
      additionalProperties: false
      example:
        metadata: "{}"
        expires_after:
          anchor: last_active_at
          days: 339
        name: name
      properties:
        name:
          description: The name of the vector store.
          nullable: true
          type: string
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    Upload:
      description: |
        The Upload object can accept byte chunks in the form of Parts.
      example:
        filename: filename
        expires_at: 1
        file:
          filename: filename
          purpose: assistants
          bytes: 0
          created_at: 6
          id: id
          status_details: status_details
          object: file
          status: uploaded
        purpose: purpose
        bytes: 6
        created_at: 0
        id: id
        status: pending
        object: upload
      properties:
        id:
          description: "The Upload unique identifier, which can be referenced in API\
            \ endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the Upload was created.
          type: integer
        filename:
          description: The name of the file to be uploaded.
          type: string
        bytes:
          description: The intended number of bytes to be uploaded.
          type: integer
        purpose:
          description: "The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose)\
            \ for acceptable values."
          type: string
        status:
          description: The status of the Upload.
          enum:
          - pending
          - completed
          - cancelled
          - expired
          type: string
        expires_at:
          description: The Unix timestamp (in seconds) for when the Upload was created.
          type: integer
        object:
          description: "The object type, which is always \"upload\"."
          enum:
          - upload
          type: string
        file:
          $ref: '#/components/schemas/OpenAIFile'
      required:
      - bytes
      - created_at
      - expires_at
      - filename
      - id
      - purpose
      - status
      title: Upload
      type: object
      x-oaiMeta:
        name: The upload object
        example: |
          {
            "id": "upload_abc123",
            "object": "upload",
            "bytes": 2147483648,
            "created_at": 1719184911,
            "filename": "training_examples.jsonl",
            "purpose": "fine-tune",
            "status": "completed",
            "expires_at": 1719127296,
            "file": {
              "id": "file-xyz321",
              "object": "file",
              "bytes": 2147483648,
              "created_at": 1719186911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
            }
          }
    UploadPart:
      description: |
        The upload Part represents a chunk of bytes we can add to an Upload object.
      example:
        upload_id: upload_id
        created_at: 0
        id: id
        object: upload.part
      properties:
        id:
          description: "The upload Part unique identifier, which can be referenced\
            \ in API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the Part was created.
          type: integer
        upload_id:
          description: The ID of the Upload object that this Part was added to.
          type: string
        object:
          description: "The object type, which is always `upload.part`."
          enum:
          - upload.part
          type: string
      required:
      - created_at
      - id
      - object
      - upload_id
      title: UploadPart
      type: object
      x-oaiMeta:
        name: The upload part object
        example: |
          {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719186911,
              "upload_id": "upload_abc123"
          }
    User:
      description: Represents an individual `user` within an organization.
      example:
        added_at: 0
        role: owner
        name: name
        id: id
        email: email
        object: organization.user
      properties:
        object:
          description: "The object type, which is always `organization.user`"
          enum:
          - organization.user
          type: string
        id:
          description: "The identifier, which can be referenced in API endpoints"
          type: string
        name:
          description: The name of the user
          type: string
        email:
          description: The email address of the user
          type: string
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
        added_at:
          description: The Unix timestamp (in seconds) of when the user was added.
          type: integer
      required:
      - added_at
      - email
      - id
      - name
      - object
      - role
      type: object
      x-oaiMeta:
        name: The user object
        example: |
          {
              "object": "organization.user",
              "id": "user_abc",
              "name": "First Last",
              "email": "user@example.com",
              "role": "owner",
              "added_at": 1711471533
          }
    UserDeleteResponse:
      example:
        deleted: true
        id: id
        object: organization.user.deleted
      properties:
        object:
          enum:
          - organization.user.deleted
          type: string
        id:
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    UserListResponse:
      example:
        first_id: first_id
        data:
        - added_at: 0
          role: owner
          name: name
          id: id
          email: email
          object: organization.user
        - added_at: 0
          role: owner
          name: name
          id: id
          email: email
          object: organization.user
        last_id: last_id
        has_more: true
        object: list
      properties:
        object:
          enum:
          - list
          type: string
        data:
          items:
            $ref: '#/components/schemas/User'
          type: array
        first_id:
          type: string
        last_id:
          type: string
        has_more:
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    UserRoleUpdateRequest:
      example:
        role: owner
      properties:
        role:
          description: '`owner` or `reader`'
          enum:
          - owner
          - reader
          type: string
      required:
      - role
      type: object
    VectorStoreExpirationAfter:
      description: The expiration policy for a vector store.
      example:
        anchor: last_active_at
        days: 339
      properties:
        anchor:
          description: "Anchor timestamp after which the expiration policy applies.\
            \ Supported anchors: `last_active_at`."
          enum:
          - last_active_at
          type: string
        days:
          description: The number of days after the anchor time that the vector store
            will expire.
          maximum: 365
          minimum: 1
          type: integer
      required:
      - anchor
      - days
      title: Vector store expiration policy
      type: object
    VectorStoreFileBatchObject:
      description: A batch of files attached to a vector store.
      example:
        file_counts:
          in_progress: 6
          total: 2
          cancelled: 5
          completed: 1
          failed: 5
        created_at: 0
        id: id
        object: vector_store.files_batch
        vector_store_id: vector_store_id
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file_batch`."
          enum:
          - vector_store.files_batch
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store files batch, which can be either\
            \ `in_progress`, `completed`, `cancelled` or `failed`."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        file_counts:
          $ref: '#/components/schemas/VectorStoreFileBatchObject_file_counts'
      required:
      - created_at
      - file_counts
      - id
      - object
      - status
      - vector_store_id
      title: Vector store file batch
      type: object
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: |
          {
            "id": "vsfb_123",
            "object": "vector_store.files_batch",
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "failed": 0,
              "cancelled": 0,
              "total": 100
            }
          }
    VectorStoreFileObject:
      description: A list of files attached to a vector store.
      example:
        chunking_strategy:
          static:
            max_chunk_size_tokens: 685
            chunk_overlap_tokens: 5
          type: static
        usage_bytes: 0
        created_at: 6
        id: id
        last_error:
          code: server_error
          message: message
        object: vector_store.file
        vector_store_id: vector_store_id
        status: in_progress
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file`."
          enum:
          - vector_store.file
          type: string
        usage_bytes:
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size.
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store file
            was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store file, which can be either `in_progress`,\
            \ `completed`, `cancelled`, or `failed`. The status `completed` indicates\
            \ that the vector store file is ready for use."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        last_error:
          $ref: '#/components/schemas/VectorStoreFileObject_last_error'
        chunking_strategy:
          $ref: '#/components/schemas/VectorStoreFileObject_chunking_strategy'
      required:
      - created_at
      - id
      - last_error
      - object
      - status
      - usage_bytes
      - vector_store_id
      title: Vector store files
      type: object
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: |
          {
            "id": "file-abc123",
            "object": "vector_store.file",
            "usage_bytes": 1234,
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "last_error": null,
            "chunking_strategy": {
              "type": "static",
              "static": {
                "max_chunk_size_tokens": 800,
                "chunk_overlap_tokens": 400
              }
            }
          }
    VectorStoreObject:
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool.
      example:
        file_counts:
          in_progress: 1
          total: 7
          cancelled: 2
          completed: 5
          failed: 5
        metadata: "{}"
        expires_at: 3
        expires_after:
          anchor: last_active_at
          days: 339
        last_active_at: 2
        usage_bytes: 6
        name: name
        created_at: 0
        id: id
        object: vector_store
        status: expired
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store`."
          enum:
          - vector_store
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            created.
          type: integer
        name:
          description: The name of the vector store.
          type: string
        usage_bytes:
          description: The total number of bytes used by the files in the vector store.
          type: integer
        file_counts:
          $ref: '#/components/schemas/VectorStoreObject_file_counts'
        status:
          description: "The status of the vector store, which can be either `expired`,\
            \ `in_progress`, or `completed`. A status of `completed` indicates that\
            \ the vector store is ready for use."
          enum:
          - expired
          - in_progress
          - completed
          type: string
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        expires_at:
          description: The Unix timestamp (in seconds) for when the vector store will
            expire.
          nullable: true
          type: integer
        last_active_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            last active.
          nullable: true
          type: integer
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - created_at
      - file_counts
      - id
      - last_active_at
      - metadata
      - name
      - object
      - status
      - usage_bytes
      title: Vector store
      type: object
      x-oaiMeta:
        name: The vector store object
        beta: true
        example: |
          {
            "id": "vs_123",
            "object": "vector_store",
            "created_at": 1698107661,
            "usage_bytes": 123456,
            "last_active_at": 1698107661,
            "name": "my_vector_store",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "cancelled": 0,
              "failed": 0,
              "total": 100
            },
            "metadata": {},
            "last_used_at": 1698107661
          }
    createTranscription_200_response:
      oneOf:
      - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
      - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
    createTranslation_200_response:
      oneOf:
      - $ref: '#/components/schemas/CreateTranslationResponseJson'
      - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
    createBatch_request:
      properties:
        input_file_id:
          description: |
            The ID of an uploaded file that contains requests for the new batch.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 100 MB in size.
          type: string
        endpoint:
          description: "The endpoint to be used for all requests in the batch. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported. Note that `/v1/embeddings` batches are also restricted to\
            \ a maximum of 50,000 embedding inputs across all requests in the batch."
          enum:
          - /v1/chat/completions
          - /v1/embeddings
          - /v1/completions
          type: string
        completion_window:
          description: The time frame within which the batch should be processed.
            Currently only `24h` is supported.
          enum:
          - 24h
          type: string
        metadata:
          additionalProperties:
            type: string
          description: Optional custom metadata for the batch.
          nullable: true
          type: object
      required:
      - completion_window
      - endpoint
      - input_file_id
      type: object
    list_audit_logs_effective_at_parameter:
      properties:
        gt:
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than this value.
          type: integer
        gte:
          description: Return only events whose `effective_at` (Unix seconds) is greater
            than or equal to this value.
          type: integer
        lt:
          description: Return only events whose `effective_at` (Unix seconds) is less
            than this value.
          type: integer
        lte:
          description: Return only events whose `effective_at` (Unix seconds) is less
            than or equal to this value.
          type: integer
      type: object
    AssistantObject_tools_inner:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    AssistantObject_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    AssistantObject_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    AssistantObject_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/AssistantObject_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/AssistantObject_tool_resources_file_search'
      type: object
    AssistantToolsFileSearch_file_search:
      description: Overrides for the file search tool.
      properties:
        max_num_results:
          description: |
            The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.

            Note that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search/customizing-file-search-settings) for more information.
          maximum: 50
          minimum: 1
          type: integer
        ranking_options:
          $ref: '#/components/schemas/FileSearchRankingOptions'
      type: object
    AssistantsNamedToolChoice_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      type: object
    AuditLog_project:
      description: The project that the action was scoped to. Absent for actions not
        scoped to projects.
      example:
        name: name
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        name:
          description: The project title.
          type: string
      type: object
    AuditLog_api_key_created_data:
      description: The payload used to create the API key.
      example:
        scopes:
        - scopes
        - scopes
      properties:
        scopes:
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
          type: array
      type: object
    AuditLog_api_key_created:
      description: The details for events with this `type`.
      example:
        data:
          scopes:
          - scopes
          - scopes
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
        data:
          $ref: '#/components/schemas/AuditLog_api_key_created_data'
      type: object
    AuditLog_api_key_updated_changes_requested:
      description: The payload used to update the API key.
      example:
        scopes:
        - scopes
        - scopes
      properties:
        scopes:
          description: "A list of scopes allowed for the API key, e.g. `[\"api.model.request\"\
            ]`"
          items:
            type: string
          type: array
      type: object
    AuditLog_api_key_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          scopes:
          - scopes
          - scopes
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
        changes_requested:
          $ref: '#/components/schemas/AuditLog_api_key_updated_changes_requested'
      type: object
    AuditLog_api_key_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The tracking ID of the API key.
          type: string
      type: object
    AuditLog_invite_sent_data:
      description: The payload used to create the invite.
      example:
        role: role
        email: email
      properties:
        email:
          description: The email invited to the organization.
          type: string
        role:
          description: The role the email was invited to be. Is either `owner` or
            `member`.
          type: string
      type: object
    AuditLog_invite_sent:
      description: The details for events with this `type`.
      example:
        data:
          role: role
          email: email
        id: id
      properties:
        id:
          description: The ID of the invite.
          type: string
        data:
          $ref: '#/components/schemas/AuditLog_invite_sent_data'
      type: object
    AuditLog_invite_accepted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The ID of the invite.
          type: string
      type: object
    AuditLog_login_failed:
      description: The details for events with this `type`.
      example:
        error_message: error_message
        error_code: error_code
      properties:
        error_code:
          description: The error code of the failure.
          type: string
        error_message:
          description: The error message of the failure.
          type: string
      type: object
    AuditLog_organization_updated_changes_requested_settings:
      example:
        threads_ui_visibility: threads_ui_visibility
        usage_dashboard_visibility: usage_dashboard_visibility
      properties:
        threads_ui_visibility:
          description: "Visibility of the threads page which shows messages created\
            \ with the Assistants API and Playground. One of `ANY_ROLE`, `OWNERS`,\
            \ or `NONE`."
          type: string
        usage_dashboard_visibility:
          description: Visibility of the usage dashboard which shows activity and
            costs for your organization. One of `ANY_ROLE` or `OWNERS`.
          type: string
      type: object
    AuditLog_organization_updated_changes_requested:
      description: The payload used to update the organization settings.
      example:
        settings:
          threads_ui_visibility: threads_ui_visibility
          usage_dashboard_visibility: usage_dashboard_visibility
        name: name
        description: description
        title: title
      properties:
        title:
          description: The organization title.
          type: string
        description:
          description: The organization description.
          type: string
        name:
          description: The organization name.
          type: string
        settings:
          $ref: '#/components/schemas/AuditLog_organization_updated_changes_requested_settings'
      type: object
    AuditLog_organization_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          settings:
            threads_ui_visibility: threads_ui_visibility
            usage_dashboard_visibility: usage_dashboard_visibility
          name: name
          description: description
          title: title
        id: id
      properties:
        id:
          description: The organization ID.
          type: string
        changes_requested:
          $ref: '#/components/schemas/AuditLog_organization_updated_changes_requested'
      type: object
    AuditLog_project_created_data:
      description: The payload used to create the project.
      example:
        name: name
        title: title
      properties:
        name:
          description: The project name.
          type: string
        title:
          description: The title of the project as seen on the dashboard.
          type: string
      type: object
    AuditLog_project_created:
      description: The details for events with this `type`.
      example:
        data:
          name: name
          title: title
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        data:
          $ref: '#/components/schemas/AuditLog_project_created_data'
      type: object
    AuditLog_project_updated_changes_requested:
      description: The payload used to update the project.
      example:
        title: title
      properties:
        title:
          description: The title of the project as seen on the dashboard.
          type: string
      type: object
    AuditLog_project_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          title: title
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        changes_requested:
          $ref: '#/components/schemas/AuditLog_project_updated_changes_requested'
      type: object
    AuditLog_project_archived:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The project ID.
          type: string
      type: object
    AuditLog_service_account_created_data:
      description: The payload used to create the service account.
      example:
        role: role
      properties:
        role:
          description: The role of the service account. Is either `owner` or `member`.
          type: string
      type: object
    AuditLog_service_account_created:
      description: The details for events with this `type`.
      example:
        data:
          role: role
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
        data:
          $ref: '#/components/schemas/AuditLog_service_account_created_data'
      type: object
    AuditLog_service_account_updated_changes_requested:
      description: The payload used to updated the service account.
      example:
        role: role
      properties:
        role:
          description: The role of the service account. Is either `owner` or `member`.
          type: string
      type: object
    AuditLog_service_account_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          role: role
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
        changes_requested:
          $ref: '#/components/schemas/AuditLog_service_account_updated_changes_requested'
      type: object
    AuditLog_service_account_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The service account ID.
          type: string
      type: object
    AuditLog_user_added_data:
      description: The payload used to add the user to the project.
      example:
        role: role
      properties:
        role:
          description: The role of the user. Is either `owner` or `member`.
          type: string
      type: object
    AuditLog_user_added:
      description: The details for events with this `type`.
      example:
        data:
          role: role
        id: id
      properties:
        id:
          description: The user ID.
          type: string
        data:
          $ref: '#/components/schemas/AuditLog_user_added_data'
      type: object
    AuditLog_user_updated_changes_requested:
      description: The payload used to update the user.
      example:
        role: role
      properties:
        role:
          description: The role of the user. Is either `owner` or `member`.
          type: string
      type: object
    AuditLog_user_updated:
      description: The details for events with this `type`.
      example:
        changes_requested:
          role: role
        id: id
      properties:
        id:
          description: The project ID.
          type: string
        changes_requested:
          $ref: '#/components/schemas/AuditLog_user_updated_changes_requested'
      type: object
    AuditLog_user_deleted:
      description: The details for events with this `type`.
      example:
        id: id
      properties:
        id:
          description: The user ID.
          type: string
      type: object
    Batch_errors_data_inner:
      example:
        code: code
        param: param
        line: 0
        message: message
      properties:
        code:
          description: An error code identifying the error type.
          type: string
        message:
          description: A human-readable message providing more details about the error.
          type: string
        param:
          description: "The name of the parameter that caused the error, if applicable."
          nullable: true
          type: string
        line:
          description: "The line number of the input file where the error occurred,\
            \ if applicable."
          nullable: true
          type: integer
      type: object
    Batch_errors:
      example:
        data:
        - code: code
          param: param
          line: 0
          message: message
        - code: code
          param: param
          line: 0
          message: message
        object: object
      properties:
        object:
          description: "The object type, which is always `list`."
          type: string
        data:
          items:
            $ref: '#/components/schemas/Batch_errors_data_inner'
          type: array
      type: object
    Batch_request_counts:
      description: The request counts for different statuses within the batch.
      example:
        total: 4
        completed: 7
        failed: 1
      properties:
        total:
          description: Total number of requests in the batch.
          type: integer
        completed:
          description: Number of requests that have been completed successfully.
          type: integer
        failed:
          description: Number of requests that have failed.
          type: integer
      required:
      - completed
      - failed
      - total
      type: object
    BatchRequestOutput_response:
      nullable: true
      properties:
        status_code:
          description: The HTTP status code of the response
          type: integer
        request_id:
          description: An unique identifier for the OpenAI API request. Please include
            this request ID when contacting support.
          type: string
        body:
          description: The JSON body of the response
          type: object
          x-oaiTypeLabel: map
      type: object
    BatchRequestOutput_error:
      description: "For requests that failed with a non-HTTP error, this will contain\
        \ more information on the cause of the failure."
      nullable: true
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
      type: object
    ChatCompletionMessageToolCall_function:
      description: The function that the model called.
      example:
        name: name
        arguments: arguments
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionMessageToolCallChunk_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
      type: object
    ChatCompletionRequestAssistantMessage_content:
      description: |
        The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
      nullable: true
      oneOf:
      - description: The contents of the assistant message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. Can be one or\
          \ more of type `text`, or exactly one of type `refusal`."
        items:
          $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
        minItems: 1
        title: Array of content parts
        type: array
      x-oaiExpandable: true
    ChatCompletionRequestAssistantMessage_audio:
      description: "Data about a previous audio response from the model. \n[Learn\
        \ more](/docs/guides/audio).\n"
      nullable: true
      properties:
        id:
          description: |
            Unique identifier for a previous audio response from the model.
          type: string
      required:
      - id
      type: object
      x-oaiExpandable: true
    ChatCompletionRequestAssistantMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      nullable: true
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionRequestMessageContentPartAudio_input_audio:
      properties:
        data:
          description: Base64 encoded audio data.
          type: string
        format:
          description: |
            The format of the encoded audio data. Currently supports "wav" and "mp3".
          enum:
          - wav
          - mp3
          type: string
      required:
      - data
      - format
      type: object
    ChatCompletionRequestMessageContentPartImage_image_url:
      properties:
        url:
          description: Either a URL of the image or the base64 encoded image data.
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. Learn more in the\
            \ [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding)."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
      type: object
    ChatCompletionRequestSystemMessage_content:
      description: The contents of the system message.
      oneOf:
      - description: The contents of the system message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. For system messages,\
          \ only type `text` is supported."
        items:
          $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
        minItems: 1
        title: Array of content parts
        type: array
    ChatCompletionRequestToolMessage_content:
      description: The contents of the tool message.
      oneOf:
      - description: The contents of the tool message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. For tool messages,\
          \ only type `text` is supported."
        items:
          $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
        minItems: 1
        title: Array of content parts
        type: array
    ChatCompletionRequestUserMessage_content:
      description: |
        The contents of the user message.
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type. Supported options\
          \ differ based on the [model](/docs/models) being used to generate the response.\
          \ Can contain text, image, or audio inputs."
        items:
          $ref: '#/components/schemas/ChatCompletionRequestUserMessageContentPart'
        minItems: 1
        title: Array of content parts
        type: array
      x-oaiExpandable: true
    ChatCompletionResponseMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      example:
        name: name
        arguments: arguments
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionResponseMessage_audio:
      description: |
        If the audio output modality is requested, this object contains data
        about the audio response from the model. [Learn more](/docs/guides/audio).
      example:
        expires_at: 6
        transcript: transcript
        data: data
        id: id
      nullable: true
      properties:
        id:
          description: Unique identifier for this audio response.
          type: string
        expires_at:
          description: |
            The Unix timestamp (in seconds) for when this audio response will
            no longer be accessible on the server for use in multi-turn
            conversations.
          type: integer
        data:
          description: |
            Base64 encoded audio bytes generated by the model, in the format
            specified in the request.
          type: string
        transcript:
          description: Transcript of the audio generated by the model.
          type: string
      required:
      - data
      - expires_at
      - id
      - transcript
      type: object
      x-oaiExpandable: true
    ChatCompletionStreamResponseDelta_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      type: object
    ChatCompletionTokenLogprob_top_logprobs_inner:
      example:
        logprob: 5.637376656633329
        bytes:
        - 2
        - 2
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          nullable: true
          type: array
      required:
      - bytes
      - logprob
      - token
      type: object
    CompletionUsage_completion_tokens_details:
      description: Breakdown of tokens used in a completion.
      example:
        audio_tokens: 4
        reasoning_tokens: 7
      properties:
        audio_tokens:
          description: Audio input tokens generated by the model.
          type: integer
        reasoning_tokens:
          description: Tokens generated by the model for reasoning.
          type: integer
      type: object
    CompletionUsage_prompt_tokens_details:
      description: Breakdown of tokens used in the prompt.
      example:
        audio_tokens: 1
        cached_tokens: 1
      properties:
        audio_tokens:
          description: Audio input tokens present in the prompt.
          type: integer
        cached_tokens:
          description: Cached tokens present in the prompt.
          type: integer
      type: object
    CreateAssistantRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-4o
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-2024-08-06
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      example: gpt-4o
      x-oaiTypeLabel: string
    CreateAssistantRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    Auto_Chunking_Strategy:
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`.
      example:
        type: auto
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          type: string
      required:
      - type
      title: Auto Chunking Strategy
      type: object
    Static_Chunking_Strategy_static:
      additionalProperties: false
      properties:
        max_chunk_size_tokens:
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`.
          maximum: 4096
          minimum: 100
          type: integer
        chunk_overlap_tokens:
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`.
          type: integer
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
      type: object
    Static_Chunking_Strategy:
      additionalProperties: false
      properties:
        type:
          description: Always `static`.
          enum:
          - static
          type: string
        static:
          $ref: '#/components/schemas/Static_Chunking_Strategy_static'
      required:
      - static
      - type
      title: Static Chunking Strategy
      type: object
    CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy."
      oneOf:
      - $ref: '#/components/schemas/Auto_Chunking_Strategy'
      - $ref: '#/components/schemas/Static_Chunking_Strategy'
      type: object
      x-oaiExpandable: true
    CreateAssistantRequest_tool_resources_file_search_vector_stores_inner:
      example:
        chunking_strategy:
          type: auto
        metadata: "{}"
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
          items:
            type: string
          maxItems: 10000
          type: array
        chunking_strategy:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          type: object
          x-oaiTypeLabel: map
      type: object
    CreateAssistantRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
        vector_stores:
        - chunking_strategy:
            type: auto
          metadata: "{}"
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
      nullable: true
      oneOf: []
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner'
          maxItems: 1
          type: array
      type: object
    CreateAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
          vector_stores:
          - chunking_strategy:
              type: auto
            metadata: "{}"
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_file_search'
      type: object
    CreateChatCompletionFunctionResponse_choices_inner:
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function.
          enum:
          - stop
          - length
          - function_call
          - content_filter
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
        message:
          $ref: '#/components/schemas/ChatCompletionResponseMessage'
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
    CreateChatCompletionRequest_audio:
      description: |
        Parameters for audio output. Required when audio output is requested with
        `modalities: ["audio"]`. [Learn more](/docs/guides/audio).
      example:
        voice: alloy
        format: wav
      nullable: true
      properties:
        voice:
          description: "Specifies the voice type. Supported voices are `alloy`, `echo`,\
            \ \n`fable`, `onyx`, `nova`, and `shimmer`.\n"
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          type: string
        format:
          description: "Specifies the output audio format. Must be one of `wav`, `mp3`,\
            \ `flac`,\n`opus`, or `pcm16`. \n"
          enum:
          - wav
          - mp3
          - flac
          - opus
          - pcm16
          type: string
      required:
      - format
      - voice
      type: object
      x-oaiExpandable: true
    CreateChatCompletionRequest_response_format:
      description: |
        An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models/gpt-4o), [GPT-4o mini](/docs/models/gpt-4o-mini), [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

        Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
      oneOf:
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
      - $ref: '#/components/schemas/ResponseFormatJsonSchema'
      x-oaiExpandable: true
    CreateChatCompletionRequest_stop:
      default: null
      description: |
        Up to 4 sequences where the API will stop generating further tokens.
      oneOf:
      - nullable: true
        type: string
      - items:
          type: string
        maxItems: 4
        minItems: 1
        type: array
    CreateChatCompletionResponse_choices_inner_logprobs:
      description: Log probability information for the choice.
      example:
        refusal:
        - top_logprobs:
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          logprob: 1.4658129805029452
          bytes:
          - 5
          - 5
          token: token
        - top_logprobs:
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          logprob: 1.4658129805029452
          bytes:
          - 5
          - 5
          token: token
        content:
        - top_logprobs:
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          logprob: 1.4658129805029452
          bytes:
          - 5
          - 5
          token: token
        - top_logprobs:
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          - logprob: 5.637376656633329
            bytes:
            - 2
            - 2
            token: token
          logprob: 1.4658129805029452
          bytes:
          - 5
          - 5
          token: token
      nullable: true
      properties:
        content:
          description: A list of message content tokens with log probability information.
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
          nullable: true
          type: array
        refusal:
          description: A list of message refusal tokens with log probability information.
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
          nullable: true
          type: array
      required:
      - content
      - refusal
      type: object
    CreateChatCompletionResponse_choices_inner:
      example:
        finish_reason: stop
        index: 0
        message:
          role: assistant
          function_call:
            name: name
            arguments: arguments
          refusal: refusal
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          audio:
            expires_at: 6
            transcript: transcript
            data: data
            id: id
          content: content
        logprobs:
          refusal:
          - top_logprobs:
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            logprob: 1.4658129805029452
            bytes:
            - 5
            - 5
            token: token
          - top_logprobs:
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            logprob: 1.4658129805029452
            bytes:
            - 5
            - 5
            token: token
          content:
          - top_logprobs:
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            logprob: 1.4658129805029452
            bytes:
            - 5
            - 5
            token: token
          - top_logprobs:
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            - logprob: 5.637376656633329
              bytes:
              - 2
              - 2
              token: token
            logprob: 1.4658129805029452
            bytes:
            - 5
            - 5
            token: token
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
        message:
          $ref: '#/components/schemas/ChatCompletionResponseMessage'
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs'
      required:
      - finish_reason
      - index
      - message
      type: object
    CreateChatCompletionStreamResponse_choices_inner:
      properties:
        delta:
          $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs'
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          nullable: true
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
      required:
      - delta
      - finish_reason
      - index
      type: object
    CreateChatCompletionStreamResponse_usage:
      description: |
        An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
        When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    CreateCompletionRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-3.5-turbo-instruct
        - davinci-002
        - babbage-002
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      x-oaiTypeLabel: string
    CreateCompletionRequest_prompt:
      description: |
        The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

        Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
      nullable: true
      oneOf:
      - default: ""
        example: This is a test.
        type: string
      - items:
          default: ""
          example: This is a test.
          type: string
        type: array
      - example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        minItems: 1
        type: array
      - example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        minItems: 1
        type: array
    CreateCompletionRequest_stop:
      description: |
        Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
      nullable: true
      oneOf:
      - default: <|endoftext|>
        example: |2+

        nullable: true
        type: string
      - items:
          example: "[\"\\n\"]"
          type: string
        maxItems: 4
        minItems: 1
        type: array
    CreateCompletionResponse_choices_inner_logprobs:
      example:
        top_logprobs:
        - key: 5.962133916683182
        - key: 5.962133916683182
        token_logprobs:
        - 1.4658129805029452
        - 1.4658129805029452
        tokens:
        - tokens
        - tokens
        text_offset:
        - 6
        - 6
      nullable: true
      properties:
        text_offset:
          items:
            type: integer
          type: array
        token_logprobs:
          items:
            type: number
          type: array
        tokens:
          items:
            type: string
          type: array
        top_logprobs:
          items:
            additionalProperties:
              type: number
            type: object
          type: array
      type: object
    CreateCompletionResponse_choices_inner:
      example:
        finish_reason: stop
        index: 0
        text: text
        logprobs:
          top_logprobs:
          - key: 5.962133916683182
          - key: 5.962133916683182
          token_logprobs:
          - 1.4658129805029452
          - 1.4658129805029452
          tokens:
          - tokens
          - tokens
          text_offset:
          - 6
          - 6
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            or `content_filter` if content was omitted due to a flag from our content filters.
          enum:
          - stop
          - length
          - content_filter
          type: string
        index:
          type: integer
        logprobs:
          $ref: '#/components/schemas/CreateCompletionResponse_choices_inner_logprobs'
        text:
          type: string
      required:
      - finish_reason
      - index
      - logprobs
      - text
      type: object
    CreateEmbeddingRequest_input:
      description: |
        Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
      example: The quick brown fox jumped over the lazy dog
      oneOf:
      - default: ""
        description: The string that will be turned into an embedding.
        example: This is a test.
        title: string
        type: string
      - description: The array of strings that will be turned into an embedding.
        items:
          default: ""
          example: "['This is a test.']"
          type: string
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      - description: The array of integers that will be turned into an embedding.
        example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      - description: The array of arrays containing integers that will be turned into
          an embedding.
        example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      x-oaiExpandable: true
    CreateEmbeddingRequest_model:
      anyOf:
      - type: string
      - enum:
        - text-embedding-ada-002
        - text-embedding-3-small
        - text-embedding-3-large
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      example: text-embedding-3-small
      x-oaiTypeLabel: string
    CreateEmbeddingResponse_usage:
      description: The usage information for the request.
      example:
        prompt_tokens: 1
        total_tokens: 5
      properties:
        prompt_tokens:
          description: The number of tokens used by the prompt.
          type: integer
        total_tokens:
          description: The total number of tokens used by the request.
          type: integer
      required:
      - prompt_tokens
      - total_tokens
      type: object
    CreateFineTuningJobRequest_model:
      anyOf:
      - type: string
      - enum:
        - babbage-002
        - davinci-002
        - gpt-3.5-turbo
        - gpt-4o-mini
        type: string
      description: |
        The name of the model to fine-tune. You can select one of the
        [supported models](/docs/guides/fine-tuning/which-models-can-be-fine-tuned).
      example: gpt-4o-mini
      x-oaiTypeLabel: string
    CreateFineTuningJobRequest_hyperparameters_batch_size:
      description: |
        Number of examples in each batch. A larger batch size means that model parameters
        are updated less frequently, but with lower variance.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 256
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier:
      description: |
        Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
        overfitting.
      oneOf:
      - enum:
        - auto
        type: string
      - exclusiveMinimum: true
        minimum: 0
        type: number
    CreateFineTuningJobRequest_hyperparameters_n_epochs:
      description: |
        The number of epochs to train the model for. An epoch refers to one full cycle
        through the training dataset.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 50
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters:
      description: The hyperparameters used for the fine-tuning job.
      example:
        batch_size: auto
        n_epochs: auto
        learning_rate_multiplier: auto
      properties:
        batch_size:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_hyperparameters_batch_size'
        learning_rate_multiplier:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier'
        n_epochs:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_hyperparameters_n_epochs'
      type: object
    CreateFineTuningJobRequest_integrations_inner_type:
      description: |
        The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported.
      oneOf:
      - enum:
        - wandb
        type: string
    CreateFineTuningJobRequest_integrations_inner_wandb:
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run.
      example:
        name: name
        project: my-wandb-project
        entity: entity
        tags:
        - custom-tag
        - custom-tag
      properties:
        project:
          description: |
            The name of the project that the new run will be created under.
          example: my-wandb-project
          type: string
        name:
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name.
          nullable: true
          type: string
        entity:
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used.
          nullable: true
          type: string
        tags:
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
          items:
            example: custom-tag
            type: string
          type: array
      required:
      - project
      type: object
    CreateFineTuningJobRequest_integrations_inner:
      example:
        wandb:
          name: name
          project: my-wandb-project
          entity: entity
          tags:
          - custom-tag
          - custom-tag
        type: wandb
      properties:
        type:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_integrations_inner_type'
        wandb:
          $ref: '#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb'
      required:
      - type
      - wandb
      type: object
    CreateImageEditRequest_model:
      anyOf:
      - type: string
      - enum:
        - dall-e-2
        type: string
      default: dall-e-2
      description: The model to use for image generation. Only `dall-e-2` is supported
        at this time.
      example: dall-e-2
      nullable: true
      x-oaiTypeLabel: string
    Array_of_content_parts_inner:
      oneOf:
      - $ref: '#/components/schemas/MessageContentImageFileObject'
      - $ref: '#/components/schemas/MessageContentImageUrlObject'
      - $ref: '#/components/schemas/MessageRequestContentTextObject'
      x-oaiExpandable: true
    CreateMessageRequest_content:
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type, each can be of\
          \ type `text` or images can be passed with `image_url` or `image_file`.\
          \ Image types are only supported on [Vision-compatible models](/docs/models/overview)."
        items:
          $ref: '#/components/schemas/Array_of_content_parts_inner'
        minItems: 1
        title: Array of content parts
        type: array
      x-oaiExpandable: true
    CreateMessageRequest_attachments_inner_tools_inner:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
      x-oaiExpandable: true
    CreateMessageRequest_attachments_inner:
      example:
        file_id: file_id
        tools:
        - type: code_interpreter
        - type: code_interpreter
      properties:
        file_id:
          description: The ID of the file to attach to the message.
          type: string
        tools:
          description: The tools to add this file to.
          items:
            $ref: '#/components/schemas/CreateMessageRequest_attachments_inner_tools_inner'
          type: array
      type: object
    CreateModerationRequest_input_oneOf_inner_oneOf_image_url:
      description: Contains either an image URL or a data URL for a base64 encoded
        image.
      properties:
        url:
          description: Either a URL of the image or the base64 encoded image data.
          example: https://example.com/image.jpg
          format: uri
          type: string
      required:
      - url
      type: object
    CreateModerationRequest_input_oneOf_inner_oneOf:
      description: An object describing an image to classify.
      properties:
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
        image_url:
          $ref: '#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf_image_url'
      required:
      - image_url
      - type
      type: object
    CreateModerationRequest_input_oneOf_inner_oneOf_1:
      description: An object describing text to classify.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          description: A string of text to classify.
          example: I want to kill them
          type: string
      required:
      - text
      - type
      type: object
    CreateModerationRequest_input_oneOf_inner:
      oneOf:
      - $ref: '#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf'
      - $ref: '#/components/schemas/CreateModerationRequest_input_oneOf_inner_oneOf_1'
      x-oaiExpandable: true
    CreateModerationRequest_input:
      description: |
        Input (or inputs) to classify. Can be a single string, an array of strings, or
        an array of multi-modal input objects similar to other models.
      oneOf:
      - default: ""
        description: A string of text to classify for moderation.
        example: I want to kill them.
        type: string
      - description: An array of strings to classify for moderation.
        items:
          default: ""
          example: I want to kill them.
          type: string
        type: array
      - description: An array of multi-modal inputs to the moderation model.
        items:
          $ref: '#/components/schemas/CreateModerationRequest_input_oneOf_inner'
        type: array
      x-oaiExpandable: true
    CreateModerationResponse_results_inner_categories:
      description: "A list of the categories, and whether they are flagged or not."
      example:
        illicit/violent: true
        self-harm/instructions: true
        harassment: true
        violence/graphic: true
        illicit: true
        self-harm/intent: true
        hate/threatening: true
        sexual/minors: true
        harassment/threatening: true
        hate: true
        self-harm: true
        sexual: true
        violence: true
      properties:
        hate:
          description: "Content that expresses, incites, or promotes hate based on\
            \ race, gender, ethnicity, religion, nationality, sexual orientation,\
            \ disability status, or caste. Hateful content aimed at non-protected\
            \ groups (e.g., chess players) is harassment."
          type: boolean
        hate/threatening:
          description: "Hateful content that also includes violence or serious harm\
            \ towards the targeted group based on race, gender, ethnicity, religion,\
            \ nationality, sexual orientation, disability status, or caste."
          type: boolean
        harassment:
          description: "Content that expresses, incites, or promotes harassing language\
            \ towards any target."
          type: boolean
        harassment/threatening:
          description: Harassment content that also includes violence or serious harm
            towards any target.
          type: boolean
        illicit:
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing, or that gives advice or instruction\
            \ on how to commit illicit acts. For example, \"how to shoplift\" would\
            \ fit this category."
          type: boolean
        illicit/violent:
          description: "Content that includes instructions or advice that facilitate\
            \ the planning or execution of wrongdoing that also includes violence,\
            \ or that gives advice or instruction on the procurement of any weapon."
          type: boolean
        self-harm:
          description: "Content that promotes, encourages, or depicts acts of self-harm,\
            \ such as suicide, cutting, and eating disorders."
          type: boolean
        self-harm/intent:
          description: "Content where the speaker expresses that they are engaging\
            \ or intend to engage in acts of self-harm, such as suicide, cutting,\
            \ and eating disorders."
          type: boolean
        self-harm/instructions:
          description: "Content that encourages performing acts of self-harm, such\
            \ as suicide, cutting, and eating disorders, or that gives instructions\
            \ or advice on how to commit such acts."
          type: boolean
        sexual:
          description: "Content meant to arouse sexual excitement, such as the description\
            \ of sexual activity, or that promotes sexual services (excluding sex\
            \ education and wellness)."
          type: boolean
        sexual/minors:
          description: Sexual content that includes an individual who is under 18
            years old.
          type: boolean
        violence:
          description: "Content that depicts death, violence, or physical injury."
          type: boolean
        violence/graphic:
          description: "Content that depicts death, violence, or physical injury in\
            \ graphic detail."
          type: boolean
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
    CreateModerationResponse_results_inner_category_scores:
      description: A list of the categories along with their scores as predicted by
        model.
      example:
        illicit/violent: 2.3021358869347655
        self-harm/instructions: 3.616076749251911
        harassment: 1.4658129805029452
        violence/graphic: 1.2315135367772556
        illicit: 5.637376656633329
        self-harm/intent: 9.301444243932576
        hate/threatening: 6.027456183070403
        sexual/minors: 4.145608029883936
        harassment/threatening: 5.962133916683182
        hate: 0.8008281904610115
        self-harm: 7.061401241503109
        sexual: 2.027123023002322
        violence: 7.386281948385884
      properties:
        hate:
          description: The score for the category 'hate'.
          type: number
        hate/threatening:
          description: The score for the category 'hate/threatening'.
          type: number
        harassment:
          description: The score for the category 'harassment'.
          type: number
        harassment/threatening:
          description: The score for the category 'harassment/threatening'.
          type: number
        illicit:
          description: The score for the category 'illicit'.
          type: number
        illicit/violent:
          description: The score for the category 'illicit/violent'.
          type: number
        self-harm:
          description: The score for the category 'self-harm'.
          type: number
        self-harm/intent:
          description: The score for the category 'self-harm/intent'.
          type: number
        self-harm/instructions:
          description: The score for the category 'self-harm/instructions'.
          type: number
        sexual:
          description: The score for the category 'sexual'.
          type: number
        sexual/minors:
          description: The score for the category 'sexual/minors'.
          type: number
        violence:
          description: The score for the category 'violence'.
          type: number
        violence/graphic:
          description: The score for the category 'violence/graphic'.
          type: number
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
    CreateModerationResponse_results_inner_category_applied_input_types:
      description: A list of the categories along with the input type(s) that the
        score applies to.
      example:
        illicit/violent:
        - text
        - text
        self-harm/instructions:
        - text
        - text
        harassment:
        - text
        - text
        violence/graphic:
        - text
        - text
        illicit:
        - text
        - text
        self-harm/intent:
        - text
        - text
        hate/threatening:
        - text
        - text
        sexual/minors:
        - text
        - text
        harassment/threatening:
        - text
        - text
        hate:
        - text
        - text
        self-harm:
        - text
        - text
        sexual:
        - text
        - text
        violence:
        - text
        - text
      properties:
        hate:
          description: The applied input type(s) for the category 'hate'.
          items:
            enum:
            - text
            type: string
          type: array
        hate/threatening:
          description: The applied input type(s) for the category 'hate/threatening'.
          items:
            enum:
            - text
            type: string
          type: array
        harassment:
          description: The applied input type(s) for the category 'harassment'.
          items:
            enum:
            - text
            type: string
          type: array
        harassment/threatening:
          description: The applied input type(s) for the category 'harassment/threatening'.
          items:
            enum:
            - text
            type: string
          type: array
        illicit:
          description: The applied input type(s) for the category 'illicit'.
          items:
            enum:
            - text
            type: string
          type: array
        illicit/violent:
          description: The applied input type(s) for the category 'illicit/violent'.
          items:
            enum:
            - text
            type: string
          type: array
        self-harm:
          description: The applied input type(s) for the category 'self-harm'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        self-harm/intent:
          description: The applied input type(s) for the category 'self-harm/intent'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        self-harm/instructions:
          description: The applied input type(s) for the category 'self-harm/instructions'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        sexual:
          description: The applied input type(s) for the category 'sexual'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        sexual/minors:
          description: The applied input type(s) for the category 'sexual/minors'.
          items:
            enum:
            - text
            type: string
          type: array
        violence:
          description: The applied input type(s) for the category 'violence'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
        violence/graphic:
          description: The applied input type(s) for the category 'violence/graphic'.
          items:
            enum:
            - text
            - image
            type: string
          type: array
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - illicit
      - illicit/violent
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
    CreateModerationResponse_results_inner:
      example:
        category_scores:
          illicit/violent: 2.3021358869347655
          self-harm/instructions: 3.616076749251911
          harassment: 1.4658129805029452
          violence/graphic: 1.2315135367772556
          illicit: 5.637376656633329
          self-harm/intent: 9.301444243932576
          hate/threatening: 6.027456183070403
          sexual/minors: 4.145608029883936
          harassment/threatening: 5.962133916683182
          hate: 0.8008281904610115
          self-harm: 7.061401241503109
          sexual: 2.027123023002322
          violence: 7.386281948385884
        flagged: true
        category_applied_input_types:
          illicit/violent:
          - text
          - text
          self-harm/instructions:
          - text
          - text
          harassment:
          - text
          - text
          violence/graphic:
          - text
          - text
          illicit:
          - text
          - text
          self-harm/intent:
          - text
          - text
          hate/threatening:
          - text
          - text
          sexual/minors:
          - text
          - text
          harassment/threatening:
          - text
          - text
          hate:
          - text
          - text
          self-harm:
          - text
          - text
          sexual:
          - text
          - text
          violence:
          - text
          - text
        categories:
          illicit/violent: true
          self-harm/instructions: true
          harassment: true
          violence/graphic: true
          illicit: true
          self-harm/intent: true
          hate/threatening: true
          sexual/minors: true
          harassment/threatening: true
          hate: true
          self-harm: true
          sexual: true
          violence: true
      properties:
        flagged:
          description: Whether any of the below categories are flagged.
          type: boolean
        categories:
          $ref: '#/components/schemas/CreateModerationResponse_results_inner_categories'
        category_scores:
          $ref: '#/components/schemas/CreateModerationResponse_results_inner_category_scores'
        category_applied_input_types:
          $ref: '#/components/schemas/CreateModerationResponse_results_inner_category_applied_input_types'
      required:
      - categories
      - category_applied_input_types
      - category_scores
      - flagged
      type: object
    CreateThreadAndRunRequest_tools_inner:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
    CreateThreadAndRunRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/AssistantObject_tool_resources_file_search'
      type: object
    CreateThreadRequest_tool_resources_file_search_vector_stores_inner:
      example:
        chunking_strategy:
          type: auto
        metadata: "{}"
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
          items:
            type: string
          maxItems: 10000
          type: array
        chunking_strategy:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner_chunking_strategy'
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
          type: object
          x-oaiTypeLabel: map
      type: object
      x-oaiExpandable: true
    CreateThreadRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
        vector_stores:
        - chunking_strategy:
            type: auto
          metadata: "{}"
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
      nullable: true
      oneOf: []
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
          maxItems: 1
          type: array
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            $ref: '#/components/schemas/CreateThreadRequest_tool_resources_file_search_vector_stores_inner'
          maxItems: 1
          type: array
      type: object
    CreateThreadRequest_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
          vector_stores:
          - chunking_strategy:
              type: auto
            metadata: "{}"
            file_ids:
            - file_ids
            - file_ids
            - file_ids
            - file_ids
            - file_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/CreateThreadRequest_tool_resources_file_search'
      type: object
    CreateTranscriptionRequest_model:
      anyOf:
      - type: string
      - enum:
        - whisper-1
        type: string
      description: |
        ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.
      example: whisper-1
      x-oaiTypeLabel: string
    CreateVectorStoreRequest_chunking_strategy:
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy. Only applicable if `file_ids` is non-empty."
      oneOf:
      - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
      - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      type: object
      x-oaiExpandable: true
    FineTuningJob_error:
      description: "For fine-tuning jobs that have `failed`, this will contain more\
        \ information on the cause of the failure."
      example:
        code: code
        param: param
        message: message
      nullable: true
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "The parameter that was invalid, usually `training_file` or\
            \ `validation_file`. This field will be null if the failure was not parameter-specific."
          nullable: true
          type: string
      required:
      - code
      - message
      - param
      type: object
    FineTuningJob_hyperparameters_n_epochs:
      description: |-
        The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
        "auto" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 50
        minimum: 1
        type: integer
    FineTuningJob_hyperparameters:
      description: "The hyperparameters used for the fine-tuning job. See the [fine-tuning\
        \ guide](/docs/guides/fine-tuning) for more details."
      example:
        n_epochs: auto
      properties:
        n_epochs:
          $ref: '#/components/schemas/FineTuningJob_hyperparameters_n_epochs'
      required:
      - n_epochs
      type: object
    FineTuningJob_integrations_inner:
      oneOf:
      - $ref: '#/components/schemas/FineTuningIntegration'
      x-oaiExpandable: true
    FineTuningJobCheckpoint_metrics:
      description: Metrics at the step number during the fine-tuning job.
      example:
        full_valid_mean_token_accuracy: 3.616076749251911
        valid_loss: 2.3021358869347655
        full_valid_loss: 9.301444243932576
        train_mean_token_accuracy: 5.637376656633329
        valid_mean_token_accuracy: 7.061401241503109
        train_loss: 5.962133916683182
        step: 1.4658129805029452
      properties:
        step:
          type: number
        train_loss:
          type: number
        train_mean_token_accuracy:
          type: number
        valid_loss:
          type: number
        valid_mean_token_accuracy:
          type: number
        full_valid_loss:
          type: number
        full_valid_mean_token_accuracy:
          type: number
      type: object
    FinetuneChatRequestInput_messages_inner:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    MessageContentImageFileObject_image_file:
      example:
        file_id: file_id
        detail: auto
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - file_id
      type: object
    MessageContentImageUrlObject_image_url:
      properties:
        url:
          description: "The external URL of the image, must be a supported image types:\
            \ jpeg, jpg, png, gif, webp."
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`. Default value\
            \ is `auto`"
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
      type: object
    MessageContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
      required:
      - file_id
      type: object
    MessageContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
      required:
      - file_id
      type: object
    MessageContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
      x-oaiExpandable: true
    MessageContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: '#/components/schemas/MessageContentTextObject_text_annotations_inner'
          type: array
      required:
      - annotations
      - value
      type: object
    MessageDeltaContentImageFileObject_image_file:
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
      type: object
    MessageDeltaContentImageUrlObject_image_url:
      properties:
        url:
          description: "The URL of the image, must be a supported image types: jpeg,\
            \ jpg, png, gif, webp."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`."
          enum:
          - auto
          - low
          - high
          type: string
      type: object
    MessageDeltaContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
      type: object
    MessageDeltaContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
      type: object
    MessageDeltaContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
      x-oaiExpandable: true
    MessageDeltaContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: '#/components/schemas/MessageDeltaContentTextObject_text_annotations_inner'
          type: array
      type: object
    MessageDeltaObject_delta_content_inner:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextObject'
      - $ref: '#/components/schemas/MessageDeltaContentRefusalObject'
      - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
      x-oaiExpandable: true
    MessageDeltaObject_delta:
      description: The delta containing the fields that have changed on the Message.
      properties:
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: '#/components/schemas/MessageDeltaObject_delta_content_inner'
          type: array
      type: object
    MessageObject_incomplete_details:
      description: "On an incomplete message, details about why the message is incomplete."
      example:
        reason: content_filter
      nullable: true
      properties:
        reason:
          description: The reason the message is incomplete.
          enum:
          - content_filter
          - max_tokens
          - run_cancelled
          - run_expired
          - run_failed
          type: string
      required:
      - reason
      type: object
    MessageObject_content_inner:
      oneOf:
      - $ref: '#/components/schemas/MessageContentImageFileObject'
      - $ref: '#/components/schemas/MessageContentImageUrlObject'
      - $ref: '#/components/schemas/MessageContentTextObject'
      - $ref: '#/components/schemas/MessageContentRefusalObject'
      x-oaiExpandable: true
    MessageStreamEvent_oneOf:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ created."
      properties:
        event:
          enum:
          - thread.message.created
          type: string
        data:
          $ref: '#/components/schemas/MessageObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_1:
      description: "Occurs when a [message](/docs/api-reference/messages/object) moves\
        \ to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.message.in_progress
          type: string
        data:
          $ref: '#/components/schemas/MessageObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_2:
      description: "Occurs when parts of a [Message](/docs/api-reference/messages/object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.message.delta
          type: string
        data:
          $ref: '#/components/schemas/MessageDeltaObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)"
    MessageStreamEvent_oneOf_3:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ completed."
      properties:
        event:
          enum:
          - thread.message.completed
          type: string
        data:
          $ref: '#/components/schemas/MessageObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_4:
      description: "Occurs when a [message](/docs/api-reference/messages/object) ends\
        \ before it is completed."
      properties:
        event:
          enum:
          - thread.message.incomplete
          type: string
        data:
          $ref: '#/components/schemas/MessageObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ModifyAssistantRequest_tool_resources_code_interpreter:
      example:
        file_ids:
        - file_ids
        - file_ids
        - file_ids
        - file_ids
        - file_ids
      properties:
        file_ids:
          default: []
          description: |
            Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    ModifyAssistantRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    ModifyAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/ModifyAssistantRequest_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/ModifyAssistantRequest_tool_resources_file_search'
      type: object
    ModifyThreadRequest_tool_resources_file_search:
      example:
        vector_store_ids:
        - vector_store_ids
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    ModifyThreadRequest_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      example:
        code_interpreter:
          file_ids:
          - file_ids
          - file_ids
          - file_ids
          - file_ids
          - file_ids
        file_search:
          vector_store_ids:
          - vector_store_ids
      nullable: true
      properties:
        code_interpreter:
          $ref: '#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter'
        file_search:
          $ref: '#/components/schemas/ModifyThreadRequest_tool_resources_file_search'
      type: object
    ProjectApiKey_owner:
      example:
        service_account:
          role: owner
          name: name
          created_at: 1
          id: id
          object: organization.project.service_account
        type: user
        user:
          added_at: 6
          role: owner
          name: name
          id: id
          email: email
          object: organization.project.user
      properties:
        type:
          description: '`user` or `service_account`'
          enum:
          - user
          - service_account
          type: string
        user:
          $ref: '#/components/schemas/ProjectUser'
        service_account:
          $ref: '#/components/schemas/ProjectServiceAccount'
      type: object
    RealtimeClientEventConversationItemCreate_item_content_inner:
      properties:
        type:
          description: "The content type (\"input_text\", \"input_audio\", \"text\"\
            , \"audio\")."
          type: string
        text:
          description: The text content.
          type: string
        audio:
          description: Base64-encoded audio bytes.
          type: string
        transcript:
          description: The transcript of the audio.
          type: string
      type: object
    RealtimeClientEventConversationItemCreate_item:
      description: The item to add to the conversation.
      properties:
        id:
          description: The unique ID of the item.
          type: string
        type:
          description: "The type of the item (\"message\", \"function_call\", \"function_call_output\"\
            )."
          type: string
        status:
          description: "The status of the item (\"completed\", \"in_progress\", \"\
            incomplete\")."
          type: string
        role:
          description: "The role of the message sender (\"user\", \"assistant\", \"\
            system\")."
          type: string
        content:
          description: The content of the message.
          items:
            $ref: '#/components/schemas/RealtimeClientEventConversationItemCreate_item_content_inner'
          type: array
        call_id:
          description: The ID of the function call (for "function_call" items).
          type: string
        name:
          description: The name of the function being called (for "function_call"
            items).
          type: string
        arguments:
          description: The arguments of the function call (for "function_call" items).
          type: string
        output:
          description: The output of the function call (for "function_call_output"
            items).
          type: string
      type: object
    RealtimeClientEventResponseCreate_response_tools_inner:
      properties:
        type:
          description: The type of the tool.
          type: string
        name:
          description: The name of the function.
          type: string
        description:
          description: The description of the function.
          type: string
        parameters:
          description: Parameters of the function in JSON Schema.
          type: object
      type: object
    RealtimeClientEventResponseCreate_response_max_output_tokens:
      description: "Maximum number of output tokens for a single assistant response,\
        \ inclusive of tool calls. Provide an integer between 1 and 4096 to limit\
        \ output tokens, or \"inf\" for the maximum available tokens for a given model.\
        \ Defaults to \"inf\"."
      oneOf:
      - type: integer
      - enum:
        - inf
        type: string
    RealtimeClientEventResponseCreate_response:
      description: Configuration for the response.
      properties:
        modalities:
          description: The modalities for the response.
          items:
            type: string
          type: array
        instructions:
          description: Instructions for the model.
          type: string
        voice:
          description: "The voice the model uses to respond - one of `alloy`, `echo`,\
            \ or `shimmer`."
          type: string
        output_audio_format:
          description: The format of output audio.
          type: string
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response_tools_inner'
          type: array
        tool_choice:
          description: How the model chooses tools.
          type: string
        temperature:
          description: Sampling temperature.
          type: number
        max_output_tokens:
          $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response_max_output_tokens'
      type: object
    RealtimeClientEventSessionUpdate_session_input_audio_transcription:
      description: Configuration for input audio transcription. Can be set to `null`
        to turn off.
      properties:
        model:
          description: "The model to use for transcription (e.g., \"whisper-1\")."
          type: string
      type: object
    RealtimeClientEventSessionUpdate_session_turn_detection:
      description: Configuration for turn detection. Can be set to `null` to turn
        off.
      properties:
        type:
          description: "Type of turn detection, only \"server_vad\" is currently supported."
          type: string
        threshold:
          description: Activation threshold for VAD (0.0 to 1.0).
          type: number
        prefix_padding_ms:
          description: Amount of audio to include before speech starts (in milliseconds).
          type: integer
        silence_duration_ms:
          description: Duration of silence to detect speech stop (in milliseconds).
          type: integer
      type: object
    RealtimeClientEventSessionUpdate_session_tools_inner:
      properties:
        type:
          description: "The type of the tool, e.g., \"function\"."
          type: string
        name:
          description: The name of the function.
          type: string
        description:
          description: The description of the function.
          type: string
        parameters:
          description: Parameters of the function in JSON Schema.
          type: object
      type: object
    RealtimeClientEventSessionUpdate_session:
      description: Session configuration to update.
      properties:
        modalities:
          description: "The set of modalities the model can respond with. To disable\
            \ audio, set this to [\"text\"]."
          items:
            type: string
          type: array
        instructions:
          description: The default system instructions prepended to model calls.
          type: string
        voice:
          description: "The voice the model uses to respond - one of `alloy`, `echo`,\
            \ or  `shimmer`. Cannot be changed once the model has responded with audio\
            \  at least once."
          type: string
        input_audio_format:
          description: "The format of input audio. Options are \"pcm16\", \"g711_ulaw\"\
            , or \"g711_alaw\"."
          type: string
        output_audio_format:
          description: "The format of output audio. Options are \"pcm16\", \"g711_ulaw\"\
            , or \"g711_alaw\"."
          type: string
        input_audio_transcription:
          $ref: '#/components/schemas/RealtimeClientEventSessionUpdate_session_input_audio_transcription'
        turn_detection:
          $ref: '#/components/schemas/RealtimeClientEventSessionUpdate_session_turn_detection'
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: '#/components/schemas/RealtimeClientEventSessionUpdate_session_tools_inner'
          type: array
        tool_choice:
          description: "How the model chooses tools. Options are \"auto\", \"none\"\
            , \"required\", or specify a function."
          type: string
        temperature:
          description: Sampling temperature for the model.
          type: number
        max_output_tokens:
          $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response_max_output_tokens'
      type: object
    RealtimeServerEventConversationCreated_conversation:
      description: The conversation resource.
      properties:
        id:
          description: The unique ID of the conversation.
          type: string
        object:
          description: "The object type, must be \"realtime.conversation\"."
          type: string
      type: object
    RealtimeServerEventConversationItemCreated_item_content_inner:
      properties:
        type:
          description: "The content type (\"text\", \"audio\", \"input_text\", \"\
            input_audio\")."
          type: string
        text:
          description: The text content.
          type: string
        audio:
          description: Base64-encoded audio data.
          type: string
        transcript:
          description: The transcript of the audio.
          type: string
      type: object
    RealtimeServerEventConversationItemCreated_item:
      description: The item that was created.
      properties:
        id:
          description: The unique ID of the item.
          type: string
        object:
          description: "The object type, must be \"realtime.item\"."
          type: string
        type:
          description: "The type of the item (\"message\", \"function_call\", \"function_call_output\"\
            )."
          type: string
        status:
          description: "The status of the item (\"completed\", \"in_progress\", \"\
            incomplete\")."
          type: string
        role:
          description: "The role associated with the item (\"user\", \"assistant\"\
            , \"system\")."
          type: string
        content:
          description: The content of the item.
          items:
            $ref: '#/components/schemas/RealtimeServerEventConversationItemCreated_item_content_inner'
          type: array
        call_id:
          description: The ID of the function call (for "function_call" items).
          type: string
        name:
          description: The name of the function being called.
          type: string
        arguments:
          description: The arguments of the function call.
          type: string
        output:
          description: The output of the function call (for "function_call_output"
            items).
          type: string
      type: object
    RealtimeServerEventConversationItemInputAudioTranscriptionFailed_error:
      description: Details of the transcription error.
      properties:
        type:
          description: The type of error.
          type: string
        code:
          description: "Error code, if any."
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "Parameter related to the error, if any."
          type: string
      type: object
    RealtimeServerEventError_error:
      description: Details of the error.
      properties:
        type:
          description: "The type of error (e.g., \"invalid_request_error\", \"server_error\"\
            )."
          type: string
        code:
          description: "Error code, if any."
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "Parameter related to the error, if any."
          type: string
        event_id:
          description: "The event_id of the client event that caused the error, if\
            \ applicable."
          type: string
      type: object
    RealtimeServerEventRateLimitsUpdated_rate_limits_inner:
      properties:
        name:
          description: "The name of the rate limit (\"requests\", \"tokens\", \"input_tokens\"\
            , \"output_tokens\")."
          type: string
        limit:
          description: The maximum allowed value for the rate limit.
          type: integer
        remaining:
          description: The remaining value before the limit is reached.
          type: integer
        reset_seconds:
          description: Seconds until the rate limit resets.
          type: number
      type: object
    RealtimeServerEventResponseContentPartAdded_part:
      description: The content part that was added.
      properties:
        type:
          description: "The content type (\"text\", \"audio\")."
          type: string
        text:
          description: The text content (if type is "text").
          type: string
        audio:
          description: Base64-encoded audio data (if type is "audio").
          type: string
        transcript:
          description: The transcript of the audio (if type is "audio").
          type: string
      type: object
    RealtimeServerEventResponseContentPartDone_part:
      description: The content part that is done.
      properties:
        type:
          description: "The content type (\"text\", \"audio\")."
          type: string
        text:
          description: The text content (if type is "text").
          type: string
        audio:
          description: Base64-encoded audio data (if type is "audio").
          type: string
        transcript:
          description: The transcript of the audio (if type is "audio").
          type: string
      type: object
    RealtimeServerEventResponseCreated_response:
      description: The response resource.
      properties:
        id:
          description: The unique ID of the response.
          type: string
        object:
          description: "The object type, must be \"realtime.response\"."
          type: string
        status:
          description: The status of the response ("in_progress").
          type: string
        status_details:
          description: Additional details about the status.
          type: object
        output:
          description: The list of output items generated by the response.
          items:
            description: An item in the response output.
            type: object
          type: array
        usage:
          description: Usage statistics for the response.
          type: object
      type: object
    RealtimeServerEventResponseDone_response:
      description: The response resource.
      properties:
        id:
          description: The unique ID of the response.
          type: string
        object:
          description: "The object type, must be \"realtime.response\"."
          type: string
        status:
          description: "The final status of the response (\"completed\", \"cancelled\"\
            , \"failed\", \"incomplete\")."
          type: string
        status_details:
          description: Additional details about the status.
          type: object
        output:
          description: The list of output items generated by the response.
          items:
            description: An item in the response output.
            type: object
          type: array
        usage:
          description: Usage statistics for the response.
          type: object
      type: object
    RealtimeServerEventResponseOutputItemAdded_item_content_inner:
      properties:
        type:
          description: "The content type (\"text\", \"audio\")."
          type: string
        text:
          description: The text content.
          type: string
        audio:
          description: Base64-encoded audio data.
          type: string
        transcript:
          description: The transcript of the audio.
          type: string
      type: object
    RealtimeServerEventResponseOutputItemAdded_item:
      description: The item that was added.
      properties:
        id:
          description: The unique ID of the item.
          type: string
        object:
          description: "The object type, must be \"realtime.item\"."
          type: string
        type:
          description: "The type of the item (\"message\", \"function_call\", \"function_call_output\"\
            )."
          type: string
        status:
          description: "The status of the item (\"in_progress\", \"completed\")."
          type: string
        role:
          description: The role associated with the item ("assistant").
          type: string
        content:
          description: The content of the item.
          items:
            $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemAdded_item_content_inner'
          type: array
      type: object
    RealtimeServerEventResponseOutputItemDone_item:
      description: The completed item.
      properties:
        id:
          description: The unique ID of the item.
          type: string
        object:
          description: "The object type, must be \"realtime.item\"."
          type: string
        type:
          description: "The type of the item (\"message\", \"function_call\", \"function_call_output\"\
            )."
          type: string
        status:
          description: "The final status of the item (\"completed\", \"incomplete\"\
            )."
          type: string
        role:
          description: The role associated with the item ("assistant").
          type: string
        content:
          description: The content of the item.
          items:
            $ref: '#/components/schemas/RealtimeServerEventResponseOutputItemAdded_item_content_inner'
          type: array
      type: object
    RealtimeServerEventSessionCreated_session_input_audio_transcription:
      description: Configuration for input audio transcription.
      properties:
        enabled:
          description: Whether input audio transcription is enabled.
          type: boolean
        model:
          description: The model used for transcription.
          type: string
      type: object
    RealtimeServerEventSessionCreated_session_turn_detection:
      description: Configuration for turn detection.
      properties:
        type:
          description: The type of turn detection ("server_vad" or "none").
          type: string
        threshold:
          description: Activation threshold for VAD.
          type: number
        prefix_padding_ms:
          description: Audio included before speech starts (in milliseconds).
          type: integer
        silence_duration_ms:
          description: Duration of silence to detect speech stop (in milliseconds).
          type: integer
      type: object
    RealtimeServerEventSessionCreated_session_max_output_tokens:
      description: Maximum number of output tokens.
      oneOf:
      - type: integer
      - enum:
        - inf
        type: string
    RealtimeServerEventSessionCreated_session:
      description: The session resource.
      properties:
        id:
          description: The unique ID of the session.
          type: string
        object:
          description: "The object type, must be \"realtime.session\"."
          type: string
        model:
          description: The default model used for this session.
          type: string
        modalities:
          description: The set of modalities the model can respond with.
          items:
            type: string
          type: array
        instructions:
          description: The default system instructions.
          type: string
        voice:
          description: "The voice the model uses to respond - one of `alloy`, `echo`,\
            \ or `shimmer`."
          type: string
        input_audio_format:
          description: The format of input audio.
          type: string
        output_audio_format:
          description: The format of output audio.
          type: string
        input_audio_transcription:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_input_audio_transcription'
        turn_detection:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_turn_detection'
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response_tools_inner'
          type: array
        tool_choice:
          description: How the model chooses tools.
          type: string
        temperature:
          description: Sampling temperature.
          type: number
        max_output_tokens:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_max_output_tokens'
      type: object
    RealtimeServerEventSessionUpdated_session:
      description: The updated session resource.
      properties:
        id:
          description: The unique ID of the session.
          type: string
        object:
          description: "The object type, must be \"realtime.session\"."
          type: string
        model:
          description: The default model used for this session.
          type: string
        modalities:
          description: The set of modalities the model can respond with.
          items:
            type: string
          type: array
        instructions:
          description: The default system instructions.
          type: string
        voice:
          description: "The voice the model uses to respond - one of `alloy`, `echo`,\
            \ or `shimmer`."
          type: string
        input_audio_format:
          description: The format of input audio.
          type: string
        output_audio_format:
          description: The format of output audio.
          type: string
        input_audio_transcription:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_input_audio_transcription'
        turn_detection:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_turn_detection'
        tools:
          description: Tools (functions) available to the model.
          items:
            $ref: '#/components/schemas/RealtimeClientEventResponseCreate_response_tools_inner'
          type: array
        tool_choice:
          description: How the model chooses tools.
          type: string
        temperature:
          description: Sampling temperature.
          type: number
        max_output_tokens:
          $ref: '#/components/schemas/RealtimeServerEventSessionCreated_session_max_output_tokens'
      type: object
    ResponseFormatJsonSchema_json_schema:
      properties:
        description:
          description: "A description of what the response format is for, used by\
            \ the model to determine how to respond in the format."
          type: string
        name:
          description: "The name of the response format. Must be a-z, A-Z, 0-9, or\
            \ contain underscores and dashes, with a maximum length of 64."
          type: string
        schema:
          additionalProperties: true
          description: "The schema for the response format, described as a JSON Schema\
            \ object."
          type: object
        strict:
          default: false
          description: "Whether to enable strict schema adherence when generating\
            \ the output. If set to true, the model will always follow the exact schema\
            \ defined in the `schema` field. Only a subset of JSON Schema is supported\
            \ when `strict` is `true`. To learn more, read the [Structured Outputs\
            \ guide](/docs/guides/structured-outputs)."
          nullable: true
          type: boolean
      required:
      - name
      - type
      type: object
    RunObject_required_action_submit_tool_outputs:
      description: Details on the tool outputs needed for this run to continue.
      example:
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
      properties:
        tool_calls:
          description: A list of the relevant tool calls.
          items:
            $ref: '#/components/schemas/RunToolCallObject'
          type: array
      required:
      - tool_calls
      type: object
    RunObject_required_action:
      description: Details on the action required to continue the run. Will be `null`
        if no action is required.
      example:
        submit_tool_outputs:
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
        type: submit_tool_outputs
      nullable: true
      properties:
        type:
          description: "For now, this is always `submit_tool_outputs`."
          enum:
          - submit_tool_outputs
          type: string
        submit_tool_outputs:
          $ref: '#/components/schemas/RunObject_required_action_submit_tool_outputs'
      required:
      - submit_tool_outputs
      - type
      type: object
    RunObject_last_error:
      description: The last error associated with this run. Will be `null` if there
        are no errors.
      example:
        code: server_error
        message: message
      nullable: true
      properties:
        code:
          description: "One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`."
          enum:
          - server_error
          - rate_limit_exceeded
          - invalid_prompt
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    RunObject_incomplete_details:
      description: Details on why the run is incomplete. Will be `null` if the run
        is not incomplete.
      example:
        reason: max_completion_tokens
      nullable: true
      properties:
        reason:
          description: The reason why the run is incomplete. This will point to which
            specific token limit was reached over the course of the run.
          enum:
          - max_completion_tokens
          - max_prompt_tokens
          type: string
      type: object
    RunStepDeltaObject_delta_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
      type: object
      x-oaiExpandable: true
    RunStepDeltaObject_delta:
      description: The delta containing the fields that have changed on the run step.
      properties:
        step_details:
          $ref: '#/components/schemas/RunStepDeltaObject_delta_step_details'
      type: object
    RunStepDeltaStepDetailsMessageCreationObject_message_creation:
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
      type: object
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
      type: object
      x-oaiExpandable: true
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner'
          type: array
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
      type: object
    RunStepDeltaStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          nullable: true
          type: string
      type: object
    RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
      x-oaiExpandable: true
    RunStepDetailsMessageCreationObject_message_creation:
      example:
        message_id: message_id
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
      required:
      - message_id
      type: object
    RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
      type: object
      x-oaiExpandable: true
    RunStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner'
          type: array
      required:
      - input
      - outputs
      type: object
    RunStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
      required:
      - file_id
      type: object
    RunStepDetailsToolCallsFileSearchObject_file_search:
      description: "For now, this is always going to be an empty object."
      properties:
        ranking_options:
          $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchRankingOptionsObject'
        results:
          description: The results of the file search.
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchResultObject'
          type: array
      type: object
      x-oaiTypeLabel: map
    RunStepDetailsToolCallsFileSearchResultObject_content_inner:
      properties:
        type:
          description: The type of the content.
          enum:
          - text
          type: string
        text:
          description: The text content of the file.
          type: string
      type: object
    RunStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          nullable: true
          type: string
      required:
      - arguments
      - name
      - output
      type: object
    RunStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
      x-oaiExpandable: true
    RunStepObject_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
      type: object
      x-oaiExpandable: true
    RunStepObject_last_error:
      description: The last error associated with this run step. Will be `null` if
        there are no errors.
      example:
        code: server_error
        message: message
      nullable: true
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - server_error
          - rate_limit_exceeded
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    RunStepStreamEvent_oneOf:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is created."
      properties:
        event:
          enum:
          - thread.run.step.created
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_1:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ moves to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.run.step.in_progress
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_2:
      description: "Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.run.step.delta
          type: string
        data:
          $ref: '#/components/schemas/RunStepDeltaObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)"
    RunStepStreamEvent_oneOf_3:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is completed."
      properties:
        event:
          enum:
          - thread.run.step.completed
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_4:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ fails."
      properties:
        event:
          enum:
          - thread.run.step.failed
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_5:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ is cancelled."
      properties:
        event:
          enum:
          - thread.run.step.cancelled
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStepStreamEvent_oneOf_6:
      description: "Occurs when a [run step](/docs/api-reference/run-steps/step-object)\
        \ expires."
      properties:
        event:
          enum:
          - thread.run.step.expired
          type: string
        data:
          $ref: '#/components/schemas/RunStepObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/run-steps/step-object)"
    RunStreamEvent_oneOf:
      description: "Occurs when a new [run](/docs/api-reference/runs/object) is created."
      properties:
        event:
          enum:
          - thread.run.created
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_1:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `queued` status."
      properties:
        event:
          enum:
          - thread.run.queued
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_2:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ an `in_progress` status."
      properties:
        event:
          enum:
          - thread.run.in_progress
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_3:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `requires_action` status."
      properties:
        event:
          enum:
          - thread.run.requires_action
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_4:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is completed."
      properties:
        event:
          enum:
          - thread.run.completed
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_5:
      description: "Occurs when a [run](/docs/api-reference/runs/object) ends with\
        \ status `incomplete`."
      properties:
        event:
          enum:
          - thread.run.incomplete
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_6:
      description: "Occurs when a [run](/docs/api-reference/runs/object) fails."
      properties:
        event:
          enum:
          - thread.run.failed
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_7:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `cancelling` status."
      properties:
        event:
          enum:
          - thread.run.cancelling
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_8:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is cancelled."
      properties:
        event:
          enum:
          - thread.run.cancelled
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_9:
      description: "Occurs when a [run](/docs/api-reference/runs/object) expires."
      properties:
        event:
          enum:
          - thread.run.expired
          type: string
        data:
          $ref: '#/components/schemas/RunObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunToolCallObject_function:
      description: The function definition.
      example:
        name: name
        arguments: arguments
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments that the model expects you to pass to the function.
          type: string
      required:
      - arguments
      - name
      type: object
    SubmitToolOutputsRunRequest_tool_outputs_inner:
      example:
        output: output
        tool_call_id: tool_call_id
      properties:
        tool_call_id:
          description: The ID of the tool call in the `required_action` object within
            the run object the output is being submitted for.
          type: string
        output:
          description: The output of the tool call to be submitted to continue the
            run.
          type: string
      type: object
    ThreadStreamEvent_oneOf:
      description: "Occurs when a new [thread](/docs/api-reference/threads/object)\
        \ is created."
      properties:
        enabled:
          description: Whether to enable input audio transcription.
          type: boolean
        event:
          enum:
          - thread.created
          type: string
        data:
          $ref: '#/components/schemas/ThreadObject'
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [thread](/docs/api-reference/threads/object)"
    VectorStoreFileBatchObject_file_counts:
      example:
        in_progress: 6
        total: 2
        cancelled: 5
        completed: 1
        failed: 5
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that where cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
    VectorStoreFileObject_last_error:
      description: The last error associated with this vector store file. Will be
        `null` if there are no errors.
      example:
        code: server_error
        message: message
      nullable: true
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - server_error
          - unsupported_file
          - invalid_file
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    VectorStoreFileObject_chunking_strategy:
      description: The strategy used to chunk the file.
      oneOf:
      - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
      - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
      type: object
      x-oaiExpandable: true
    VectorStoreObject_file_counts:
      example:
        in_progress: 1
        total: 7
        cancelled: 2
        completed: 5
        failed: 5
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been successfully processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that were cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
  securitySchemes:
    ApiKeyAuth:
      scheme: bearer
      type: http
x-oaiMeta:
  navigationGroups:
  - id: endpoints
    title: Endpoints
  - id: assistants
    title: Assistants
    beta: true
  - id: administration
    title: Administration
  - id: realtime
    title: Realtime
    beta: true
  - id: legacy
    title: Legacy
  groups:
  - id: audio
    title: Audio
    description: |
      Learn how to turn audio into text or text into audio.

      Related guide: [Speech to text](/docs/guides/speech-to-text)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createSpeech
      path: createSpeech
    - type: endpoint
      key: createTranscription
      path: createTranscription
    - type: endpoint
      key: createTranslation
      path: createTranslation
    - type: object
      key: CreateTranscriptionResponseJson
      path: json-object
    - type: object
      key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
  - id: chat
    title: Chat
    description: |
      Given a list of messages comprising a conversation, the model will return a response.
      Related guide: [Chat Completions](/docs/guides/text-generation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createChatCompletion
      path: create
    - type: object
      key: CreateChatCompletionResponse
      path: object
    - type: object
      key: CreateChatCompletionStreamResponse
      path: streaming
  - id: embeddings
    title: Embeddings
    description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
      Related guide: [Embeddings](/docs/guides/embeddings)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEmbedding
      path: create
    - type: object
      key: Embedding
      path: object
  - id: fine-tuning
    title: Fine-tuning
    description: |
      Manage fine-tuning jobs to tailor a model to your specific training data.
      Related guide: [Fine-tune models](/docs/guides/fine-tuning)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFineTuningJob
      path: create
    - type: endpoint
      key: listPaginatedFineTuningJobs
      path: list
    - type: endpoint
      key: listFineTuningEvents
      path: list-events
    - type: endpoint
      key: listFineTuningJobCheckpoints
      path: list-checkpoints
    - type: endpoint
      key: retrieveFineTuningJob
      path: retrieve
    - type: endpoint
      key: cancelFineTuningJob
      path: cancel
    - type: object
      key: FinetuneChatRequestInput
      path: chat-input
    - type: object
      key: FinetuneCompletionRequestInput
      path: completions-input
    - type: object
      key: FineTuningJob
      path: object
    - type: object
      key: FineTuningJobEvent
      path: event-object
    - type: object
      key: FineTuningJobCheckpoint
      path: checkpoint-object
  - id: batch
    title: Batch
    description: |
      Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
      Related guide: [Batch](/docs/guides/batch)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createBatch
      path: create
    - type: endpoint
      key: retrieveBatch
      path: retrieve
    - type: endpoint
      key: cancelBatch
      path: cancel
    - type: endpoint
      key: listBatches
      path: list
    - type: object
      key: Batch
      path: object
    - type: object
      key: BatchRequestInput
      path: request-input
    - type: object
      key: BatchRequestOutput
      path: request-output
  - id: files
    title: Files
    description: |
      Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFile
      path: create
    - type: endpoint
      key: listFiles
      path: list
    - type: endpoint
      key: retrieveFile
      path: retrieve
    - type: endpoint
      key: deleteFile
      path: delete
    - type: endpoint
      key: downloadFile
      path: retrieve-contents
    - type: object
      key: OpenAIFile
      path: object
  - id: uploads
    title: Uploads
    description: |
      Allows you to upload large files in multiple parts.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createUpload
      path: create
    - type: endpoint
      key: addUploadPart
      path: add-part
    - type: endpoint
      key: completeUpload
      path: complete
    - type: endpoint
      key: cancelUpload
      path: cancel
    - type: object
      key: Upload
      path: object
    - type: object
      key: UploadPart
      path: part-object
  - id: images
    title: Images
    description: |
      Given a prompt and/or an input image, the model will generate a new image.
      Related guide: [Image generation](/docs/guides/images)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createImage
      path: create
    - type: endpoint
      key: createImageEdit
      path: createEdit
    - type: endpoint
      key: createImageVariation
      path: createVariation
    - type: object
      key: Image
      path: object
  - id: models
    title: Models
    description: |
      List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: listModels
      path: list
    - type: endpoint
      key: retrieveModel
      path: retrieve
    - type: endpoint
      key: deleteModel
      path: delete
    - type: object
      key: Model
      path: object
  - id: moderations
    title: Moderations
    description: |
      Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
      Related guide: [Moderations](/docs/guides/moderation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createModeration
      path: create
    - type: object
      key: CreateModerationResponse
      path: object
  - id: assistants
    title: Assistants
    beta: true
    description: |
      Build assistants that can call models and use tools to perform tasks.

      [Get started with the Assistants API](/docs/assistants)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createAssistant
      path: createAssistant
    - type: endpoint
      key: listAssistants
      path: listAssistants
    - type: endpoint
      key: getAssistant
      path: getAssistant
    - type: endpoint
      key: modifyAssistant
      path: modifyAssistant
    - type: endpoint
      key: deleteAssistant
      path: deleteAssistant
    - type: object
      key: AssistantObject
      path: object
  - id: threads
    title: Threads
    beta: true
    description: |
      Create threads that assistants can interact with.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createThread
      path: createThread
    - type: endpoint
      key: getThread
      path: getThread
    - type: endpoint
      key: modifyThread
      path: modifyThread
    - type: endpoint
      key: deleteThread
      path: deleteThread
    - type: object
      key: ThreadObject
      path: object
  - id: messages
    title: Messages
    beta: true
    description: |
      Create messages within threads

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createMessage
      path: createMessage
    - type: endpoint
      key: listMessages
      path: listMessages
    - type: endpoint
      key: getMessage
      path: getMessage
    - type: endpoint
      key: modifyMessage
      path: modifyMessage
    - type: endpoint
      key: deleteMessage
      path: deleteMessage
    - type: object
      key: MessageObject
      path: object
  - id: runs
    title: Runs
    beta: true
    description: |
      Represents an execution run on a thread.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createRun
      path: createRun
    - type: endpoint
      key: createThreadAndRun
      path: createThreadAndRun
    - type: endpoint
      key: listRuns
      path: listRuns
    - type: endpoint
      key: getRun
      path: getRun
    - type: endpoint
      key: modifyRun
      path: modifyRun
    - type: endpoint
      key: submitToolOuputsToRun
      path: submitToolOutputs
    - type: endpoint
      key: cancelRun
      path: cancelRun
    - type: object
      key: RunObject
      path: object
  - id: run-steps
    title: Run steps
    beta: true
    description: |
      Represents the steps (model and tool calls) taken during the run.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: listRunSteps
      path: listRunSteps
    - type: endpoint
      key: getRunStep
      path: getRunStep
    - type: object
      key: RunStepObject
      path: step-object
  - id: vector-stores
    title: Vector stores
    beta: true
    description: |
      Vector stores are used to store files for use by the `file_search` tool.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStore
      path: create
    - type: endpoint
      key: listVectorStores
      path: list
    - type: endpoint
      key: getVectorStore
      path: retrieve
    - type: endpoint
      key: modifyVectorStore
      path: modify
    - type: endpoint
      key: deleteVectorStore
      path: delete
    - type: object
      key: VectorStoreObject
      path: object
  - id: vector-stores-files
    title: Vector store files
    beta: true
    description: |
      Vector store files represent files inside a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStoreFile
      path: createFile
    - type: endpoint
      key: listVectorStoreFiles
      path: listFiles
    - type: endpoint
      key: getVectorStoreFile
      path: getFile
    - type: endpoint
      key: deleteVectorStoreFile
      path: deleteFile
    - type: object
      key: VectorStoreFileObject
      path: file-object
  - id: vector-stores-file-batches
    title: Vector store file batches
    beta: true
    description: |
      Vector store file batches represent operations to add multiple files to a vector store.
      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStoreFileBatch
      path: createBatch
    - type: endpoint
      key: getVectorStoreFileBatch
      path: getBatch
    - type: endpoint
      key: cancelVectorStoreFileBatch
      path: cancelBatch
    - type: endpoint
      key: listFilesInVectorStoreBatch
      path: listBatchFiles
    - type: object
      key: VectorStoreFileBatchObject
      path: batch-object
  - id: assistants-streaming
    title: Streaming
    beta: true
    description: |
      Stream the result of executing a Run or resuming a Run after submitting tool outputs.
      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
      [Assistants API quickstart](/docs/assistants/overview) to learn more.
    navigationGroup: assistants
    sections:
    - type: object
      key: MessageDeltaObject
      path: message-delta-object
    - type: object
      key: RunStepDeltaObject
      path: run-step-delta-object
    - type: object
      key: AssistantStreamEvent
      path: events
  - id: administration
    title: Administration
    description: "Programmatically manage your organization. \nThe Audit Logs endpoint\
      \ provides a log of all actions taken in the  organization for security and\
      \ monitoring purposes.\nTo access these endpoints please generate an Admin API\
      \ Key through the [API Platform Organization overview](/organization/admin-keys).\
      \ Admin API keys cannot be used for non-administration endpoints.\nFor best\
      \ practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices/setting-up-your-organization)\n"
    navigationGroup: administration
  - id: invite
    title: Invites
    description: Invite and manage invitations for an organization. Invited users
      are automatically added to the Default project.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-invites
      path: list
    - type: endpoint
      key: inviteUser
      path: create
    - type: endpoint
      key: retrieve-invite
      path: retrieve
    - type: endpoint
      key: delete-invite
      path: delete
    - type: object
      key: Invite
      path: object
  - id: users
    title: Users
    description: |
      Manage users and their role in an organization. Users will be automatically added to the Default project.
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-users
      path: list
    - type: endpoint
      key: modify-user
      path: modify
    - type: endpoint
      key: retrieve-user
      path: retrieve
    - type: endpoint
      key: delete-user
      path: delete
    - type: object
      key: User
      path: object
  - id: projects
    title: Projects
    description: "Manage the projects within an orgnanization includes creation, updating,\
      \ and archiving or projects. \nThe Default project cannot be modified or archived.\n"
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-projects
      path: list
    - type: endpoint
      key: create-project
      path: create
    - type: endpoint
      key: retrieve-project
      path: retrieve
    - type: endpoint
      key: modify-project
      path: modify
    - type: endpoint
      key: archive-project
      path: archive
    - type: object
      key: Project
      path: object
  - id: project-users
    title: Project users
    description: "Manage users within a project, including adding, updating roles,\
      \ and removing users. \nUsers cannot be removed from the Default project, unless\
      \ they are being removed from the organization.\n"
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-users
      path: list
    - type: endpoint
      key: create-project-user
      path: creeate
    - type: endpoint
      key: retrieve-project-user
      path: retrieve
    - type: endpoint
      key: modify-project-user
      path: modify
    - type: endpoint
      key: delete-project-user
      path: delete
    - type: object
      key: ProjectUser
      path: object
  - id: project-service-accounts
    title: Project service accounts
    description: "Manage service accounts within a project. A service account is a\
      \ bot user that is not associated with a user. \nIf a user leaves an organization,\
      \ their keys and membership in projects will no longer work. Service accounts\
      \ \ndo not have this limitation. However, service accounts can also be deleted\
      \ from a project.\n"
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-service-accounts
      path: list
    - type: endpoint
      key: create-project-service-account
      path: create
    - type: endpoint
      key: retrieve-project-service-account
      path: retrieve
    - type: endpoint
      key: delete-project-service-account
      path: delete
    - type: object
      key: ProjectServiceAccount
      path: object
  - id: project-api-keys
    title: Project API keys
    description: "Manage API keys for a given project. Supports listing and deleting\
      \ keys for users. \nThis API does not allow issuing keys for users, as users\
      \ need to authorize themselves to generate keys.\n"
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-project-api-keys
      path: list
    - type: endpoint
      key: retrieve-project-api-key
      path: retrieve
    - type: endpoint
      key: delete-project-api-key
      path: delete
    - type: object
      key: ProjectApiKey
      path: object
  - id: audit-logs
    title: Audit logs
    description: "Logs of user actions and configuration changes within this organization.\
      \ \nTo log events, you must activate logging in the [Organization Settings](/settings/organization/general).\
      \ \nOnce activated, for security reasons, logging cannot be deactivated.\n"
    navigationGroup: administration
    sections:
    - type: endpoint
      key: list-audit-logs
      path: list
    - type: object
      key: AuditLog
      path: object
  - id: realtime
    title: Realtime
    beta: true
    description: |
      Communicate with a GPT-4o class model live, in real time, over WebSocket.
      Produces both audio and text transcriptions.
      [Learn more about the Realtime API](/docs/guides/realtime).
    navigationGroup: realtime
  - id: realtime-client-events
    title: Client events
    description: |
      These are events that the OpenAI Realtime WebSocket server will accept from the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeClientEventSessionUpdate
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferAppend
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferCommit
      path: <auto>
    - type: object
      key: RealtimeClientEventInputAudioBufferClear
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemTruncate
      path: <auto>
    - type: object
      key: RealtimeClientEventConversationItemDelete
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCreate
      path: <auto>
    - type: object
      key: RealtimeClientEventResponseCancel
      path: <auto>
  - id: realtime-server-events
    title: Server events
    description: |
      These are events emitted from the OpenAI Realtime WebSocket server to the client.
    navigationGroup: realtime
    sections:
    - type: object
      key: RealtimeServerEventError
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventSessionUpdated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemTruncated
      path: <auto>
    - type: object
      key: RealtimeServerEventConversationItemDeleted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCommitted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferCleared
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStarted
      path: <auto>
    - type: object
      key: RealtimeServerEventInputAudioBufferSpeechStopped
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseCreated
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseOutputItemDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartAdded
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseContentPartDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseTextDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioTranscriptDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseAudioDone
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDelta
      path: <auto>
    - type: object
      key: RealtimeServerEventResponseFunctionCallArgumentsDone
      path: <auto>
    - type: object
      key: RealtimeServerEventRateLimitsUpdated
      path: <auto>
  - id: completions
    title: Completions
    legacy: true
    navigationGroup: legacy
    description: |
      Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation/text-generation-models) to leverage our best and newest models.
    sections:
    - type: endpoint
      key: createCompletion
      path: create
    - type: object
      key: CreateCompletionResponse
      path: object

